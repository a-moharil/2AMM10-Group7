{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "730fd591"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_4/assignment_4_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "d32f8d18"
      },
      "source": [
        "# Group Number:\n",
        "\n",
        "# Student 1: Ambarish Moharil\n",
        "\n",
        "# Student 2: Kunal Geed\n",
        "\n",
        "# Student 3: Mert Lostar"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vBZyoF4CzeqK"
      },
      "source": [
        "# Imports"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "8hfRbF4gzeqK"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pickle\n",
        "import requests\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.optim import Adam\n",
        "from torchvision.datasets import FashionMNIST\n",
        "import torchvision.transforms as transforms\n",
        "from torch.utils.data import DataLoader, SubsetRandomSampler\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from tqdm import tqdm\n",
        "from sklearn.metrics import roc_curve, precision_recall_curve, auc\n",
        "\n",
        "# other imports go here"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "sWTBxXuIzeqL"
      },
      "source": [
        "# Data loading and inspection"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "u3gKc0l-zeqL"
      },
      "outputs": [],
      "source": [
        "# load and inspect data\n",
        "data_location = 'https://surfdrive.surf.nl/files/index.php/s/K3ArFDQJb5USQ6K/download'\n",
        "data_request = requests.get(data_location)\n",
        "full_data = pickle.loads(data_request.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5MWymCXGLNlZ",
        "outputId": "6ab56526-aeb2-41e3-8308-e205fc086aa2"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dict_keys(['unlabeled_data', 'labeled_data', 'representative_set_1', 'representative_set_2'])"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ],
      "source": [
        "#Let's see how the full dataset looks like.\n",
        "\n",
        "full_data.keys()\n",
        "\n",
        "#unlabelled dataset - 26000 Images in distribution that are not labellled.\n",
        "\n",
        "#labeled dataset - 2000 Images that are in distribution and labelled\n",
        "\n",
        "#representatiive set1 and set2 - 1052 data points each which contain roughly 5% out-of-\n",
        "#                      distribution data and which are fully labeled (anomalies being \n",
        "#                       labeled as a sixth class)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "-AfhzfowLNlb"
      },
      "outputs": [],
      "source": [
        "\n",
        "train_data = full_data[\"unlabeled_data\"]/255.0 #train on the 26000 in distribution images, normalizing(/255)\n",
        "\n",
        "val_data = full_data[\"labeled_data\"][\"data\"] \n",
        "val_labels = full_data[\"labeled_data\"][\"labels\"]\n",
        "\n",
        "test_set_1 = full_data[\"representative_set_1\"][\"data\"] #get the data from first repres set\n",
        "test_set_2 = full_data[\"representative_set_2\"][\"data\"] # get the data from the second repres set\n",
        "\n",
        "test_labels_set1 = full_data[\"representative_set_1\"][\"labels\"] #get the labels from rep set 1\n",
        "test_labels_set2 = full_data[\"representative_set_2\"][\"labels\"] #get the resp labels from rep set 2\n",
        "\n",
        "test_set = np.concatenate((test_set_1, test_set_2), axis =0) # concatenate those two sets for testing\n",
        "                                                                      # [2104, 1, 32, 32]\n",
        "test_labels = np.concatenate((test_labels_set1, test_labels_set2), axis =0)# get the respective labels\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "bwDmHpSxLNlb"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "from torchvision import transforms\n",
        "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
        "import numpy as np\n",
        "from PIL import Image\n",
        "\n",
        "class TrainDataset(Dataset):\n",
        "    def __init__(self, data):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "\n",
        "        return x\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)\n",
        "\n",
        "class GeneralDataset(Dataset):\n",
        "    def __init__(self, data, target):\n",
        "        self.data = torch.FloatTensor(data)\n",
        "        self.target  = torch.FloatTensor(target)\n",
        "        \n",
        "    def __getitem__(self, index):\n",
        "        x = self.data[index]\n",
        "        y = self.data[target]\n",
        "\n",
        "        return x, y\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "9cT0xFwQLNlc"
      },
      "outputs": [],
      "source": [
        "#Create the dataloaders\n",
        "train_dataset = TrainDataset(train_data)\n",
        "train_dataloader = DataLoader(dataset=train_dataset, batch_size= 10)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "id": "A06LcAaILNlc"
      },
      "outputs": [],
      "source": [
        "def show_images(x, ncols=10):\n",
        "    \"\"\" plots first ncols images in a batch \"\"\"\n",
        "    x = x.view(-1, 32, 32)\n",
        "\n",
        "    fig, ax = plt.subplots(1, ncols, figsize=(20, 2))\n",
        "    for idx in range(ncols):\n",
        "        ax[idx].imshow(x[idx].cpu().numpy(), cmap=\"Greys\")\n",
        "        ax[idx].axis('off')\n",
        "    plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 125
        },
        "id": "KsbABILKLNlc",
        "outputId": "ac8f1963-4625-4648-f144-cdbe4682305e"
      },
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1440x144 with 10 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ],
      "source": [
        "#Plot the images\n",
        "for x in train_dataloader:\n",
        "    show_images(x)\n",
        "    break"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "TKZIzTPAzeqL"
      },
      "source": [
        "# Data augmentation and pipeline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gka5t3dBzeqM"
      },
      "outputs": [],
      "source": [
        "# code for data augmentation pipeline "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uCVwEcbXzeqM"
      },
      "source": [
        "# Model definitions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {
        "id": "Ut8sUHlVzeqM"
      },
      "outputs": [],
      "source": [
        "# code for model definitions goes here\n",
        "class Encoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim):\n",
        "        super(Encoder, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "        self.input_layer = nn.Linear(input_dim, hidden_dim) # can also give a convolutional input\n",
        "        self.hidden_layer = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.mu_layer = nn.Linear(hidden_dim, latent_dim)\n",
        "        self.sigma_layer = nn.Linear(hidden_dim, latent_dim)\n",
        "        \n",
        "    def forward(self, batch_input):\n",
        "        \n",
        "        \n",
        "        h = nn.ReLU()(self.input_layer(batch_input)) #[N X H], H = hidden_dim, N = batch_size\n",
        "        h = nn.ReLU()(self.hidden_layer(h)) #[N X H]\n",
        "        \n",
        "        mu = self.mu_layer(h)\n",
        "        log_sigma = self.sigma_layer(h)\n",
        "        \n",
        "        z = self.reparam(mu, log_sigma)\n",
        "        \n",
        "        return z, mu, log_sigma\n",
        "    \n",
        "    def reparam(self, mu, log_sigma):\n",
        "        sigma = torch.exp(log_sigma)\n",
        "        eps = torch.randn_like(sigma) #Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.\n",
        "        \n",
        "        z = mu + sigma*eps\n",
        "        \n",
        "        return z\n",
        "    \n",
        "#The encoder has now encoded the the input into an L dim latent vector Z, we need to decode z in order to sample from p(x)\n",
        "#Thus we define a decoder \n",
        "\n",
        "class Decoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, latent_dim, output_dim):\n",
        "        super(Decoder, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.hidden_layer1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.hidden_layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "    def forward(self, z):\n",
        "        \n",
        "        h_o = nn.ReLU()(self.hidden_layer1(z))\n",
        "        h_o = nn.ReLU()(self.hidden_layer2(h_o))\n",
        "        \n",
        "        reconstruction = nn.Sigmoid()(self.out(h_o))\n",
        "        \n",
        "        return reconstruction\n",
        "        \n",
        "#Now we can define the VAE\n",
        "\n",
        "class VAE(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(VAE, self).__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "        \n",
        "    def forward(self, batch_input):\n",
        "        \n",
        "        z, mu, log_sigma = self.encoder(batch_input)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "        \n",
        "        return x_reconstructed, mu, log_sigma"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#use a convolutional layer in the network\n",
        "\n",
        "\n",
        "# code for model definitions goes here\n",
        "class ConvEncoder(nn.Module):\n",
        "    def __init__(self, input_dim, hidden_dim, latent_dim, imgChannels =1, featureDim = 32*28*28):\n",
        "        super(ConvEncoder, self).__init__()\n",
        "        \n",
        "        self.input_dim = input_dim\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        \n",
        "        # Initializing the 2 convolutional layers and 2 full-connected layers for the encoder\n",
        "        self.encConv1 = nn.Conv2d(imgChannels, 16, 3, stride =1)\n",
        "        self.encConv2 = nn.Conv2d(16, 32, 3, stride =1)\n",
        "        self.encFC1 = nn.Linear(featureDim, latent_dim)\n",
        "        self.encFC2 = nn.Linear(featureDim, latent_dim)\n",
        "\n",
        "        \n",
        "        #self.input_layer = nn.Linear(out_channels*32*32, hidden_dim)\n",
        "        self.hidden_layer = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.mu_layer = nn.Linear(featureDim, latent_dim)\n",
        "        self.sigma_layer = nn.Linear(featureDim, latent_dim)\n",
        "        \n",
        "    def forward(self, batch_input):\n",
        "        \n",
        "        h = nn.ReLU()(self.encConv1(batch_input)) #[N X H], H = hidden_dim, N = batch_size\n",
        "        h = nn.ReLU()(self.encConv2(h)) \n",
        "        #h = nn.ReLU()(self.hidden_layer(h)) #[N X H]\n",
        "        h = h.view(-1, 32*28*28)\n",
        "        \n",
        "        \n",
        "        \n",
        "        mu = self.mu_layer(h)\n",
        "        log_sigma = self.sigma_layer(h)\n",
        "        \n",
        "        z = self.reparam(mu, log_sigma)\n",
        "        \n",
        "        return z, mu, log_sigma\n",
        "    \n",
        "    def reparam(self, mu, log_sigma):\n",
        "        sigma = torch.exp(log_sigma)\n",
        "        eps = torch.randn_like(sigma) #Returns a tensor with the same size as input that is filled with random numbers from a normal distribution with mean 0 and variance 1.\n",
        "        \n",
        "        z = mu + sigma*eps\n",
        "        \n",
        "        return z\n",
        "    \n",
        "#The encoder has now encoded the the input into an L dim latent vector Z, we need to decode z in order to sample from p(x)\n",
        "#Thus we define a decoder \n",
        "\n",
        "class ConvDecoder(nn.Module):\n",
        "    def __init__(self, hidden_dim, latent_dim, output_dim, imgChannels =1, featureDim = 32*28*28):\n",
        "        super(ConvDecoder, self).__init__()\n",
        "        \n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.latent_dim = latent_dim\n",
        "        self.output_dim = output_dim\n",
        "        \n",
        "        self.hidden_layer1 = nn.Linear(latent_dim, hidden_dim)\n",
        "        self.hidden_layer2 = nn.Linear(hidden_dim, hidden_dim)\n",
        "        self.out = nn.Linear(hidden_dim, output_dim)\n",
        "        \n",
        "        # Initializing the fully-connected layer and 2 convolutional layers for decoder\n",
        "        self.decFC1 = nn.Linear(latent_dim, featureDim)\n",
        "        self.decConv1 = nn.ConvTranspose2d(32, 16, 3)\n",
        "        self.decConv2 = nn.ConvTranspose2d(16, imgChannels, 3)\n",
        "\n",
        "        \n",
        "    def forward(self, z):\n",
        "        \n",
        "        h_o = nn.ReLU()(self.decFC1(z))\n",
        "        \n",
        "        h_o = h_o.view(-1, 32,28,28)\n",
        "        \n",
        "        h_o = nn.ReLU()(self.decConv1(h_o))\n",
        "\n",
        "        reconstruction = nn.Sigmoid()(self.decConv2(h_o))\n",
        "        \n",
        "        return reconstruction\n",
        "        \n",
        "#Now we can define the VAE\n",
        "\n",
        "class ConvVAE(nn.Module):\n",
        "    def __init__(self, encoder, decoder):\n",
        "        super(ConvVAE, self).__init__()\n",
        "        \n",
        "        self.encoder = encoder\n",
        "        self.decoder = decoder\n",
        "        \n",
        "        \n",
        "    def forward(self, batch_input):\n",
        "        \n",
        "        z, mu, log_sigma = self.encoder(batch_input)\n",
        "        x_reconstructed = self.decoder(z)\n",
        "        \n",
        "        return x_reconstructed, mu, log_sigma\n",
        "    "
      ],
      "metadata": {
        "id": "kTYtfW0QzLvO"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Aw0OHyzRzeqN"
      },
      "source": [
        "# Training and validation loop"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "id": "vJX78MD3zeqN"
      },
      "outputs": [],
      "source": [
        "# write your training and validation loop here\n",
        "\n",
        "# training and validation after every epoch\n",
        "def train(model, train_loader, num_epochs, save_name):\n",
        "    best_loss = float(\"Inf\") \n",
        "    train_overall_loss, train_recons_loss, train_kl_loss = [], [], []\n",
        "    cur_step = 0\n",
        "    train_pred = []\n",
        "    val_pred = []\n",
        "    input_dim = 32*32\n",
        "    batch_size = 10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        overall_loss = 0.0 \n",
        "        overall_recons_loss = 0.0\n",
        "        overall_kl_loss = 0.0 \n",
        "        model.train()\n",
        "        print(\"Starting epoch \" + str(epoch+1))\n",
        "        for train_data in train_loader:   \n",
        "            # Forward\n",
        "            input_tensor = train_data.to(device)\n",
        "            input_tensor = input_tensor.view(batch_size, 32*32)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, mu, log_sigma = model.forward(input_tensor)\n",
        "            loss, reconstruction_loss, kl_loss = loss_criterion(input_tensor, outputs,mu, log_sigma)\n",
        "            overall_loss += loss.item()\n",
        "            overall_recons_loss  += reconstruction_loss.item()\n",
        "            overall_kl_loss += kl_loss\n",
        "            \n",
        "                \n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()   \n",
        "            \n",
        "        n_datapoints = len(train_loader)\n",
        "        avg_overall_loss = overall_loss / n_datapoints\n",
        "        train_overall_loss.append(avg_overall_loss)\n",
        "        \n",
        "        avg_recons_loss = overall_recons_loss/ n_datapoints\n",
        "        train_recons_loss.append(avg_recons_loss)\n",
        "        \n",
        "        avg_kl_loss = overall_kl_loss / n_datapoints\n",
        "        train_kl_loss.append(avg_kl_loss)\n",
        "        \n",
        "        print(\"Train Pass Completed\")\n",
        "        \n",
        "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", avg_overall_loss, \"\\tReconstruction Loss:\", avg_recons_loss, \"\\tKL Loss:\", avg_kl_loss)\n",
        "\n",
        "        if avg_recons_loss < best_loss:\n",
        "            best_loss = avg_recons_loss\n",
        "            #save_model_checkpoint(save_name, model, optimizer, best_loss, 0, 0,avg_recons_loss )\n",
        "    \n",
        "    print(\"Finished Training\") \n",
        "    return train_overall_loss, train_recons_loss, train_kl_loss\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# write your training and validation loop here\n",
        "\n",
        "# training and validation after every epoch\n",
        "def train_conv(model, train_loader, num_epochs, save_name):\n",
        "    best_loss = float(\"Inf\") \n",
        "    train_overall_loss, train_recons_loss, train_kl_loss = [], [], []\n",
        "    cur_step = 0\n",
        "    train_pred = []\n",
        "    val_pred = []\n",
        "    input_dim = 32*32\n",
        "    batch_size = 10\n",
        "\n",
        "    for epoch in range(num_epochs):\n",
        "        overall_loss = 0.0 \n",
        "        overall_recons_loss = 0.0\n",
        "        overall_kl_loss = 0.0 \n",
        "        model.train()\n",
        "        print(\"Starting epoch \" + str(epoch+1))\n",
        "        for train_data in train_loader:   \n",
        "            # Forward\n",
        "            input_tensor = train_data.to(device)\n",
        "            #input_tensor = input_tensor.view(batch_size,32*32)\n",
        "            optimizer.zero_grad()\n",
        "            outputs, mu, log_sigma = model.forward(input_tensor)\n",
        "            loss, reconstruction_loss, kl_loss = loss_criterion(input_tensor, outputs,mu, log_sigma)\n",
        "            overall_loss += loss.item()\n",
        "            overall_recons_loss  += reconstruction_loss.item()\n",
        "            overall_kl_loss += kl_loss\n",
        "            \n",
        "                \n",
        "            # Backward and optimize\n",
        "            loss.backward()\n",
        "            optimizer.step()   \n",
        "            \n",
        "        n_datapoints = len(train_loader)\n",
        "        avg_overall_loss = overall_loss / n_datapoints\n",
        "        train_overall_loss.append(avg_overall_loss)\n",
        "        \n",
        "        avg_recons_loss = overall_recons_loss/ n_datapoints\n",
        "        train_recons_loss.append(avg_recons_loss)\n",
        "        \n",
        "        avg_kl_loss = overall_kl_loss / n_datapoints\n",
        "        train_kl_loss.append(avg_kl_loss)\n",
        "        \n",
        "        print(\"Train Pass Completed\")\n",
        "        \n",
        "        print(\"\\tEpoch\", epoch + 1, \"\\tAverage Loss: \", avg_overall_loss, \"\\tReconstruction Loss:\", avg_recons_loss, \"\\tKL Loss:\", avg_kl_loss)\n",
        "\n",
        "        if avg_recons_loss < best_loss:\n",
        "            best_loss = avg_recons_loss\n",
        "            #save_model_checkpoint(save_name, model, optimizer, best_loss, 0, 0,avg_recons_loss )\n",
        "    \n",
        "    print(\"Finished Training\") \n",
        "    return train_overall_loss, train_recons_loss, train_kl_loss\n"
      ],
      "metadata": {
        "id": "_QazYtKFzWeF"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "id": "tIaB0ITtLNle"
      },
      "outputs": [],
      "source": [
        "#Loss Criterion\n",
        "\n",
        "def loss_criterion(x, x_reconstr, mu, log_sigma):\n",
        "    reconstr_loss = nn.functional.mse_loss(x_reconstr, x, reduction='sum')\n",
        "    kl_loss = 0.5 * torch.sum(mu.pow(2) + (2*log_sigma).exp() - 2*log_sigma - 1)\n",
        "    total_loss = reconstr_loss + kl_loss\n",
        "    return total_loss, reconstr_loss, kl_loss"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "D0ALoFf2zeqN",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "c9f383f7-3444-41e9-f368-95b09571a255"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Train Pass Completed\n",
            "\tEpoch 1 \tAverage Loss:  318.2812664208045 \tReconstruction Loss: 265.5634706057035 \tKL Loss: tensor(52.7178, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 2\n",
            "Train Pass Completed\n",
            "\tEpoch 2 \tAverage Loss:  257.1870663686899 \tReconstruction Loss: 196.1627971971952 \tKL Loss: tensor(61.0243, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 3\n",
            "Train Pass Completed\n",
            "\tEpoch 3 \tAverage Loss:  249.3517426476112 \tReconstruction Loss: 187.53321632385254 \tKL Loss: tensor(61.8186, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 4\n",
            "Train Pass Completed\n",
            "\tEpoch 4 \tAverage Loss:  244.83212759164664 \tReconstruction Loss: 182.16125150240384 \tKL Loss: tensor(62.6709, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 5\n",
            "Train Pass Completed\n",
            "\tEpoch 5 \tAverage Loss:  242.25783145024226 \tReconstruction Loss: 178.79569751446064 \tKL Loss: tensor(63.4621, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 6\n",
            "Train Pass Completed\n",
            "\tEpoch 6 \tAverage Loss:  240.08808626028207 \tReconstruction Loss: 176.24165042583758 \tKL Loss: tensor(63.8464, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 7\n",
            "Train Pass Completed\n",
            "\tEpoch 7 \tAverage Loss:  238.47573209322417 \tReconstruction Loss: 174.39384843679574 \tKL Loss: tensor(64.0819, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 8\n",
            "Train Pass Completed\n",
            "\tEpoch 8 \tAverage Loss:  236.7451369711069 \tReconstruction Loss: 172.46604036771333 \tKL Loss: tensor(64.2791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 9\n",
            "Train Pass Completed\n",
            "\tEpoch 9 \tAverage Loss:  236.07693549522986 \tReconstruction Loss: 171.21791289989764 \tKL Loss: tensor(64.8590, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 10\n",
            "Train Pass Completed\n",
            "\tEpoch 10 \tAverage Loss:  234.92328342731182 \tReconstruction Loss: 169.82134422302246 \tKL Loss: tensor(65.1019, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 11\n",
            "Train Pass Completed\n",
            "\tEpoch 11 \tAverage Loss:  233.93622387225813 \tReconstruction Loss: 168.73739696209248 \tKL Loss: tensor(65.1988, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 12\n",
            "Train Pass Completed\n",
            "\tEpoch 12 \tAverage Loss:  233.4811452953632 \tReconstruction Loss: 167.90663109119123 \tKL Loss: tensor(65.5746, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 13\n",
            "Train Pass Completed\n",
            "\tEpoch 13 \tAverage Loss:  232.75355806790864 \tReconstruction Loss: 166.99469250605657 \tKL Loss: tensor(65.7589, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 14\n",
            "Train Pass Completed\n",
            "\tEpoch 14 \tAverage Loss:  232.2522705606314 \tReconstruction Loss: 166.36057395054743 \tKL Loss: tensor(65.8917, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 15\n",
            "Train Pass Completed\n",
            "\tEpoch 15 \tAverage Loss:  231.4170023052509 \tReconstruction Loss: 165.59261658008282 \tKL Loss: tensor(65.8245, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 16\n",
            "Train Pass Completed\n",
            "\tEpoch 16 \tAverage Loss:  231.33179766728327 \tReconstruction Loss: 165.06615967090312 \tKL Loss: tensor(66.2656, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 17\n",
            "Train Pass Completed\n",
            "\tEpoch 17 \tAverage Loss:  230.7649863962027 \tReconstruction Loss: 164.59013021322397 \tKL Loss: tensor(66.1749, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 18\n",
            "Train Pass Completed\n",
            "\tEpoch 18 \tAverage Loss:  230.2634642791748 \tReconstruction Loss: 163.70427505199726 \tKL Loss: tensor(66.5592, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 19\n",
            "Train Pass Completed\n",
            "\tEpoch 19 \tAverage Loss:  229.7810459606464 \tReconstruction Loss: 163.39158556424655 \tKL Loss: tensor(66.3895, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 20\n",
            "Train Pass Completed\n",
            "\tEpoch 20 \tAverage Loss:  229.89857636084923 \tReconstruction Loss: 163.12866472097542 \tKL Loss: tensor(66.7699, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 21\n",
            "Train Pass Completed\n",
            "\tEpoch 21 \tAverage Loss:  229.5481772848276 \tReconstruction Loss: 162.84076016646165 \tKL Loss: tensor(66.7075, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 22\n",
            "Train Pass Completed\n",
            "\tEpoch 22 \tAverage Loss:  229.2528218137301 \tReconstruction Loss: 162.24633977449858 \tKL Loss: tensor(67.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 23\n",
            "Train Pass Completed\n",
            "\tEpoch 23 \tAverage Loss:  228.45717303349423 \tReconstruction Loss: 161.65061817756066 \tKL Loss: tensor(66.8065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 24\n",
            "Train Pass Completed\n",
            "\tEpoch 24 \tAverage Loss:  228.99071516770582 \tReconstruction Loss: 161.7219435794537 \tKL Loss: tensor(67.2687, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 25\n",
            "Train Pass Completed\n",
            "\tEpoch 25 \tAverage Loss:  228.35992780832143 \tReconstruction Loss: 161.3289042340792 \tKL Loss: tensor(67.0310, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 26\n",
            "Train Pass Completed\n",
            "\tEpoch 26 \tAverage Loss:  228.15236862769493 \tReconstruction Loss: 160.83981706765982 \tKL Loss: tensor(67.3126, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 27\n",
            "Train Pass Completed\n",
            "\tEpoch 27 \tAverage Loss:  228.03648426349346 \tReconstruction Loss: 160.7808314191378 \tKL Loss: tensor(67.2557, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 28\n",
            "Train Pass Completed\n",
            "\tEpoch 28 \tAverage Loss:  227.6433552316519 \tReconstruction Loss: 160.3071428651076 \tKL Loss: tensor(67.3363, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 29\n",
            "Train Pass Completed\n",
            "\tEpoch 29 \tAverage Loss:  227.81373342660757 \tReconstruction Loss: 160.08141070732702 \tKL Loss: tensor(67.7324, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 30\n",
            "Train Pass Completed\n",
            "\tEpoch 30 \tAverage Loss:  227.4412250342736 \tReconstruction Loss: 159.98021090874306 \tKL Loss: tensor(67.4611, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 31\n",
            "Train Pass Completed\n",
            "\tEpoch 31 \tAverage Loss:  227.25687405512883 \tReconstruction Loss: 159.76993870074932 \tKL Loss: tensor(67.4870, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 32\n",
            "Train Pass Completed\n",
            "\tEpoch 32 \tAverage Loss:  227.23782485375037 \tReconstruction Loss: 159.42361377716065 \tKL Loss: tensor(67.8142, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 33\n",
            "Train Pass Completed\n",
            "\tEpoch 33 \tAverage Loss:  226.89818959162784 \tReconstruction Loss: 159.26675635117752 \tKL Loss: tensor(67.6315, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 34\n",
            "Train Pass Completed\n",
            "\tEpoch 34 \tAverage Loss:  226.81038601801944 \tReconstruction Loss: 159.04430698101336 \tKL Loss: tensor(67.7661, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 35\n",
            "Train Pass Completed\n",
            "\tEpoch 35 \tAverage Loss:  226.48578180753267 \tReconstruction Loss: 158.54644132760856 \tKL Loss: tensor(67.9393, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 36\n",
            "Train Pass Completed\n",
            "\tEpoch 36 \tAverage Loss:  226.71792690570538 \tReconstruction Loss: 158.59877346625694 \tKL Loss: tensor(68.1191, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 37\n",
            "Train Pass Completed\n",
            "\tEpoch 37 \tAverage Loss:  226.3698886988713 \tReconstruction Loss: 158.34857253441444 \tKL Loss: tensor(68.0212, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 38\n",
            "Train Pass Completed\n",
            "\tEpoch 38 \tAverage Loss:  226.2722693340595 \tReconstruction Loss: 158.30897778437688 \tKL Loss: tensor(67.9633, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 39\n",
            "Train Pass Completed\n",
            "\tEpoch 39 \tAverage Loss:  225.86589344904974 \tReconstruction Loss: 157.83015917264498 \tKL Loss: tensor(68.0357, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 40\n",
            "Train Pass Completed\n",
            "\tEpoch 40 \tAverage Loss:  226.04193484966572 \tReconstruction Loss: 157.79063840132494 \tKL Loss: tensor(68.2513, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 41\n",
            "Train Pass Completed\n",
            "\tEpoch 41 \tAverage Loss:  226.20765366187462 \tReconstruction Loss: 157.69127321096568 \tKL Loss: tensor(68.5164, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 42\n",
            "Train Pass Completed\n",
            "\tEpoch 42 \tAverage Loss:  225.82765263484075 \tReconstruction Loss: 157.5443562580989 \tKL Loss: tensor(68.2833, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 43\n",
            "Train Pass Completed\n",
            "\tEpoch 43 \tAverage Loss:  225.67419640761156 \tReconstruction Loss: 157.40303499075083 \tKL Loss: tensor(68.2712, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 44\n",
            "Train Pass Completed\n",
            "\tEpoch 44 \tAverage Loss:  225.50509346595177 \tReconstruction Loss: 157.27989156576302 \tKL Loss: tensor(68.2253, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 45\n",
            "Train Pass Completed\n",
            "\tEpoch 45 \tAverage Loss:  225.51149649399977 \tReconstruction Loss: 156.88861501547007 \tKL Loss: tensor(68.6229, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 46\n",
            "Train Pass Completed\n",
            "\tEpoch 46 \tAverage Loss:  225.41067128108097 \tReconstruction Loss: 156.8764965732281 \tKL Loss: tensor(68.5343, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 47\n",
            "Train Pass Completed\n",
            "\tEpoch 47 \tAverage Loss:  225.1775535290058 \tReconstruction Loss: 156.73800479008602 \tKL Loss: tensor(68.4396, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 48\n",
            "Train Pass Completed\n",
            "\tEpoch 48 \tAverage Loss:  225.0094926746075 \tReconstruction Loss: 156.60986951387846 \tKL Loss: tensor(68.3996, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 49\n",
            "Train Pass Completed\n",
            "\tEpoch 49 \tAverage Loss:  225.01419170673077 \tReconstruction Loss: 156.54454488314116 \tKL Loss: tensor(68.4697, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 50\n",
            "Train Pass Completed\n",
            "\tEpoch 50 \tAverage Loss:  224.9218387075571 \tReconstruction Loss: 156.26770326761098 \tKL Loss: tensor(68.6541, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 51\n",
            "Train Pass Completed\n",
            "\tEpoch 51 \tAverage Loss:  225.09366995591384 \tReconstruction Loss: 156.4503653042133 \tKL Loss: tensor(68.6433, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 52\n",
            "Train Pass Completed\n",
            "\tEpoch 52 \tAverage Loss:  224.73584149874173 \tReconstruction Loss: 155.9310412128155 \tKL Loss: tensor(68.8048, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 53\n",
            "Train Pass Completed\n",
            "\tEpoch 53 \tAverage Loss:  224.8871571995662 \tReconstruction Loss: 155.95458162747897 \tKL Loss: tensor(68.9325, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 54\n",
            "Train Pass Completed\n",
            "\tEpoch 54 \tAverage Loss:  224.755052924523 \tReconstruction Loss: 155.82200868753287 \tKL Loss: tensor(68.9330, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 55\n",
            "Train Pass Completed\n",
            "\tEpoch 55 \tAverage Loss:  224.31297864473783 \tReconstruction Loss: 155.7835215641902 \tKL Loss: tensor(68.5295, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 56\n",
            "Train Pass Completed\n",
            "\tEpoch 56 \tAverage Loss:  224.7286279296875 \tReconstruction Loss: 155.66891278780423 \tKL Loss: tensor(69.0598, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 57\n",
            "Train Pass Completed\n",
            "\tEpoch 57 \tAverage Loss:  224.2798588033823 \tReconstruction Loss: 155.22757295168364 \tKL Loss: tensor(69.0523, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 58\n",
            "Train Pass Completed\n",
            "\tEpoch 58 \tAverage Loss:  224.3744872870812 \tReconstruction Loss: 155.1121236214271 \tKL Loss: tensor(69.2624, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 59\n",
            "Train Pass Completed\n",
            "\tEpoch 59 \tAverage Loss:  224.55749168395997 \tReconstruction Loss: 155.36581385979287 \tKL Loss: tensor(69.1917, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 60\n",
            "Train Pass Completed\n",
            "\tEpoch 60 \tAverage Loss:  224.21828319256122 \tReconstruction Loss: 155.19799954341008 \tKL Loss: tensor(69.0203, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 61\n",
            "Train Pass Completed\n",
            "\tEpoch 61 \tAverage Loss:  224.05381280165452 \tReconstruction Loss: 154.9973999404907 \tKL Loss: tensor(69.0564, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 62\n",
            "Train Pass Completed\n",
            "\tEpoch 62 \tAverage Loss:  223.81443402803862 \tReconstruction Loss: 154.6297507770245 \tKL Loss: tensor(69.1847, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 63\n",
            "Train Pass Completed\n",
            "\tEpoch 63 \tAverage Loss:  224.09254716726448 \tReconstruction Loss: 154.89047069843 \tKL Loss: tensor(69.2022, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 64\n",
            "Train Pass Completed\n",
            "\tEpoch 64 \tAverage Loss:  224.18031463623046 \tReconstruction Loss: 154.67957284193773 \tKL Loss: tensor(69.5007, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 65\n",
            "Train Pass Completed\n",
            "\tEpoch 65 \tAverage Loss:  223.78280076246995 \tReconstruction Loss: 154.56817305344802 \tKL Loss: tensor(69.2147, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 66\n",
            "Train Pass Completed\n",
            "\tEpoch 66 \tAverage Loss:  223.98271270165077 \tReconstruction Loss: 154.556305034344 \tKL Loss: tensor(69.4264, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 67\n",
            "Train Pass Completed\n",
            "\tEpoch 67 \tAverage Loss:  223.41439856896034 \tReconstruction Loss: 154.35241889366736 \tKL Loss: tensor(69.0620, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 68\n",
            "Train Pass Completed\n",
            "\tEpoch 68 \tAverage Loss:  223.89758026709924 \tReconstruction Loss: 154.51396955049955 \tKL Loss: tensor(69.3836, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 69\n",
            "Train Pass Completed\n",
            "\tEpoch 69 \tAverage Loss:  223.8087009840745 \tReconstruction Loss: 154.3111149597168 \tKL Loss: tensor(69.4976, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 70\n",
            "Train Pass Completed\n",
            "\tEpoch 70 \tAverage Loss:  223.74667106041542 \tReconstruction Loss: 154.2311979176448 \tKL Loss: tensor(69.5155, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 71\n",
            "Train Pass Completed\n",
            "\tEpoch 71 \tAverage Loss:  223.55783150306115 \tReconstruction Loss: 154.16802733788123 \tKL Loss: tensor(69.3898, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 72\n",
            "Train Pass Completed\n",
            "\tEpoch 72 \tAverage Loss:  223.6538959796612 \tReconstruction Loss: 154.28947046720066 \tKL Loss: tensor(69.3644, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 73\n",
            "Train Pass Completed\n",
            "\tEpoch 73 \tAverage Loss:  223.66924523573655 \tReconstruction Loss: 153.95980426201453 \tKL Loss: tensor(69.7095, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 74\n",
            "Train Pass Completed\n",
            "\tEpoch 74 \tAverage Loss:  223.63343618539665 \tReconstruction Loss: 153.8708266859788 \tKL Loss: tensor(69.7626, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 75\n",
            "Train Pass Completed\n",
            "\tEpoch 75 \tAverage Loss:  223.35399896474985 \tReconstruction Loss: 153.8514013466468 \tKL Loss: tensor(69.5026, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 76\n",
            "Train Pass Completed\n",
            "\tEpoch 76 \tAverage Loss:  223.48893869840182 \tReconstruction Loss: 153.88920271359956 \tKL Loss: tensor(69.5997, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 77\n",
            "Train Pass Completed\n",
            "\tEpoch 77 \tAverage Loss:  223.22138888432428 \tReconstruction Loss: 153.66901061131404 \tKL Loss: tensor(69.5524, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 78\n",
            "Train Pass Completed\n",
            "\tEpoch 78 \tAverage Loss:  223.54337567256047 \tReconstruction Loss: 153.78420943626992 \tKL Loss: tensor(69.7592, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 79\n",
            "Train Pass Completed\n",
            "\tEpoch 79 \tAverage Loss:  223.27042855482836 \tReconstruction Loss: 153.55031712165245 \tKL Loss: tensor(69.7201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 80\n",
            "Train Pass Completed\n",
            "\tEpoch 80 \tAverage Loss:  223.1496739079402 \tReconstruction Loss: 153.52489427713246 \tKL Loss: tensor(69.6249, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 81\n",
            "Train Pass Completed\n",
            "\tEpoch 81 \tAverage Loss:  222.97036008981559 \tReconstruction Loss: 153.545767625662 \tKL Loss: tensor(69.4245, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 82\n",
            "Train Pass Completed\n",
            "\tEpoch 82 \tAverage Loss:  223.3188582611084 \tReconstruction Loss: 153.47323667672964 \tKL Loss: tensor(69.8457, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 83\n",
            "Train Pass Completed\n",
            "\tEpoch 83 \tAverage Loss:  222.99995836111216 \tReconstruction Loss: 153.44656760289118 \tKL Loss: tensor(69.5535, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 84\n",
            "Train Pass Completed\n",
            "\tEpoch 84 \tAverage Loss:  223.1058861717811 \tReconstruction Loss: 153.20065776238076 \tKL Loss: tensor(69.9053, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 85\n",
            "Train Pass Completed\n",
            "\tEpoch 85 \tAverage Loss:  222.95365684509278 \tReconstruction Loss: 153.20699643648587 \tKL Loss: tensor(69.7466, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 86\n",
            "Train Pass Completed\n",
            "\tEpoch 86 \tAverage Loss:  222.9232667013315 \tReconstruction Loss: 153.16924898294303 \tKL Loss: tensor(69.7540, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 87\n",
            "Train Pass Completed\n",
            "\tEpoch 87 \tAverage Loss:  223.02274178138146 \tReconstruction Loss: 153.14113212878888 \tKL Loss: tensor(69.8816, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 88\n",
            "Train Pass Completed\n",
            "\tEpoch 88 \tAverage Loss:  223.08878008328952 \tReconstruction Loss: 153.09482134598952 \tKL Loss: tensor(69.9938, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 89\n",
            "Train Pass Completed\n",
            "\tEpoch 89 \tAverage Loss:  222.75440115121694 \tReconstruction Loss: 152.92634054037242 \tKL Loss: tensor(69.8280, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 90\n",
            "Train Pass Completed\n",
            "\tEpoch 90 \tAverage Loss:  222.92932749821588 \tReconstruction Loss: 152.91611749795766 \tKL Loss: tensor(70.0132, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 91\n",
            "Train Pass Completed\n",
            "\tEpoch 91 \tAverage Loss:  222.93131590623122 \tReconstruction Loss: 152.83968615018404 \tKL Loss: tensor(70.0916, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 92\n",
            "Train Pass Completed\n",
            "\tEpoch 92 \tAverage Loss:  222.519675187331 \tReconstruction Loss: 152.93571940788857 \tKL Loss: tensor(69.5840, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 93\n",
            "Train Pass Completed\n",
            "\tEpoch 93 \tAverage Loss:  222.57478667626015 \tReconstruction Loss: 152.77175562638502 \tKL Loss: tensor(69.8030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 94\n",
            "Train Pass Completed\n",
            "\tEpoch 94 \tAverage Loss:  222.62304374694824 \tReconstruction Loss: 152.84184106680064 \tKL Loss: tensor(69.7812, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 95\n",
            "Train Pass Completed\n",
            "\tEpoch 95 \tAverage Loss:  222.3163705913837 \tReconstruction Loss: 152.52273506457988 \tKL Loss: tensor(69.7937, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 96\n",
            "Train Pass Completed\n",
            "\tEpoch 96 \tAverage Loss:  222.58636219904972 \tReconstruction Loss: 152.60662432450513 \tKL Loss: tensor(69.9797, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 97\n",
            "Train Pass Completed\n",
            "\tEpoch 97 \tAverage Loss:  222.49847619863658 \tReconstruction Loss: 152.47632019923284 \tKL Loss: tensor(70.0222, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 98\n",
            "Train Pass Completed\n",
            "\tEpoch 98 \tAverage Loss:  222.69312282855694 \tReconstruction Loss: 152.3856825344379 \tKL Loss: tensor(70.3074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 99\n",
            "Train Pass Completed\n",
            "\tEpoch 99 \tAverage Loss:  222.3004494828444 \tReconstruction Loss: 152.49739369905913 \tKL Loss: tensor(69.8030, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 100\n",
            "Train Pass Completed\n",
            "\tEpoch 100 \tAverage Loss:  222.40347930321326 \tReconstruction Loss: 152.3984597866352 \tKL Loss: tensor(70.0050, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Finished Training\n"
          ]
        }
      ],
      "source": [
        "# perform training\n",
        "import torch.optim as optim\n",
        "\n",
        "device = \"cuda:0\"\n",
        "\n",
        "encoder = Encoder(input_dim = 32*32, hidden_dim = 500, latent_dim = 5).cuda()\n",
        "decoder = Decoder(hidden_dim = 500, latent_dim = 5, output_dim = 32*32).cuda()\n",
        "\n",
        "vae = VAE(encoder = encoder, decoder = decoder).cuda()\n",
        "\n",
        "optimizer = optim.Adam(vae.parameters(), lr = 6e-4)\n",
        "save_name = f'Vanilla_VAE.pt'\n",
        "epochs = 100\n",
        "obtained_train_overall_loss, obtained_train_recons_loss, obtained_train_kl_loss = train(vae, train_dataloader,\n",
        "                                                                                        epochs , save_name )\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# perform training\n",
        "import torch.optim as optim\n",
        "\n",
        "device = \"cuda:0\"\n",
        "\n",
        "encoder = ConvEncoder(input_dim = 32*32, hidden_dim = 500, latent_dim = 5).cuda()\n",
        "decoder = ConvDecoder(hidden_dim = 500, latent_dim = 5, output_dim = 32*32).cuda()\n",
        "\n",
        "conv_vae = ConvVAE(encoder = encoder, decoder = decoder).cuda()\n",
        "\n",
        "optimizer = optim.Adam(conv_vae.parameters(), lr = 3e-4)\n",
        "save_name = f'Conv_VAE.pt'\n",
        "epochs = 100\n",
        "obtained_train_overall_loss, obtained_train_recons_loss, obtained_train_kl_loss = train_conv(conv_vae, train_dataloader,\n",
        "                                                                                        epochs , save_name )\n"
      ],
      "metadata": {
        "id": "Vj7y9Qx6zcD7",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "outputId": "2433e8b1-9fbb-4f46-cd19-92360d4445a7"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting epoch 1\n",
            "Train Pass Completed\n",
            "\tEpoch 1 \tAverage Loss:  378.8871323746901 \tReconstruction Loss: 307.3035065636268 \tKL Loss: tensor(71.5837, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 2\n",
            "Train Pass Completed\n",
            "\tEpoch 2 \tAverage Loss:  266.18930389404295 \tReconstruction Loss: 196.07840074099028 \tKL Loss: tensor(70.1109, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 3\n",
            "Train Pass Completed\n",
            "\tEpoch 3 \tAverage Loss:  256.52211876502406 \tReconstruction Loss: 185.94348112839918 \tKL Loss: tensor(70.5786, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 4\n",
            "Train Pass Completed\n",
            "\tEpoch 4 \tAverage Loss:  251.9292435807448 \tReconstruction Loss: 180.7332887150691 \tKL Loss: tensor(71.1959, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 5\n",
            "Train Pass Completed\n",
            "\tEpoch 5 \tAverage Loss:  248.20634165250337 \tReconstruction Loss: 177.04468100914588 \tKL Loss: tensor(71.1617, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 6\n",
            "Train Pass Completed\n",
            "\tEpoch 6 \tAverage Loss:  245.76323858994704 \tReconstruction Loss: 174.1051672421969 \tKL Loss: tensor(71.6582, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 7\n",
            "Train Pass Completed\n",
            "\tEpoch 7 \tAverage Loss:  244.08171096801757 \tReconstruction Loss: 172.05202659020057 \tKL Loss: tensor(72.0296, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 8\n",
            "Train Pass Completed\n",
            "\tEpoch 8 \tAverage Loss:  242.80528351416956 \tReconstruction Loss: 170.403521930988 \tKL Loss: tensor(72.4017, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 9\n",
            "Train Pass Completed\n",
            "\tEpoch 9 \tAverage Loss:  241.19424548809346 \tReconstruction Loss: 168.79848270709698 \tKL Loss: tensor(72.3958, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 10\n",
            "Train Pass Completed\n",
            "\tEpoch 10 \tAverage Loss:  240.61085148151105 \tReconstruction Loss: 167.89147065382738 \tKL Loss: tensor(72.7193, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 11\n",
            "Train Pass Completed\n",
            "\tEpoch 11 \tAverage Loss:  239.1914471259484 \tReconstruction Loss: 166.7168191058819 \tKL Loss: tensor(72.4747, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 12\n",
            "Train Pass Completed\n",
            "\tEpoch 12 \tAverage Loss:  238.7976956998385 \tReconstruction Loss: 165.82899039341854 \tKL Loss: tensor(72.9687, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 13\n",
            "Train Pass Completed\n",
            "\tEpoch 13 \tAverage Loss:  237.56491184528056 \tReconstruction Loss: 164.90691466404843 \tKL Loss: tensor(72.6581, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 14\n",
            "Train Pass Completed\n",
            "\tEpoch 14 \tAverage Loss:  237.4651560328557 \tReconstruction Loss: 164.36249818361722 \tKL Loss: tensor(73.1027, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 15\n",
            "Train Pass Completed\n",
            "\tEpoch 15 \tAverage Loss:  236.73348720257098 \tReconstruction Loss: 163.6042476976835 \tKL Loss: tensor(73.1293, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 16\n",
            "Train Pass Completed\n",
            "\tEpoch 16 \tAverage Loss:  236.18657364478477 \tReconstruction Loss: 163.0664235628568 \tKL Loss: tensor(73.1201, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 17\n",
            "Train Pass Completed\n",
            "\tEpoch 17 \tAverage Loss:  235.6360961503249 \tReconstruction Loss: 162.35601794022782 \tKL Loss: tensor(73.2802, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 18\n",
            "Train Pass Completed\n",
            "\tEpoch 18 \tAverage Loss:  235.67249282836914 \tReconstruction Loss: 162.09423336029053 \tKL Loss: tensor(73.5783, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 19\n",
            "Train Pass Completed\n",
            "\tEpoch 19 \tAverage Loss:  235.00286743164062 \tReconstruction Loss: 161.59086930788482 \tKL Loss: tensor(73.4119, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 20\n",
            "Train Pass Completed\n",
            "\tEpoch 20 \tAverage Loss:  234.54640902592587 \tReconstruction Loss: 161.07944773160494 \tKL Loss: tensor(73.4669, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 21\n",
            "Train Pass Completed\n",
            "\tEpoch 21 \tAverage Loss:  234.24618720421424 \tReconstruction Loss: 160.61902345217192 \tKL Loss: tensor(73.6272, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 22\n",
            "Train Pass Completed\n",
            "\tEpoch 22 \tAverage Loss:  233.7875182049091 \tReconstruction Loss: 160.249142972506 \tKL Loss: tensor(73.5385, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 23\n",
            "Train Pass Completed\n",
            "\tEpoch 23 \tAverage Loss:  233.53324341407188 \tReconstruction Loss: 159.9078973212609 \tKL Loss: tensor(73.6254, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 24\n",
            "Train Pass Completed\n",
            "\tEpoch 24 \tAverage Loss:  233.41628908010628 \tReconstruction Loss: 159.648754096398 \tKL Loss: tensor(73.7676, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 25\n",
            "Train Pass Completed\n",
            "\tEpoch 25 \tAverage Loss:  233.29281443669245 \tReconstruction Loss: 159.3333519744873 \tKL Loss: tensor(73.9595, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 26\n",
            "Train Pass Completed\n",
            "\tEpoch 26 \tAverage Loss:  232.75105721106897 \tReconstruction Loss: 159.02326551584096 \tKL Loss: tensor(73.7279, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 27\n",
            "Train Pass Completed\n",
            "\tEpoch 27 \tAverage Loss:  232.27148259089543 \tReconstruction Loss: 158.32835253201998 \tKL Loss: tensor(73.9430, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 28\n",
            "Train Pass Completed\n",
            "\tEpoch 28 \tAverage Loss:  232.03192595261794 \tReconstruction Loss: 158.24637694725624 \tKL Loss: tensor(73.7856, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 29\n",
            "Train Pass Completed\n",
            "\tEpoch 29 \tAverage Loss:  232.06066023606522 \tReconstruction Loss: 158.3028449043861 \tKL Loss: tensor(73.7578, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 30\n",
            "Train Pass Completed\n",
            "\tEpoch 30 \tAverage Loss:  231.5785629918025 \tReconstruction Loss: 157.61335899059588 \tKL Loss: tensor(73.9651, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 31\n",
            "Train Pass Completed\n",
            "\tEpoch 31 \tAverage Loss:  231.46013458251954 \tReconstruction Loss: 157.51327672518218 \tKL Loss: tensor(73.9468, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 32\n",
            "Train Pass Completed\n",
            "\tEpoch 32 \tAverage Loss:  231.36960610609788 \tReconstruction Loss: 157.33877881857066 \tKL Loss: tensor(74.0307, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 33\n",
            "Train Pass Completed\n",
            "\tEpoch 33 \tAverage Loss:  231.05014954787035 \tReconstruction Loss: 156.98797170492318 \tKL Loss: tensor(74.0622, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 34\n",
            "Train Pass Completed\n",
            "\tEpoch 34 \tAverage Loss:  230.9161785008357 \tReconstruction Loss: 156.85377989255466 \tKL Loss: tensor(74.0623, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 35\n",
            "Train Pass Completed\n",
            "\tEpoch 35 \tAverage Loss:  230.57545619084286 \tReconstruction Loss: 156.55817544496978 \tKL Loss: tensor(74.0173, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 36\n",
            "Train Pass Completed\n",
            "\tEpoch 36 \tAverage Loss:  230.64542634230395 \tReconstruction Loss: 156.3835829602755 \tKL Loss: tensor(74.2619, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 37\n",
            "Train Pass Completed\n",
            "\tEpoch 37 \tAverage Loss:  230.2557584498479 \tReconstruction Loss: 156.24921527862548 \tKL Loss: tensor(74.0065, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 38\n",
            "Train Pass Completed\n",
            "\tEpoch 38 \tAverage Loss:  230.06829350398138 \tReconstruction Loss: 156.0155670782236 \tKL Loss: tensor(74.0528, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 39\n",
            "Train Pass Completed\n",
            "\tEpoch 39 \tAverage Loss:  229.7349087230976 \tReconstruction Loss: 155.70376949897178 \tKL Loss: tensor(74.0312, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 40\n",
            "Train Pass Completed\n",
            "\tEpoch 40 \tAverage Loss:  230.34640944847695 \tReconstruction Loss: 155.7987683046781 \tKL Loss: tensor(74.5477, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 41\n",
            "Train Pass Completed\n",
            "\tEpoch 41 \tAverage Loss:  229.49143979586088 \tReconstruction Loss: 155.45412487910343 \tKL Loss: tensor(74.0374, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 42\n",
            "Train Pass Completed\n",
            "\tEpoch 42 \tAverage Loss:  229.51582562373235 \tReconstruction Loss: 155.4506038284302 \tKL Loss: tensor(74.0652, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 43\n",
            "Train Pass Completed\n",
            "\tEpoch 43 \tAverage Loss:  229.74396423339843 \tReconstruction Loss: 155.1870432310838 \tKL Loss: tensor(74.5569, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 44\n",
            "Train Pass Completed\n",
            "\tEpoch 44 \tAverage Loss:  229.26864698556753 \tReconstruction Loss: 154.9751371383667 \tKL Loss: tensor(74.2936, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 45\n",
            "Train Pass Completed\n",
            "\tEpoch 45 \tAverage Loss:  229.4096631211501 \tReconstruction Loss: 154.98522173368013 \tKL Loss: tensor(74.4244, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 46\n",
            "Train Pass Completed\n",
            "\tEpoch 46 \tAverage Loss:  229.00375399662897 \tReconstruction Loss: 154.7127907708975 \tKL Loss: tensor(74.2910, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 47\n",
            "Train Pass Completed\n",
            "\tEpoch 47 \tAverage Loss:  228.9354554455097 \tReconstruction Loss: 154.43109506166897 \tKL Loss: tensor(74.5044, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 48\n",
            "Train Pass Completed\n",
            "\tEpoch 48 \tAverage Loss:  228.71298642085148 \tReconstruction Loss: 154.30221214000994 \tKL Loss: tensor(74.4108, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 49\n",
            "Train Pass Completed\n",
            "\tEpoch 49 \tAverage Loss:  228.7480346738375 \tReconstruction Loss: 154.207684073815 \tKL Loss: tensor(74.5404, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 50\n",
            "Train Pass Completed\n",
            "\tEpoch 50 \tAverage Loss:  228.7435427563007 \tReconstruction Loss: 154.14419129298284 \tKL Loss: tensor(74.5993, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 51\n",
            "Train Pass Completed\n",
            "\tEpoch 51 \tAverage Loss:  228.56424010643593 \tReconstruction Loss: 153.88842729421762 \tKL Loss: tensor(74.6758, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 52\n",
            "Train Pass Completed\n",
            "\tEpoch 52 \tAverage Loss:  228.42151178213265 \tReconstruction Loss: 153.81271752284124 \tKL Loss: tensor(74.6087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 53\n",
            "Train Pass Completed\n",
            "\tEpoch 53 \tAverage Loss:  228.25710041339582 \tReconstruction Loss: 153.55878052931567 \tKL Loss: tensor(74.6984, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 54\n",
            "Train Pass Completed\n",
            "\tEpoch 54 \tAverage Loss:  228.1931373537504 \tReconstruction Loss: 153.6634079537025 \tKL Loss: tensor(74.5297, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 55\n",
            "Train Pass Completed\n",
            "\tEpoch 55 \tAverage Loss:  227.93444448617788 \tReconstruction Loss: 153.35537892855132 \tKL Loss: tensor(74.5791, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 56\n",
            "Train Pass Completed\n",
            "\tEpoch 56 \tAverage Loss:  227.964163877047 \tReconstruction Loss: 153.21703845977783 \tKL Loss: tensor(74.7472, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 57\n",
            "Train Pass Completed\n",
            "\tEpoch 57 \tAverage Loss:  227.9262311084454 \tReconstruction Loss: 153.12394390693078 \tKL Loss: tensor(74.8023, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 58\n",
            "Train Pass Completed\n",
            "\tEpoch 58 \tAverage Loss:  227.72572609534632 \tReconstruction Loss: 152.91182715489313 \tKL Loss: tensor(74.8138, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 59\n",
            "Train Pass Completed\n",
            "\tEpoch 59 \tAverage Loss:  227.70235240642842 \tReconstruction Loss: 152.8053841341459 \tKL Loss: tensor(74.8969, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 60\n",
            "Train Pass Completed\n",
            "\tEpoch 60 \tAverage Loss:  227.69072774446929 \tReconstruction Loss: 152.905187495305 \tKL Loss: tensor(74.7855, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 61\n",
            "Train Pass Completed\n",
            "\tEpoch 61 \tAverage Loss:  227.74939940819374 \tReconstruction Loss: 152.7407458290687 \tKL Loss: tensor(75.0087, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 62\n",
            "Train Pass Completed\n",
            "\tEpoch 62 \tAverage Loss:  227.3973968857985 \tReconstruction Loss: 152.62701640789325 \tKL Loss: tensor(74.7703, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 63\n",
            "Train Pass Completed\n",
            "\tEpoch 63 \tAverage Loss:  227.50748880239632 \tReconstruction Loss: 152.70006863814135 \tKL Loss: tensor(74.8074, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 64\n",
            "Train Pass Completed\n",
            "\tEpoch 64 \tAverage Loss:  227.26558426490197 \tReconstruction Loss: 152.36817616389348 \tKL Loss: tensor(74.8974, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 65\n",
            "Train Pass Completed\n",
            "\tEpoch 65 \tAverage Loss:  227.23996369581957 \tReconstruction Loss: 152.17698013599102 \tKL Loss: tensor(75.0630, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 66\n",
            "Train Pass Completed\n",
            "\tEpoch 66 \tAverage Loss:  227.06327509366548 \tReconstruction Loss: 152.1292935356727 \tKL Loss: tensor(74.9341, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 67\n",
            "Train Pass Completed\n",
            "\tEpoch 67 \tAverage Loss:  227.01715161837063 \tReconstruction Loss: 152.01123177455023 \tKL Loss: tensor(75.0060, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 68\n",
            "Train Pass Completed\n",
            "\tEpoch 68 \tAverage Loss:  226.9535439828726 \tReconstruction Loss: 152.0096876496535 \tKL Loss: tensor(74.9439, device='cuda:0', grad_fn=<DivBackward0>)\n",
            "Starting epoch 69\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-16-71b579516d2e>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mepochs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m100\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m obtained_train_overall_loss, obtained_train_recons_loss, obtained_train_kl_loss = train_conv(conv_vae, train_dataloader,\n\u001b[0;32m---> 15\u001b[0;31m                                                                                         epochs , save_name )\n\u001b[0m",
            "\u001b[0;32m<ipython-input-15-23fb14f7fa1e>\u001b[0m in \u001b[0;36mtrain_conv\u001b[0;34m(model, train_loader, num_epochs, save_name)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     31\u001b[0m             \u001b[0;31m# Backward and optimize\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 32\u001b[0;31m             \u001b[0mloss\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     33\u001b[0m             \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     34\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/_tensor.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    361\u001b[0m                 \u001b[0mcreate_graph\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    362\u001b[0m                 inputs=inputs)\n\u001b[0;32m--> 363\u001b[0;31m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mautograd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgradient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    364\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    365\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mregister_hook\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mhook\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.7/dist-packages/torch/autograd/__init__.py\u001b[0m in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    173\u001b[0m     Variable._execution_engine.run_backward(  # Calls into the C++ engine to run the backward pass\n\u001b[1;32m    174\u001b[0m         \u001b[0mtensors\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mgrad_tensors_\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mretain_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcreate_graph\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 175\u001b[0;31m         allow_unreachable=True, accumulate_grad=True)  # Calls into the C++ engine to run the backward pass\n\u001b[0m\u001b[1;32m    176\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    177\u001b[0m def grad(\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "SQJOrisezcGX"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ISCt8wMyzeqN"
      },
      "source": [
        "# Inspection, Validation, and Analysis"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "SFkAlLvZzeqN"
      },
      "outputs": [],
      "source": [
        "# Inspect, validate, and analyse your trained model"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "name": "assignment_4_skeleton (1).ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "interpreter": {
      "hash": "93aa0139fa57dda094a7ddd49a7a44ee21342a7ee37e3f7e1205953a77a5c532"
    },
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.12"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "nbformat": 4,
  "nbformat_minor": 0
}