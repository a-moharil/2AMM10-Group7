{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {
    "id": "730fd591"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {
    "id": "d32f8d18"
   },
   "source": [
    "# Group Number: 7\n",
    "\n",
    "# Student 1: Ambarish Moharil (1704818)\n",
    "\n",
    "# Student 2: Kunal Geed (1736051)\n",
    "\n",
    "# Student 3: Mert Lostar (1668846)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {
    "id": "faec2056"
   },
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "7d0580a5",
   "metadata": {
    "id": "7d0580a5"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io\n",
    "import torch_geometric\n",
    "from torch import nn\n",
    "from torch_geometric.nn import SAGEConv\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0756591",
   "metadata": {
    "id": "b0756591"
   },
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bb77a4be",
   "metadata": {
    "id": "bb77a4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training data:\n",
      "\n",
      "positions: (10000, 4, 2, 5)\n",
      "velocities: (10000, 1, 2, 5)\n",
      "charges: (10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "1c3ea4cb",
   "metadata": {
    "id": "1c3ea4cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of retrieving data from the arrays:\n",
      "\n",
      "\n",
      "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
      "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
     ]
    }
   ],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 42\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "10a3438a",
   "metadata": {
    "id": "10a3438a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "10000 train, 2000 validation, 2000 test simulations\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f9106543",
   "metadata": {
    "id": "f9106543"
   },
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d28681a6",
   "metadata": {
    "id": "d28681a6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {
    "id": "059b633c"
   },
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "e6ecb529",
   "metadata": {
    "id": "e6ecb529"
   },
   "outputs": [],
   "source": [
    "\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "f8633eb8",
   "metadata": {
    "id": "f8633eb8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DatasetClass(Dataset):\n",
    "    def __init__(self, positions, velocities,charges):\n",
    "        \n",
    "        (samples,seq_length,dim,length) = positions.shape\n",
    "        # Get the initial positions\n",
    "        init_pos = positions[:,0,:,:]\n",
    "        init_pos = init_pos.reshape(samples,dim*length) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the initial velocities\n",
    "        init_vel = velocities.reshape(samples,dim*length) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the charges\n",
    "        c = charges.reshape(samples,length) # Flatten (samples,1,length) -> (samples,length)\n",
    "        # Create the feature array using initial state\n",
    "        features = np.concatenate((init_pos,init_vel,c),axis=1) # Concatenate initial information to a feature array\n",
    "        \n",
    "        #Create targets using positions in timesteps after the initial one and flattening the dimensions to a single list\n",
    "        targets = positions[:,1:,:,:].reshape(samples,seq_length - 1, dim*length)\n",
    "        \n",
    "        self.data = torch.FloatTensor(features)\n",
    "        print(self.data.shape)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        # Sanity checks\n",
    "        assert features.shape == (samples,dim*length*2 + length)\n",
    "        assert targets.shape == (samples,seq_length - 1, dim*length)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "0a99a32b",
   "metadata": {
    "id": "0a99a32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 25])\n",
      "torch.Size([2000, 25])\n",
      "torch.Size([2000, 25])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DatasetClass(positions_train,velocities_train,charges_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10)\n",
    "valid_dataset = DatasetClass(positions_valid, velocities_valid, charges_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=10)\n",
    "test_dataset = DatasetClass(positions_test, velocities_test, charges_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "01d3588e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 2)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(samples,seq_length,dim,length) = positions_train.shape\n",
    "init_positions = positions_train[:,0,:,:]\n",
    "init_positions = init_positions.reshape(samples,length, dim)\n",
    "init_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "9ca765d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "t1 = torch.rand(n, n)\n",
    "t1 = t1 * (torch.ones(n, n) - torch.eye(n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "6ee6a40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.2183, 0.7634, 0.0076, 0.6395],\n",
       "        [0.2335, 0.0000, 0.8388, 0.3060, 0.3509],\n",
       "        [0.8152, 0.1336, 0.0000, 0.5929, 0.4005],\n",
       "        [0.5476, 0.5776, 0.9921, 0.0000, 0.6922],\n",
       "        [0.8126, 0.5285, 0.3750, 0.9462, 0.0000]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "a8c86992",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "def create_graphset(positions, velocities,charges,t_horizons,batch_size = 20):\n",
    "        (samples,seq_length,dim,length) = positions.shape\n",
    "        # Get the initial positions\n",
    "        init_pos = positions[:,0,:,:]\n",
    "        init_pos = init_pos.reshape(samples,length,dim) # (Samples,n,2)\n",
    "        # Get the initial velocities\n",
    "        init_vel = velocities.reshape(samples,length,dim) # (Samples,n,2)\n",
    "        # Get the charges\n",
    "        c = charges.reshape(samples,length,1) # Reshape (samples,length) -> (samples,length,1) for compatibility\n",
    "        src = []\n",
    "        tgt = []\n",
    "        for i in range(length):\n",
    "           for j in range(length):\n",
    "              src.append(i)\n",
    "              tgt.append(j)\n",
    "            \n",
    "        # Same generic edge index for every simulation\n",
    "        edge_index = torch.LongTensor([src,tgt])\n",
    "        features_array = []\n",
    "        data = []\n",
    "        batches = []\n",
    "        batch_counter = 0\n",
    "        target_ids = np.random.choice(np.arange(1,len(t_horizons)+1),size=samples)\n",
    "        target_values = np.array([t_horizons[target_id-1] for target_id in target_ids]).reshape(samples,1,1)\n",
    "        target_values = np.broadcast_to(target_values,(samples,length,1))\n",
    "        targets = np.array([positions[idx,target_ids[idx],:,:] for idx in range(len(target_ids))]).reshape(samples,length,dim)\n",
    "        features = np.concatenate((init_pos,init_vel,c,target_values),axis=2) # Concatenate initial information to a feature array\n",
    "        \n",
    "            \n",
    "        # Create the feature array using initial state\n",
    "        print(features.shape)\n",
    "        print(targets.shape)\n",
    "        #features,targets = unison_shuffled_copies(features,targets)\n",
    "        features = torch.FloatTensor(features)\n",
    "        for sim_id in range(features.shape[0]):\n",
    "            data.append(torch_geometric.data.Data(x=features[sim_id],edge_index=edge_index,num_nodes = features.shape[1]))\n",
    "            batch_counter+=1\n",
    "            if batch_counter == batch_size:\n",
    "                batch = torch_geometric.data.Batch.from_data_list(data)\n",
    "                batches.append(batch)\n",
    "                data = []\n",
    "                batch_counter = 0\n",
    "        #Create targets using positions in timesteps after the initial one and flattening the dimensions to a single list\n",
    "        \n",
    "        #data = torch.FloatTensor(features)\n",
    "        targets = torch.FloatTensor(targets.reshape(len(batches),length*batch_size,dim))\n",
    "        return batches,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "267a83d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(10000, 5, 6)\n",
      "(10000, 5, 2)\n",
      "(2000, 5, 6)\n",
      "(2000, 5, 2)\n",
      "(2000, 5, 6)\n",
      "(2000, 5, 2)\n"
     ]
    }
   ],
   "source": [
    "graph_train_data,graph_train_targets = create_graphset(positions_train,velocities_train,charges_train,[0.5,1,1.5])\n",
    "graph_valid_data,graph_valid_targets = create_graphset(positions_valid,velocities_valid,charges_valid,[0.5,1,1.5])\n",
    "graph_test_data,graph_test_targets = create_graphset(positions_test,velocities_test,charges_test,[0.5,1,1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {
    "id": "18b2874d"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "ba598378",
   "metadata": {
    "id": "ba598378"
   },
   "outputs": [],
   "source": [
    "# This is our previous approach using LSTMS which we chose not to report \n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.rnn = nn.LSTMCell(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "\n",
    "    def forward(self, batch_input):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, seq_length, input_shape]\n",
    "        \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        c0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        hidden1, c1 = self.rnn(batch_input,(hidden0,c0))\n",
    "        hidden2, c2 = self.rnn(batch_input,(hidden1,c1)) # Feed same input to all for now\n",
    "        hidden3, c3 = self.rnn(batch_input,(hidden2,c2)) # Feed same input to all for now\n",
    "        \n",
    "        \n",
    "        # retrieve final hidden output of last timestep for each sequence\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        #last_timestep = out[:,-1]\n",
    "        \n",
    "        # apply dropout\n",
    "        #self.drop(last_timestep)\n",
    "        \n",
    "        # feed lstm output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        h1 = nn.ReLU()(self.fc1(hidden1))\n",
    "        output1 = self.fc2(h1)\n",
    "        h2 = nn.ReLU()(self.fc1(hidden2))\n",
    "        output2 = self.fc2(h2)\n",
    "        h3 = nn.ReLU()(self.fc1(hidden3))\n",
    "        output3 = self.fc2(h3)\n",
    "        #h = nn.ReLU()(h)\n",
    "        \n",
    "        y_preds = torch.stack((output1,output2,output3),axis=1) # (Batch_size,3,dim * length)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "95154df7",
   "metadata": {
    "id": "95154df7"
   },
   "outputs": [],
   "source": [
    "\n",
    "class LSTMRegressorFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(LSTMRegressorFeedForward, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.rnn = nn.LSTMCell(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "\n",
    "    def forward(self, batch_input):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, seq_length, input_shape]\n",
    "        \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        c0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        hidden1, c1 = self.rnn(batch_input,(hidden0,c0))\n",
    "        h1 = nn.ReLU()(self.fc1(hidden1))\n",
    "        output1 = self.fc2(h1)\n",
    "        \n",
    "        avg_velocities = (output1 - batch_input[:,:10]) / 0.5\n",
    "        batch_input2 = torch.cat((output1,avg_velocities,batch_input[:,-5:]),axis=1)\n",
    "        hidden2, c2 = self.rnn(batch_input2,(hidden1,c1)) # Feed same input to all for now\n",
    "        h2 = nn.ReLU()(self.fc1(hidden2))\n",
    "        output2 = self.fc2(h2)\n",
    "        \n",
    "        avg_velocities2 = (output2 - batch_input2[:,:10]) / 0.5\n",
    "        batch_input3 = torch.cat((output2,avg_velocities2,batch_input2[:,-5:]),axis=1)\n",
    "        hidden3, c3 = self.rnn(batch_input3,(hidden2,c2)) # Feed same input to all for now\n",
    "        h3 = nn.ReLU()(self.fc1(hidden3))\n",
    "        output3 = self.fc2(h3)\n",
    "        \n",
    "        \n",
    "        # retrieve final hidden output of last timestep for each sequence\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        #last_timestep = out[:,-1]\n",
    "        \n",
    "        # apply dropout\n",
    "        #self.drop(last_timestep)\n",
    "        \n",
    "        # feed lstm output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        \n",
    "        #h = nn.ReLU()(h)\n",
    "        \n",
    "        y_preds = torch.stack((output1,output2,output3),axis=1) # (Batch_size,3,dim * length)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "713e5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class PhysicsSAGE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(PhysicsSAGE, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.sage = SAGEConv(in_channels=input_dim,\n",
    "                       out_channels=hidden_dim)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc2 = nn.Linear(hidden_dim//2, output_dim)\n",
    "        \n",
    "    def forward(self, batch_data,batch_edge_index):\n",
    "        \n",
    "        embedding = self.sage(batch_data,batch_edge_index)\n",
    "        embedding = self.drop(embedding)\n",
    "        h1 = nn.ReLU()(self.fc1(embedding))\n",
    "        #h1 = self.drop(h1)\n",
    "        output = self.fc2(h1)\n",
    "        \n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {
    "id": "dea70d73"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3af520ae",
   "metadata": {
    "id": "3af520ae"
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(path, model, optimizer, val_loss, val_acc, train_acc, train_loss ):\n",
    "    if path == None:\n",
    "        return print(\"Kindly define a path\")\n",
    "    path = path\n",
    "    \n",
    "    save_dict = {\"model_dict\" : model.state_dict(), \n",
    "                 \"optimizer_dict\": optimizer.state_dict(),\n",
    "                 \"val_loss_dict\": val_loss,\n",
    "                 \"val_acc_dict\": val_acc,\n",
    "                 \"train_acc_dict\": train_acc,\n",
    "                 \"train_loss_dict\": train_loss}\n",
    "    torch.save(save_dict, path)\n",
    "    return print(\"Model Saved to ==> {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e95af5f9",
   "metadata": {
    "id": "e95af5f9"
   },
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train(model, train_loader, val_loader, criterion, num_epochs, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    cur_step = 0\n",
    "    train_pred = []\n",
    "    val_pred = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "  \n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for train_data, targets in train_loader:\n",
    "            \n",
    "           \n",
    "            # Forward\n",
    "            input_tensor = train_data.to(device)\n",
    "            outputs = model.forward(input_tensor)\n",
    "            loss = criterion(outputs,targets.to(device))\n",
    "            \n",
    "                \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            running_loss += loss\n",
    "          \n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(\"Train Pass Completed\")\n",
    "\n",
    "        ########################################|Validation Set|#############################################\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for val_data, val_targets in val_loader:\n",
    "                input_tensor = val_data.to(device)\n",
    "                outputs = model.forward(input_tensor)\n",
    "                loss = criterion(outputs,val_targets.to(device))\n",
    "                val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}' \n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss \n",
    "            save_model_checkpoint(save_name, model, optimizer, best_val_loss, 0, 0, avg_train_loss )\n",
    "    \n",
    "    print(\"Finished Training\") \n",
    "    return train_losses, val_losses\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train_graph(model, train_data,train_targets,\n",
    "                val_data,val_targets,\n",
    "                criterion, num_epochs, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    cur_step = 0\n",
    "    train_pred = []\n",
    "    val_pred = []\n",
    "\n",
    "                              \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        running_loss = 0.0\n",
    "        for batch_idx,batch in enumerate(train_data):\n",
    "            # Forward\n",
    "            outputs = model.forward(batch.x.to(device),\n",
    "                                   batch.edge_index.to(device))\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs,train_targets[batch_idx].to(device))\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            running_loss += loss\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_data)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(\"Train Pass Completed\")\n",
    "\n",
    "        ########################################|Validation Set|#############################################\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch_idx,batch in enumerate(val_data):\n",
    "                outputs = model.forward(batch.x.to(device),\n",
    "                                   batch.edge_index.to(device))\n",
    "                loss = criterion(outputs,val_targets[batch_idx].to(device))\n",
    "                val_running_loss += loss\n",
    "\n",
    "            avg_val_loss = val_running_loss / len(val_data)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}' \n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss \n",
    "            save_model_checkpoint(save_name, model, optimizer, best_val_loss, 0, 0, avg_train_loss )\n",
    "    \n",
    "    print(\"Finished Training\") \n",
    "    return train_losses, val_losses\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sage = PhysicsSAGE(6,192,2,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(p_sage.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'p_sage_t=all.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss_psage, obtained_val_loss_psage = train_graph(p_sage, \n",
    "                                                      graph_train_data,graph_train_targets,\n",
    "                                                      graph_valid_data,graph_valid_targets,                                  \n",
    "                                                      criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07e03ddf",
   "metadata": {
    "id": "07e03ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/100],Train Loss: 1.7338, Valid Loss: 0.56551653\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/100],Train Loss: 0.5043, Valid Loss: 0.43483043\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/100],Train Loss: 0.4045, Valid Loss: 0.38587406\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/100],Train Loss: 0.3471, Valid Loss: 0.34214899\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/100],Train Loss: 0.3065, Valid Loss: 0.31607971\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/100],Train Loss: 0.2791, Valid Loss: 0.29593742\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/100],Train Loss: 0.2561, Valid Loss: 0.27490342\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/100],Train Loss: 0.2387, Valid Loss: 0.25953364\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/100],Train Loss: 0.2241, Valid Loss: 0.25022793\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/100],Train Loss: 0.2130, Valid Loss: 0.24167404\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/100],Train Loss: 0.2028, Valid Loss: 0.23520391\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/100],Train Loss: 0.1953, Valid Loss: 0.22716445\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/100],Train Loss: 0.1880, Valid Loss: 0.22278243\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 14\n",
      "Train Pass Completed\n",
      "Epoch [14/100],Train Loss: 0.1821, Valid Loss: 0.21806754\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 15\n",
      "Train Pass Completed\n",
      "Epoch [15/100],Train Loss: 0.1768, Valid Loss: 0.21328804\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 16\n",
      "Train Pass Completed\n",
      "Epoch [16/100],Train Loss: 0.1726, Valid Loss: 0.20971148\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 17\n",
      "Train Pass Completed\n",
      "Epoch [17/100],Train Loss: 0.1690, Valid Loss: 0.20892118\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 18\n",
      "Train Pass Completed\n",
      "Epoch [18/100],Train Loss: 0.1644, Valid Loss: 0.20750563\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 19\n",
      "Train Pass Completed\n",
      "Epoch [19/100],Train Loss: 0.1616, Valid Loss: 0.20314725\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 20\n",
      "Train Pass Completed\n",
      "Epoch [20/100],Train Loss: 0.1589, Valid Loss: 0.19981550\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 21\n",
      "Train Pass Completed\n",
      "Epoch [21/100],Train Loss: 0.1564, Valid Loss: 0.19923854\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 22\n",
      "Train Pass Completed\n",
      "Epoch [22/100],Train Loss: 0.1536, Valid Loss: 0.19516559\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 23\n",
      "Train Pass Completed\n",
      "Epoch [23/100],Train Loss: 0.1507, Valid Loss: 0.19479044\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 24\n",
      "Train Pass Completed\n",
      "Epoch [24/100],Train Loss: 0.1479, Valid Loss: 0.19317694\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 25\n",
      "Train Pass Completed\n",
      "Epoch [25/100],Train Loss: 0.1461, Valid Loss: 0.19157873\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 26\n",
      "Train Pass Completed\n",
      "Epoch [26/100],Train Loss: 0.1438, Valid Loss: 0.19076639\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 27\n",
      "Train Pass Completed\n",
      "Epoch [27/100],Train Loss: 0.1424, Valid Loss: 0.19026613\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 28\n",
      "Train Pass Completed\n",
      "Epoch [28/100],Train Loss: 0.1402, Valid Loss: 0.19011910\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 29\n",
      "Train Pass Completed\n",
      "Epoch [29/100],Train Loss: 0.1387, Valid Loss: 0.18851508\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 30\n",
      "Train Pass Completed\n",
      "Epoch [30/100],Train Loss: 0.1368, Valid Loss: 0.18670960\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 31\n",
      "Train Pass Completed\n",
      "Epoch [31/100],Train Loss: 0.1352, Valid Loss: 0.18542884\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 32\n",
      "Train Pass Completed\n",
      "Epoch [32/100],Train Loss: 0.1338, Valid Loss: 0.18553375\n",
      "Starting epoch 33\n",
      "Train Pass Completed\n",
      "Epoch [33/100],Train Loss: 0.1323, Valid Loss: 0.18215495\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 34\n",
      "Train Pass Completed\n",
      "Epoch [34/100],Train Loss: 0.1307, Valid Loss: 0.18189643\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 35\n",
      "Train Pass Completed\n",
      "Epoch [35/100],Train Loss: 0.1294, Valid Loss: 0.18038872\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 36\n",
      "Train Pass Completed\n",
      "Epoch [36/100],Train Loss: 0.1279, Valid Loss: 0.18228132\n",
      "Starting epoch 37\n",
      "Train Pass Completed\n",
      "Epoch [37/100],Train Loss: 0.1271, Valid Loss: 0.18023035\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 38\n",
      "Train Pass Completed\n",
      "Epoch [38/100],Train Loss: 0.1254, Valid Loss: 0.17877075\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 39\n",
      "Train Pass Completed\n",
      "Epoch [39/100],Train Loss: 0.1244, Valid Loss: 0.17659397\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 40\n",
      "Train Pass Completed\n",
      "Epoch [40/100],Train Loss: 0.1237, Valid Loss: 0.17741169\n",
      "Starting epoch 41\n",
      "Train Pass Completed\n",
      "Epoch [41/100],Train Loss: 0.1220, Valid Loss: 0.17671777\n",
      "Starting epoch 42\n",
      "Train Pass Completed\n",
      "Epoch [42/100],Train Loss: 0.1209, Valid Loss: 0.17559859\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 43\n",
      "Train Pass Completed\n",
      "Epoch [43/100],Train Loss: 0.1203, Valid Loss: 0.17523356\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 44\n",
      "Train Pass Completed\n",
      "Epoch [44/100],Train Loss: 0.1191, Valid Loss: 0.17540579\n",
      "Starting epoch 45\n",
      "Train Pass Completed\n",
      "Epoch [45/100],Train Loss: 0.1179, Valid Loss: 0.17663832\n",
      "Starting epoch 46\n",
      "Train Pass Completed\n",
      "Epoch [46/100],Train Loss: 0.1175, Valid Loss: 0.17312013\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 47\n",
      "Train Pass Completed\n",
      "Epoch [47/100],Train Loss: 0.1165, Valid Loss: 0.17299244\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 48\n",
      "Train Pass Completed\n",
      "Epoch [48/100],Train Loss: 0.1153, Valid Loss: 0.17294982\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 49\n",
      "Train Pass Completed\n",
      "Epoch [49/100],Train Loss: 0.1147, Valid Loss: 0.17057750\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 50\n",
      "Train Pass Completed\n",
      "Epoch [50/100],Train Loss: 0.1138, Valid Loss: 0.17371221\n",
      "Starting epoch 51\n",
      "Train Pass Completed\n",
      "Epoch [51/100],Train Loss: 0.1129, Valid Loss: 0.17151318\n",
      "Starting epoch 52\n",
      "Train Pass Completed\n",
      "Epoch [52/100],Train Loss: 0.1120, Valid Loss: 0.17055109\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 53\n",
      "Train Pass Completed\n",
      "Epoch [53/100],Train Loss: 0.1112, Valid Loss: 0.17048626\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 54\n",
      "Train Pass Completed\n",
      "Epoch [54/100],Train Loss: 0.1108, Valid Loss: 0.17019922\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 55\n",
      "Train Pass Completed\n",
      "Epoch [55/100],Train Loss: 0.1101, Valid Loss: 0.17004302\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 56\n",
      "Train Pass Completed\n",
      "Epoch [56/100],Train Loss: 0.1094, Valid Loss: 0.17086019\n",
      "Starting epoch 57\n",
      "Train Pass Completed\n",
      "Epoch [57/100],Train Loss: 0.1086, Valid Loss: 0.17025092\n",
      "Starting epoch 58\n",
      "Train Pass Completed\n",
      "Epoch [58/100],Train Loss: 0.1078, Valid Loss: 0.16793346\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 59\n",
      "Train Pass Completed\n",
      "Epoch [59/100],Train Loss: 0.1072, Valid Loss: 0.16994213\n",
      "Starting epoch 60\n",
      "Train Pass Completed\n",
      "Epoch [60/100],Train Loss: 0.1066, Valid Loss: 0.16932231\n",
      "Starting epoch 61\n",
      "Train Pass Completed\n",
      "Epoch [61/100],Train Loss: 0.1062, Valid Loss: 0.16855903\n",
      "Starting epoch 62\n",
      "Train Pass Completed\n",
      "Epoch [62/100],Train Loss: 0.1057, Valid Loss: 0.16887183\n",
      "Starting epoch 63\n",
      "Train Pass Completed\n",
      "Epoch [63/100],Train Loss: 0.1049, Valid Loss: 0.16723457\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 64\n",
      "Train Pass Completed\n",
      "Epoch [64/100],Train Loss: 0.1044, Valid Loss: 0.16738532\n",
      "Starting epoch 65\n",
      "Train Pass Completed\n",
      "Epoch [65/100],Train Loss: 0.1040, Valid Loss: 0.16796656\n",
      "Starting epoch 66\n",
      "Train Pass Completed\n",
      "Epoch [66/100],Train Loss: 0.1034, Valid Loss: 0.16712838\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 67\n",
      "Train Pass Completed\n",
      "Epoch [67/100],Train Loss: 0.1027, Valid Loss: 0.16794051\n",
      "Starting epoch 68\n",
      "Train Pass Completed\n",
      "Epoch [68/100],Train Loss: 0.1024, Valid Loss: 0.16786323\n",
      "Starting epoch 69\n",
      "Train Pass Completed\n",
      "Epoch [69/100],Train Loss: 0.1018, Valid Loss: 0.16726047\n",
      "Starting epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass Completed\n",
      "Epoch [70/100],Train Loss: 0.1014, Valid Loss: 0.16614254\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 71\n",
      "Train Pass Completed\n",
      "Epoch [71/100],Train Loss: 0.1010, Valid Loss: 0.16670536\n",
      "Starting epoch 72\n",
      "Train Pass Completed\n",
      "Epoch [72/100],Train Loss: 0.1000, Valid Loss: 0.16573808\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 73\n",
      "Train Pass Completed\n",
      "Epoch [73/100],Train Loss: 0.0997, Valid Loss: 0.16699180\n",
      "Starting epoch 74\n",
      "Train Pass Completed\n",
      "Epoch [74/100],Train Loss: 0.0995, Valid Loss: 0.16705044\n",
      "Starting epoch 75\n",
      "Train Pass Completed\n",
      "Epoch [75/100],Train Loss: 0.0990, Valid Loss: 0.16674715\n",
      "Starting epoch 76\n",
      "Train Pass Completed\n",
      "Epoch [76/100],Train Loss: 0.0985, Valid Loss: 0.16640814\n",
      "Starting epoch 77\n",
      "Train Pass Completed\n",
      "Epoch [77/100],Train Loss: 0.0981, Valid Loss: 0.16520455\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 78\n",
      "Train Pass Completed\n",
      "Epoch [78/100],Train Loss: 0.0977, Valid Loss: 0.16619679\n",
      "Starting epoch 79\n",
      "Train Pass Completed\n",
      "Epoch [79/100],Train Loss: 0.0975, Valid Loss: 0.16597268\n",
      "Starting epoch 80\n",
      "Train Pass Completed\n",
      "Epoch [80/100],Train Loss: 0.0968, Valid Loss: 0.16629563\n",
      "Starting epoch 81\n",
      "Train Pass Completed\n",
      "Epoch [81/100],Train Loss: 0.0962, Valid Loss: 0.16631834\n",
      "Starting epoch 82\n",
      "Train Pass Completed\n",
      "Epoch [82/100],Train Loss: 0.0961, Valid Loss: 0.16554661\n",
      "Starting epoch 83\n",
      "Train Pass Completed\n",
      "Epoch [83/100],Train Loss: 0.0957, Valid Loss: 0.16545688\n",
      "Starting epoch 84\n",
      "Train Pass Completed\n",
      "Epoch [84/100],Train Loss: 0.0956, Valid Loss: 0.16652651\n",
      "Starting epoch 85\n",
      "Train Pass Completed\n",
      "Epoch [85/100],Train Loss: 0.0951, Valid Loss: 0.16511020\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 86\n",
      "Train Pass Completed\n",
      "Epoch [86/100],Train Loss: 0.0946, Valid Loss: 0.16638784\n",
      "Starting epoch 87\n",
      "Train Pass Completed\n",
      "Epoch [87/100],Train Loss: 0.0941, Valid Loss: 0.16572365\n",
      "Starting epoch 88\n",
      "Train Pass Completed\n",
      "Epoch [88/100],Train Loss: 0.0939, Valid Loss: 0.16615134\n",
      "Starting epoch 89\n",
      "Train Pass Completed\n",
      "Epoch [89/100],Train Loss: 0.0935, Valid Loss: 0.16751413\n",
      "Starting epoch 90\n",
      "Train Pass Completed\n",
      "Epoch [90/100],Train Loss: 0.0933, Valid Loss: 0.16674000\n",
      "Starting epoch 91\n",
      "Train Pass Completed\n",
      "Epoch [91/100],Train Loss: 0.0927, Valid Loss: 0.16485965\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 92\n",
      "Train Pass Completed\n",
      "Epoch [92/100],Train Loss: 0.0924, Valid Loss: 0.16706701\n",
      "Starting epoch 93\n",
      "Train Pass Completed\n",
      "Epoch [93/100],Train Loss: 0.0924, Valid Loss: 0.16412306\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 94\n",
      "Train Pass Completed\n",
      "Epoch [94/100],Train Loss: 0.0918, Valid Loss: 0.16595542\n",
      "Starting epoch 95\n",
      "Train Pass Completed\n",
      "Epoch [95/100],Train Loss: 0.0914, Valid Loss: 0.16535644\n",
      "Starting epoch 96\n",
      "Train Pass Completed\n",
      "Epoch [96/100],Train Loss: 0.0909, Valid Loss: 0.16599590\n",
      "Starting epoch 97\n",
      "Train Pass Completed\n",
      "Epoch [97/100],Train Loss: 0.0910, Valid Loss: 0.16663922\n",
      "Starting epoch 98\n",
      "Train Pass Completed\n",
      "Epoch [98/100],Train Loss: 0.0906, Valid Loss: 0.16510227\n",
      "Starting epoch 99\n",
      "Train Pass Completed\n",
      "Epoch [99/100],Train Loss: 0.0902, Valid Loss: 0.16626045\n",
      "Starting epoch 100\n",
      "Train Pass Completed\n",
      "Epoch [100/100],Train Loss: 0.0900, Valid Loss: 0.16604753\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "LSTM_reg = LSTMRegressor(25,192,10,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(LSTM_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'LSTM_reg.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(LSTM_reg, \n",
    "                                                      train_loader, valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15d74560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/100],Train Loss: 2.9493, Valid Loss: 1.29062331\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/100],Train Loss: 1.1049, Valid Loss: 0.92549068\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/100],Train Loss: 0.7987, Valid Loss: 0.68528670\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/100],Train Loss: 0.6311, Valid Loss: 0.58944482\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/100],Train Loss: 0.5417, Valid Loss: 0.52197975\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/100],Train Loss: 0.4797, Valid Loss: 0.48037547\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/100],Train Loss: 0.4292, Valid Loss: 0.43565467\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/100],Train Loss: 0.3978, Valid Loss: 0.41503748\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/100],Train Loss: 0.3722, Valid Loss: 0.40283674\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/100],Train Loss: 0.3507, Valid Loss: 0.37834665\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/100],Train Loss: 0.3321, Valid Loss: 0.36455217\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/100],Train Loss: 0.3183, Valid Loss: 0.34966055\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/100],Train Loss: 0.3086, Valid Loss: 0.34366205\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 14\n",
      "Train Pass Completed\n",
      "Epoch [14/100],Train Loss: 0.2967, Valid Loss: 0.34058064\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 15\n",
      "Train Pass Completed\n",
      "Epoch [15/100],Train Loss: 0.2870, Valid Loss: 0.33346996\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 16\n",
      "Train Pass Completed\n",
      "Epoch [16/100],Train Loss: 0.2785, Valid Loss: 0.33192214\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 17\n",
      "Train Pass Completed\n",
      "Epoch [17/100],Train Loss: 0.2723, Valid Loss: 0.31535167\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 18\n",
      "Train Pass Completed\n",
      "Epoch [18/100],Train Loss: 0.2660, Valid Loss: 0.31408799\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 19\n",
      "Train Pass Completed\n",
      "Epoch [19/100],Train Loss: 0.2607, Valid Loss: 0.31582147\n",
      "Starting epoch 20\n",
      "Train Pass Completed\n",
      "Epoch [20/100],Train Loss: 0.2540, Valid Loss: 0.30499691\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 21\n",
      "Train Pass Completed\n",
      "Epoch [21/100],Train Loss: 0.2512, Valid Loss: 0.29763767\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 22\n",
      "Train Pass Completed\n",
      "Epoch [22/100],Train Loss: 0.2436, Valid Loss: 0.29927057\n",
      "Starting epoch 23\n",
      "Train Pass Completed\n",
      "Epoch [23/100],Train Loss: 0.2394, Valid Loss: 0.29683733\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 24\n",
      "Train Pass Completed\n",
      "Epoch [24/100],Train Loss: 0.2362, Valid Loss: 0.29610604\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 25\n",
      "Train Pass Completed\n",
      "Epoch [25/100],Train Loss: 0.2336, Valid Loss: 0.29498926\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 26\n",
      "Train Pass Completed\n",
      "Epoch [26/100],Train Loss: 0.2313, Valid Loss: 0.28475180\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 27\n",
      "Train Pass Completed\n",
      "Epoch [27/100],Train Loss: 0.2272, Valid Loss: 0.28751436\n",
      "Starting epoch 28\n",
      "Train Pass Completed\n",
      "Epoch [28/100],Train Loss: 0.2259, Valid Loss: 0.28743619\n",
      "Starting epoch 29\n",
      "Train Pass Completed\n",
      "Epoch [29/100],Train Loss: 0.2223, Valid Loss: 0.28567123\n",
      "Starting epoch 30\n",
      "Train Pass Completed\n",
      "Epoch [30/100],Train Loss: 0.2190, Valid Loss: 0.28503561\n",
      "Starting epoch 31\n",
      "Train Pass Completed\n",
      "Epoch [31/100],Train Loss: 0.2158, Valid Loss: 0.27811444\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 32\n",
      "Train Pass Completed\n",
      "Epoch [32/100],Train Loss: 0.2141, Valid Loss: 0.27330038\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 33\n",
      "Train Pass Completed\n",
      "Epoch [33/100],Train Loss: 0.2087, Valid Loss: 0.27348918\n",
      "Starting epoch 34\n",
      "Train Pass Completed\n",
      "Epoch [34/100],Train Loss: 0.2089, Valid Loss: 0.27400443\n",
      "Starting epoch 35\n",
      "Train Pass Completed\n",
      "Epoch [35/100],Train Loss: 0.2064, Valid Loss: 0.27201033\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 36\n",
      "Train Pass Completed\n",
      "Epoch [36/100],Train Loss: 0.2047, Valid Loss: 0.26804864\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 37\n",
      "Train Pass Completed\n",
      "Epoch [37/100],Train Loss: 0.2019, Valid Loss: 0.26925543\n",
      "Starting epoch 38\n",
      "Train Pass Completed\n",
      "Epoch [38/100],Train Loss: 0.1996, Valid Loss: 0.26853362\n",
      "Starting epoch 39\n",
      "Train Pass Completed\n",
      "Epoch [39/100],Train Loss: 0.1981, Valid Loss: 0.26473987\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 40\n",
      "Train Pass Completed\n",
      "Epoch [40/100],Train Loss: 0.1953, Valid Loss: 0.25657952\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 41\n",
      "Train Pass Completed\n",
      "Epoch [41/100],Train Loss: 0.1925, Valid Loss: 0.25961962\n",
      "Starting epoch 42\n",
      "Train Pass Completed\n",
      "Epoch [42/100],Train Loss: 0.1905, Valid Loss: 0.25333253\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 43\n",
      "Train Pass Completed\n",
      "Epoch [43/100],Train Loss: 0.1898, Valid Loss: 0.26035395\n",
      "Starting epoch 44\n",
      "Train Pass Completed\n",
      "Epoch [44/100],Train Loss: 0.1882, Valid Loss: 0.26395831\n",
      "Starting epoch 45\n",
      "Train Pass Completed\n",
      "Epoch [45/100],Train Loss: 0.1867, Valid Loss: 0.25319597\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 46\n",
      "Train Pass Completed\n",
      "Epoch [46/100],Train Loss: 0.1846, Valid Loss: 0.25714317\n",
      "Starting epoch 47\n",
      "Train Pass Completed\n",
      "Epoch [47/100],Train Loss: 0.1824, Valid Loss: 0.25595808\n",
      "Starting epoch 48\n",
      "Train Pass Completed\n",
      "Epoch [48/100],Train Loss: 0.1804, Valid Loss: 0.25282317\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 49\n",
      "Train Pass Completed\n",
      "Epoch [49/100],Train Loss: 0.1802, Valid Loss: 0.24583970\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 50\n",
      "Train Pass Completed\n",
      "Epoch [50/100],Train Loss: 0.1776, Valid Loss: 0.24919814\n",
      "Starting epoch 51\n",
      "Train Pass Completed\n",
      "Epoch [51/100],Train Loss: 0.1770, Valid Loss: 0.24930111\n",
      "Starting epoch 52\n",
      "Train Pass Completed\n",
      "Epoch [52/100],Train Loss: 0.1759, Valid Loss: 0.25439864\n",
      "Starting epoch 53\n",
      "Train Pass Completed\n",
      "Epoch [53/100],Train Loss: 0.1737, Valid Loss: 0.25380909\n",
      "Starting epoch 54\n",
      "Train Pass Completed\n",
      "Epoch [54/100],Train Loss: 0.1719, Valid Loss: 0.24569982\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 55\n",
      "Train Pass Completed\n",
      "Epoch [55/100],Train Loss: 0.1723, Valid Loss: 0.24684644\n",
      "Starting epoch 56\n",
      "Train Pass Completed\n",
      "Epoch [56/100],Train Loss: 0.1702, Valid Loss: 0.24515311\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 57\n",
      "Train Pass Completed\n",
      "Epoch [57/100],Train Loss: 0.1704, Valid Loss: 0.24455579\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 58\n",
      "Train Pass Completed\n",
      "Epoch [58/100],Train Loss: 0.1678, Valid Loss: 0.24116378\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 59\n",
      "Train Pass Completed\n",
      "Epoch [59/100],Train Loss: 0.1672, Valid Loss: 0.24180578\n",
      "Starting epoch 60\n",
      "Train Pass Completed\n",
      "Epoch [60/100],Train Loss: 0.1664, Valid Loss: 0.24226911\n",
      "Starting epoch 61\n",
      "Train Pass Completed\n",
      "Epoch [61/100],Train Loss: 0.1642, Valid Loss: 0.24174155\n",
      "Starting epoch 62\n",
      "Train Pass Completed\n",
      "Epoch [62/100],Train Loss: 0.1638, Valid Loss: 0.24137124\n",
      "Starting epoch 63\n",
      "Train Pass Completed\n",
      "Epoch [63/100],Train Loss: 0.1635, Valid Loss: 0.25235420\n",
      "Starting epoch 64\n",
      "Train Pass Completed\n",
      "Epoch [64/100],Train Loss: 0.1630, Valid Loss: 0.23838997\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 65\n",
      "Train Pass Completed\n",
      "Epoch [65/100],Train Loss: 0.1601, Valid Loss: 0.24036425\n",
      "Starting epoch 66\n",
      "Train Pass Completed\n",
      "Epoch [66/100],Train Loss: 0.1606, Valid Loss: 0.23438631\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 67\n",
      "Train Pass Completed\n",
      "Epoch [67/100],Train Loss: 0.1582, Valid Loss: 0.23792414\n",
      "Starting epoch 68\n",
      "Train Pass Completed\n",
      "Epoch [68/100],Train Loss: 0.1580, Valid Loss: 0.23837689\n",
      "Starting epoch 69\n",
      "Train Pass Completed\n",
      "Epoch [69/100],Train Loss: 0.1557, Valid Loss: 0.23570846\n",
      "Starting epoch 70\n",
      "Train Pass Completed\n",
      "Epoch [70/100],Train Loss: 0.1550, Valid Loss: 0.23686178\n",
      "Starting epoch 71\n",
      "Train Pass Completed\n",
      "Epoch [71/100],Train Loss: 0.1550, Valid Loss: 0.23352066\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass Completed\n",
      "Epoch [72/100],Train Loss: 0.1541, Valid Loss: 0.23342770\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 73\n",
      "Train Pass Completed\n",
      "Epoch [73/100],Train Loss: 0.1524, Valid Loss: 0.23360404\n",
      "Starting epoch 74\n",
      "Train Pass Completed\n",
      "Epoch [74/100],Train Loss: 0.1516, Valid Loss: 0.23012914\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 75\n",
      "Train Pass Completed\n",
      "Epoch [75/100],Train Loss: 0.1514, Valid Loss: 0.23431210\n",
      "Starting epoch 76\n",
      "Train Pass Completed\n",
      "Epoch [76/100],Train Loss: 0.1510, Valid Loss: 0.23052359\n",
      "Starting epoch 77\n",
      "Train Pass Completed\n",
      "Epoch [77/100],Train Loss: 0.1504, Valid Loss: 0.23349459\n",
      "Starting epoch 78\n",
      "Train Pass Completed\n",
      "Epoch [78/100],Train Loss: 0.1488, Valid Loss: 0.23225616\n",
      "Starting epoch 79\n",
      "Train Pass Completed\n",
      "Epoch [79/100],Train Loss: 0.1467, Valid Loss: 0.23099835\n",
      "Starting epoch 80\n",
      "Train Pass Completed\n",
      "Epoch [80/100],Train Loss: 0.1467, Valid Loss: 0.23157686\n",
      "Starting epoch 81\n",
      "Train Pass Completed\n",
      "Epoch [81/100],Train Loss: 0.1461, Valid Loss: 0.22974180\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 82\n",
      "Train Pass Completed\n",
      "Epoch [82/100],Train Loss: 0.1450, Valid Loss: 0.23117775\n",
      "Starting epoch 83\n",
      "Train Pass Completed\n",
      "Epoch [83/100],Train Loss: 0.1446, Valid Loss: 0.22763848\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 84\n",
      "Train Pass Completed\n",
      "Epoch [84/100],Train Loss: 0.1435, Valid Loss: 0.23095949\n",
      "Starting epoch 85\n",
      "Train Pass Completed\n",
      "Epoch [85/100],Train Loss: 0.1440, Valid Loss: 0.22723998\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 86\n",
      "Train Pass Completed\n",
      "Epoch [86/100],Train Loss: 0.1423, Valid Loss: 0.23059779\n",
      "Starting epoch 87\n",
      "Train Pass Completed\n",
      "Epoch [87/100],Train Loss: 0.1413, Valid Loss: 0.22821938\n",
      "Starting epoch 88\n",
      "Train Pass Completed\n",
      "Epoch [88/100],Train Loss: 0.1423, Valid Loss: 0.22272567\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 89\n",
      "Train Pass Completed\n",
      "Epoch [89/100],Train Loss: 0.1408, Valid Loss: 0.22982825\n",
      "Starting epoch 90\n",
      "Train Pass Completed\n",
      "Epoch [90/100],Train Loss: 0.1405, Valid Loss: 0.23373578\n",
      "Starting epoch 91\n",
      "Train Pass Completed\n",
      "Epoch [91/100],Train Loss: 0.1386, Valid Loss: 0.22638546\n",
      "Starting epoch 92\n",
      "Train Pass Completed\n",
      "Epoch [92/100],Train Loss: 0.1387, Valid Loss: 0.22841266\n",
      "Starting epoch 93\n",
      "Train Pass Completed\n",
      "Epoch [93/100],Train Loss: 0.1388, Valid Loss: 0.22377825\n",
      "Starting epoch 94\n",
      "Train Pass Completed\n",
      "Epoch [94/100],Train Loss: 0.1375, Valid Loss: 0.22374986\n",
      "Starting epoch 95\n",
      "Train Pass Completed\n",
      "Epoch [95/100],Train Loss: 0.1363, Valid Loss: 0.22193779\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 96\n",
      "Train Pass Completed\n",
      "Epoch [96/100],Train Loss: 0.1358, Valid Loss: 0.22199100\n",
      "Starting epoch 97\n",
      "Train Pass Completed\n",
      "Epoch [97/100],Train Loss: 0.1357, Valid Loss: 0.22568738\n",
      "Starting epoch 98\n",
      "Train Pass Completed\n",
      "Epoch [98/100],Train Loss: 0.1349, Valid Loss: 0.22563781\n",
      "Starting epoch 99\n",
      "Train Pass Completed\n",
      "Epoch [99/100],Train Loss: 0.1348, Valid Loss: 0.22097562\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 100\n",
      "Train Pass Completed\n",
      "Epoch [100/100],Train Loss: 0.1330, Valid Loss: 0.22106713\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "LSTM_reg_ff = LSTMRegressorFeedForward(25,192,10,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(LSTM_reg_ff.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'LSTM_reg_ff.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(LSTM_reg_ff, \n",
    "                                                      train_loader, valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {
    "id": "d5fb3b29"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf5fa1b4",
   "metadata": {
    "id": "bf5fa1b4"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "# Baseline model\n",
    "def baseline_predictor(inputs,t):\n",
    "    # The same input [samples,25]\n",
    "    initial_pos = inputs[:,10]\n",
    "    initial_vel = inputs[:,10:20]\n",
    "    return initial_pos + initial_vel * t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed4a1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on the validation set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def evaluate(model, test_loader,device='cpu'):\n",
    "    val_running_loss = 0.0\n",
    "    preds = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for val_data, val_targets in test_loader:\n",
    "            input_tensor = val_data.to(device)\n",
    "            outputs = model.forward(input_tensor)\n",
    "            preds.append(outputs)\n",
    "            actual.append(val_targets)\n",
    "            loss = criterion(outputs,val_targets.to(device))\n",
    "            val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(test_loader)\n",
    "        print(\"Average Test Loss: {:4f}\".format(avg_val_loss))\n",
    "        return preds,actual\n",
    "def evaluate_graph(model,test_data,test_targets,device='cpu'):\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_idx,batch in enumerate(test_data):\n",
    "            outputs = model.forward(batch.x.to(device),\n",
    "                               batch.edge_index.to(device))\n",
    "            loss = criterion(outputs,test_targets[batch_idx].to(device))\n",
    "            val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(test_data)\n",
    "        print(\"Average Test Loss: {:4f}\".format(avg_val_loss))\n",
    "        return preds,actual\n",
    "def evaluate_baseline(test_loader):\n",
    "    for seq_id,t in enumerate([0.5,1,1.5]):\n",
    "        test_running_loss = 0\n",
    "        for test_data,test_target in test_loader:\n",
    "            test_data = test_data.numpy()\n",
    "            test_target = test_target.numpy()\n",
    "            predictions = baseline_predictor(test_data,t)\n",
    "            loss = mean_squared_error(test_target[:,seq_id],predictions)\n",
    "            test_running_loss += loss\n",
    "        avg_test_loss = test_running_loss / len(test_loader)\n",
    "        print(\"Average Test Loss for Baseline Predictor(t={}): {}\".format(t,avg_test_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2280031f",
   "metadata": {
    "id": "2280031f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LSTMRegressorFeedForward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_241/1999655844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Model Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMRegressorFeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM_reg_ff.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTMRegressorFeedForward' is not defined"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "model = LSTMRegressorFeedForward(25,192,10,'cpu')\n",
    "checkpoint = torch.load('LSTM_reg_ff.pt', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model_dict'])\n",
    "\n",
    "preds,actual = evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a140730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation trained by sampling t=0.5,1 data tested on sampling from all possible t's\n",
    "model = PhysicsSAGE(6,192,2,'cpu')\n",
    "checkpoint = torch.load('p_sage_t=[0.5,1].pt', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model_dict'])\n",
    "\n",
    "preds,actual = evaluate_graph(model, graph_test_data,graph_test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be48400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation trained by sampling t=0.5,1,1.5 data tested on sampling from all possible t's\n",
    "model = PhysicsSAGE(6,192,2,'cpu')\n",
    "checkpoint = torch.load('p_sage_t=all.pt', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model_dict'])\n",
    "\n",
    "preds,actual = evaluate_graph(model, graph_test_data,graph_test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "658e878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss for Baseline Predictor(t=0.5): 6.7281222403049465\n",
      "Average Test Loss for Baseline Predictor(t=1): 6.916228829622269\n",
      "Average Test Loss for Baseline Predictor(t=1.5): 7.2571910440921785\n"
     ]
    }
   ],
   "source": [
    "evaluate_baseline(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a334b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_positions(preds_sample, actual_sample):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(5):\n",
    "        plt.plot(preds_sample[i],preds_sample[i+5],'o',color=colors[i])\n",
    "        plt.plot(actual_sample[i],actual_sample[i+5],'x',color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a8240f1",
   "metadata": {
    "id": "3a8240f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][0], actual[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2561c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][1], actual[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4666f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][2], actual[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdac092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "a2_skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
