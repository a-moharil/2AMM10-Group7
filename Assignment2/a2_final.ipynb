{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {
    "id": "730fd591"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {
    "id": "d32f8d18"
   },
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {
    "id": "faec2056"
   },
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {
    "id": "7d0580a5"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0756591",
   "metadata": {
    "id": "b0756591"
   },
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {
    "id": "bb77a4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training data:\n",
      "\n",
      "positions: (10000, 4, 2, 5)\n",
      "velocities: (10000, 1, 2, 5)\n",
      "charges: (10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806d69c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = positions_train[:,0,:,:] #initial positions\n",
    "a.reshape(10000,10)\n",
    "np.concatenate((a.reshape(10000,10),velocities_train.reshape(10000,10),charges_train.reshape(10000,5)),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3ea4cb",
   "metadata": {
    "id": "1c3ea4cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of retrieving data from the arrays:\n",
      "\n",
      "\n",
      "In simulation 42 of the training set, particle 3 with charge -1.0 had coordinates [ 2.05159559 -1.46130851].\n",
      "The initial velocity of this particle was [ 0.28402364 -0.24784824].\n"
     ]
    }
   ],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 42\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a3438a",
   "metadata": {
    "id": "10a3438a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "10000 train, 2000 validation, 2000 test simulations\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9106543",
   "metadata": {
    "id": "f9106543"
   },
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28681a6",
   "metadata": {
    "id": "d28681a6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAGbCAYAAACVqdT+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAAtXklEQVR4nO3deXxU1f3/8fchLJEgLhAQWQyuLCEETCAshURQURA3BP1Fy6KNoFa+VquiX5SiVetShFbhq4LYupFSqfu3iAYRvy4JEpElCCoUhEJARSBhC5/fH0OmhC3LTHLvZF7PxyOPZO7MPfczQ+DNuffcc5yZCQAAv6rjdQEAABwLQQUA8DWCCgDgawQVAMDXCCoAgK/V9eKgTZs2tYSEBC8ODQDwqUWLFm0xs/hDt3sSVAkJCcrLy/Pi0AAAn3LOrT3Sdk79AQB8jaACAPgaQQUA8DVPrlEB8N7evXu1fv167dq1y+tSEGViY2PVqlUr1atXr0KvJ6iAKLV+/Xodf/zxSkhIkHPO63IQJcxMW7du1fr169W2bdsK7cOpPyBK7dq1S02aNCGkUKOcc2rSpEmlevIEFRDFCCl4obK/dwQVAMDXCCoAFbZs2TIlJiZq2bJlYWmvZ8+e5b7mhhtu0PLlyyVJDz30UKX3b9SoUdWKq4Bp06bpL3/5iyRp5syZ2rBhQ/C5g+tGaJwXCyempKQYM1MA3lqxYoXat29f4dfv3LlTHTp00Lp169SmTRstW7ZMcXFx1Vjh4Ro1aqQdO3ZU+z5VkZ6erscff1wpKSnVfqza4Ei/f865RWZ22AdIjwpAhYwaNUqbN2+WmWnTpk26/vrrQ26ztLczf/58paena8iQIWrXrp0yMzNV+p/o9PR05eXl6e6771ZxcbGSk5OVmZlZZv8dO3aoX79+6tq1qzp16qTXX3/9mMdds2aN2rVrp+HDhyspKUlDhgxRUVGRJOn9999Xly5d1KlTJ40aNUq7d++WJN19993q0KGDkpKSdMcdd0iSJkyYoMcff1yzZ89WXl6eMjMzlZycrOLi4mDdkvTKK6+oU6dOSkxM1F133VXm/d97773q3Lmz0tLStGnTppA/01rJzGr869xzzzUA3lq+fHmFXzt9+nSLi4szScGvhg0b2vTp00OqIS4uzszMcnJyrHHjxrZu3TorKSmxtLQ0++ijj8zMrG/fvpabm1vm9Yfuv3fvXtu2bZuZmRUWFtoZZ5xh+/fvP+I+ZmbfffedSbKFCxeamdnIkSPtscces+LiYmvVqpWtXLnSzMyuu+46mzRpkm3dutXOPvvsYJs//vijmZndf//99thjjx1W58GPv//+e2vdurVt3rzZ9u7daxkZGTZnzhwzM5Nkb7zxhpmZ/fa3v7UHHnigqh9lxDnS75+kPDtCZtCjAlCucePGaefOnWW2FRUVady4cWE7Rrdu3dSqVSvVqVNHycnJWrNmTYX3NTPdc889SkpKUv/+/fX999+X2ztp3bq1evXqJUm69tprtXDhQq1cuVJt27bV2WefLUkaPny4FixYoMaNGys2NlY33HCDXnvtNTVs2LDCteXm5io9PV3x8fGqW7euMjMztWDBAklS/fr1NWjQIEnSueeeW6n3HE0IKgDlevjhhw+7HtWwYUM98sgjYTtGgwYNgj/HxMRo3759Fd73pZdeUmFhoRYtWqT8/Hw1b9683Pt0Dh0i7ZwLnm48VN26dfX555/ryiuv1D/+8Q8NGDCgwrUdrU1JqlevXrCOyr7naEJQASjXqFGjNHDgQMXGxkoKTIFzySWXaOTIkTVaR7169bR3797Dtm/btk3NmjVTvXr1lJOTo7Vrj7haRBn/+te/9Mknn0gKXEPq3bu32rVrpzVr1mj16tWSpL/+9a/q27evduzYoW3btuniiy/Wk08+qfz8/MPaO/7447V9+/bDtnfv3l0ffvihtmzZopKSEr3yyivq27dvJd95dCOoAFTIjBkz1KxZMznn1Lx5c02fPr3Ga8jKylJSUlJwMEWpzMxM5eXlKSUlRS+99JLatWtXblvt27fXCy+8oKSkJP3www8aM2aMYmNj9fzzz+uqq65Sp06dVKdOHY0ePVrbt2/XoEGDlJSUpL59+2rSpEmHtTdixAiNHj06OJiiVIsWLfTwww8rIyNDnTt3VteuXXXppZeG/mFEEYanA1GqssPTpcB9VMOGDdOsWbPUsWPHaqqs+q1Zs0aDBg3S0qVLvS4lalVmeDqT0gKosI4dO/KPO2ocp/4ARJ2EhAQCN4IQVAAAXyOoAAC+RlABAHyNoAIA+BpBBcAzU6ZMUfv27ZWZmak33ngjpJkuWM6j9mJ4OoByPfroo0pNTVVGRkZwW05OjnJzc3XnnXdWud2nn35a7777rtq2bStJGjx4cMi1VofRo0cHf545c6YSExN16qmnSpKee+45r8qKGvSoAJQrNTVVQ4cOVU5OjqRASA0dOlSpqalVbnP06NH69ttvNXjwYE2aNEkzZ87ULbfcIikwy8Ott96qnj176vTTT9fs2bMlsZxH1DrSlOrV/cUyH4D3KrPMh5nZBx98YE2bNrXx48db06ZN7YMPPgi5htNOO80KCwvNzOz555+3m2++2czMhg8fbkOGDLGSkhJbtmyZnXHGGWbGch61Cct8AAi7jIwMjRkzRg888IDGjBlT5jRgdbjssstUp04ddejQIdgDMZbziEoEFYAKycnJ0dSpUzV+/HhNnTo1eBqwuhy87IcdmJOU5TyiE0EFoFyl16Sys7M1ceJEZWdnl7lmVVNYziM6EVQAypWbm6vs7Ozg6b6MjAxlZ2crNze3RutgOY/oxDIfQJSqyjIfkYblPPyrMst80KMCAPhaWG74dc6tkbRdUomkfUdKRACoaSznUTuEc2aKDDPbEsb2AADg1B8AwN/CFVQmaa5zbpFzLutIL3DOZTnn8pxzeYWFhWE6LACgtgtXUPUys66SLpJ0s3Ouz6EvMLNnzCzFzFLi4+PDdFgAQG0XlqAysw0Hvm+WNEdSt3C0C6B269mzZ7mvOXgZjYceeqjS+4dr+Y+qtnPfffdp3rx5kqQnn3wyOCkuKi7k+6icc3GS6pjZ9gM/vydpopn979H24T4qwHuReB9Vo0aNtGPHjmrfp7raSUhIUF5enpo2bRpyPZGupu+jai5poXPuS0mfS3r7WCEFAKVKeynz589Xenq6hgwZonbt2ikzMzM4d17pMhp33323iouLlZycrMzMzDL7V3b5j7vuuktPP/108PGECRP0xBNPSJIee+wxpaamKikpSffff/9h+5qZfvvb3yoxMVGdOnXSrFmzgs89+uij6tSpkzp37qy7775bUmAmi9mzZ2vKlCnasGGDMjIylJGRoenTp+u2224L7vvss8/qN7/5TaU/w6hwpCnVq/uLZT4A71V2mY/qULo0R05OjjVu3NjWrVtnJSUllpaWZh999JGZlV1W49ClPEofV3b5jy+++ML69OkTfNy+fXtbu3at/fOf/7Rf/epXtn//fispKbGBAwfahx9+WKad2bNnW//+/W3fvn3273//21q3bm0bNmywd955x3r06GE7d+40M7OtW7eaWWDJkr/97W9mVnZZkx07dtjpp59ue/bsMTOzHj162JIlS6r+YUYYlvkAEHG6deumVq1aqU6dOkpOTq7UUhhWyeU/unTpos2bN2vDhg368ssvddJJJ6lNmzaaO3eu5s6dqy5duqhr164qKCjQqlWryuy7cOFCXXPNNYqJiVHz5s3Vt29f5ebmat68eRo5cmRwaZCTTz75mDXHxcXpvPPO01tvvaWCggLt3btXnTp1qvB7jiYsRQ+E0/JHpSapUvOD1mralCNtzZU6VH3J9mhw8LIelV0K4+DlP+rVq6eEhIRyl/8YMmSIZs+erX//+9+6+uqrJQUCb9y4cbrxxhuPup8d5bq+mR22pEh5brjhBj300ENq166dRo4cWal9owk9KiCcmqRKC4cGwkkKfF84NLAdIatXr5727t172PaqLP9x9dVX69VXX9Xs2bM1ZMgQSdKFF16oGTNmBAdNfP/999q8eXOZ/fr06aNZs2appKREhYWFWrBggbp166YLLrhAM2bMCI7q++GHHw475qFLhHTv3l3r1q3Tyy+/rGuuuabiH0SUoUcFhFPzDKl3diCczhojrZoaeNy8elfDjRZZWVlKSkpS165d9dJLLwW3Z2Zm6pJLLlFKSoqSk5MrtPxHx44dtX37drVs2VItWrSQJF1wwQVasWKFevToISkwWOPFF19Us2bNgvtdfvnl+uSTT9S5c2c55/Too4/qlFNO0YABA5Sfn6+UlBTVr19fF1988WHD6bOysnTRRRepRYsWwbW8hg4dqvz8fJ100kkhfz61Fct8ANVhyX3S0gekxPFS0kSvqzmiSByeXhsNGjRIt912m/r16+d1KTWKZT4AL23KCfSkEscHvm+q2VVwERl++uknnX322TruuOOiLqQqi1N/QDiVXpMqPd3XPKPsYx9LT08/bNvQoUN10003qaioSBdffPFhz48YMUIjRozQli1bgtd5Ss2fP7+aKq0dTjzxRH399ddelxER6FEB4bQ1t2wolV6z2lqzS7YDtQnXqIAo5bdrVBMmTFCjRo10xx136L777lOfPn3Uv3//kNrMz8/Xhg0bgr3BN954Q8uXLw/OGuGlcE3tFKpp06apYcOG+uUvf6mZM2fqggsu0KmnnlqpNqoyNVRlrlFx6g+A70yceOQBKCUlJYqJialwO/n5+crLywsG1eDBgzV48OCw1FhbjB49OvjzzJkzlZiYWOmgqm6c+gPgmd///vc655xz1L9/f61cuTK4vXR+PCnwv/WJEyeqd+/e+tvf/qa5c+eqR48e6tq1q6666qpgryQ3N1c9e/ZU586d1a1bN23btk333XefZs2apeTkZM2aNUszZ87ULbfcIklau3at+vXrp6SkJPXr10//+te/gse+9dZb1bNnT51++unBOg512WWX6dxzz1XHjh31zDPPBLc3atRI9957rzp37qy0tLTgDBnfffedevToodTUVI0fP/6Iba5Zs0bt2rXTDTfcoMTERGVmZmrevHnq1auXzjrrLH3++eeSpM8//1w9e/ZUly5d1LNnz+BnV1RUpKFDhyopKUnDhg1T9+7dVXr26mh1TZgwQY8//rhmz56tvLw8ZWZmKjk5WcXFxUpISNCWLYGF2/Py8oLXMbdu3aoLLrhAXbp00Y033ljmJugXX3xR3bp1U3Jysm688UaVlJRU6HfhWAgqAJ5YtGiRXn31VS1evFivvfaacnOPfh0vNjZWCxcuVP/+/fXggw9q3rx5+uKLL5SSkqI//vGP2rNnj4YNG6bJkyfryy+/1Lx58xQXF6eJEydq2LBhys/P17Bhw8q0ecstt+iXv/yllixZoszMTN16663B5zZu3KiFCxfqrbfeOuppwhkzZmjRokXKy8vTlClTtHXrVknSzp07lZaWpi+//FJ9+vTRs88+K0kaO3asxowZo9zcXJ1yyilHfa+rV6/W2LFjtWTJEhUUFOjll1/WwoUL9fjjjwfvy2rXrp0WLFigxYsXa+LEibrnnnskSU8//bROOukkLVmyROPHj9eiRYuC7R6trlJDhgxRSkqKXnrpJeXn5+u44447ao2/+93v1Lt3by1evFiDBw8OhvyKFSs0a9Ysffzxx8rPz1dMTEyZ+92qilN/ADzx0Ucf6fLLLw/OjXesU3KlIfPpp59q+fLl6tWrlyRpz5496tGjh1auXKkWLVooNTUwA0jjxo3LPf4nn3yi1157TZJ03XXX6c47/zPF1WWXXaY6deqoQ4cOR50zcMqUKZozZ44kad26dVq1apWaNGmi+vXra9CgQZKkc889V++9954k6eOPP9bf//734PHuuuuuI7bbtm3b4Jx/HTt2VL9+/eScU6dOnYLzH27btk3Dhw/XqlWr5JwLztaxcOFCjR07VpKUmJiopKSkYLtHq6sqFixYEPzsBg4cGLxZ+f3339eiRYuCfw7FxcVlbpauKoIKCIfcm6VTzpdaX+Z1JRGlonPjxcXFSQrMp3f++efrlVdeKfP8kiVLKj3P3rFqOXjewSMNOJs/f77mzZunTz75RA0bNlR6enpwbsF69eoF2zp0zsKK1HjwsevUqRN8XKdOnWBb48ePV0ZGhubMmaM1a9YET8kda3Dcseo6mrp162r//v2SdNjciUd6L2am4cOH6+GHHy637crg1B8Qqh8WSauelnas9rqSiNKnTx/NmTNHxcXF2r59u958881y90lLS9PHH3+s1asDn3VRUZG+/vprtWvXThs2bAiePty+fbv27dt32Nx6B+vZs6deffVVSYFJbXv37l3h2rdt26aTTjpJDRs2VEFBgT799NNy9+nVq1eZ44Vi27ZtatmypaTAAIhSvXv3VnZ2tiRp+fLl+uqrryrV7qGfV0JCQvD0YWlvUAr82ZW+h3fffVc//vijJKlfv36aPXt2cH7EH374oULzLpaHoAJCtfwxqV5j6cwsryuJKF27dtWwYcOUnJysK6+8Ur/4xS/K3Sc+Pl4zZ87UNddco6SkJKWlpamgoED169fXrFmz9Otf/1qdO3fW+eefr127dikjI0PLly8PDqY42JQpU/T8888rKSlJf/3rXzV58uQK1z5gwADt27dPSUlJGj9+vNLS0srdZ/LkyXrqqaeUmpqqbdu2VfhYR3LnnXdq3Lhx6tWrV5nBCjfddJMKCwuVlJSkP/zhD0pKStIJJ5xQ4XZHjBih0aNHBwdT3H///Ro7dqx+8YtflBltef/992vBggXq2rWr5s6dqzZt2kiSOnTooAcffFAXXHCBkpKSdP7552vjxo0hvVeJ+6iA0Oz4VnrzLKndHVKXP3hdTaX47T4qhK6kpER79+5VbGysvvnmG/Xr109ff/216tev73Vph+E+KqCmFEySXIx0zlivKwFUVFSkjIwM7d27V2amqVOn+jKkKougAkLRtJfUoJnU0F83SCI6HX/88aqNZ6sIKiAUCVd7XUFIqrIqLRCqyl5yYjAFUBX7iqSCJ6W9P3tdSZXFxsZq69atlf5HAwiFmWnr1q2KjY2t8D70qICq+O4F6YvbpJO7Ss36eF1NlbRq1Urr169XYWGh16UgysTGxqpVq1YVfj1BBVTGT8sC60vt+1lq0l2KL39ItV/Vq1dPbdu29boMoFwEFVBR+3ZK8y+WigLzmin5EYnrO0C14xoVUFGfjpJ2lc775qR1r3taDhAtCCqgIr6ZIX3/trR/94ENJm14O7AdQLUiqICKyB8nlewsu62kKLAdQLUiqICKSH5Yiokruy2mYeA6FYBqRVABFXHGKKnlQCnmwL0fdWKllpdIZ4z0ti4gChBUQEWlzQhMlyQnHddcSpvudUVAVCCogIqqGyelvyOd0EHq+3bgMYBqx31UQGWc2FEauNTrKoCoQo8KAOBrBBUAwNcIKgCArxFUAABfI6gAAL5GUAEAfI2gAgD4WtiCyjkX45xb7Jx7K1xtAgAQzh7VWEkrwtgeAADhCSrnXCtJAyU9F472AAAoFa4e1ZOS7pS0/2gvcM5lOefynHN5hYWFYTosAKC2CzmonHODJG02s0XHep2ZPWNmKWaWEh8fH+phAQBRIhw9ql6SBjvn1kh6VdJ5zrkXw9AuAAChB5WZjTOzVmaWIOlqSR+Y2bUhVwYAgLiPCgDgc2Fdj8rM5kuaH842AQDRjR4VAMDXCCoAgK8RVAAAXyOoAAC+RlABAHyNoAIA+BpBBQDwNYIKAOBrBBUAwNcIKgCArxFUAABfI6gAAL5GUAEAfI2gAgD4GkEFAPA1ggoA4GsEFQDA1wgqAICvEVQAAF8jqAAAvkZQAQB8jaACAPgaQQUA8DWCCgDgawQVAMDXCCoAgK8RVAAAXyOoAAC+RlABAHyNoAIA+BpBBQDwNYIKAOBrBBUAwNcIKgCArxFUAABfI6gAAL5GUAEAfI2gAgD4WshB5ZyLdc597pz70jm3zDn3u3AUBgCAJNUNQxu7JZ1nZjucc/UkLXTOvWtmn4ahbQBAlAs5qMzMJO048LDegS8LtV0AAKQwXaNyzsU45/IlbZb0npl9doTXZDnn8pxzeYWFheE4LAAgCoQlqMysxMySJbWS1M05l3iE1zxjZilmlhIfHx+OwwIAokBYR/2Z2U+S5ksaEM52AQDRKxyj/uKdcyce+Pk4Sf0lFYTaLgAAUnhG/bWQ9IJzLkaB4Ms2s7fC0C4AAGEZ9bdEUpcw1AIAwGGYmQIA4GsEFQDA1wgqAICvEVTwheXTp2vTZ2XvE9/02WdaPn26RxUB8AuCCr7QJDFRC2+/PRhWmz77TAtvv11NEg+7dxxAlAnH8HQgZM27d1fvJ57Qwttv11nDhmnVrFnq/cQTat69u9elAfAYPSr4RvPu3XXWsGFaOm2azho2jJACIImggo9s+uwzrZo1S4mjR2vVrFmHXbMCEJ049Yca9ejHjyr11FRltM0Ibsv5LkdLPnhDrZ7PDZ7ua96tmxbefjun/wDQo0LNSj01VUNnD1XOdzmSAiE1dPZQnf7DcWVCqfSa1dalS70sF4APuMC6hzUrJSXF8vLyavy48IfScBqTMkZT86Yqe0h2mR4WgOjknFtkZimHbqdHhRqX0TZDY1LG6IEFD2hMyhhCCsAxEVSocTnf5Whq3lSN7zNeU/OmBk8DAsCREFSoUaWn/bKHZGtixkRlD8kuc80KAA5FUKFG5W7ILXNNKqNthrKHZCt3Q67HlQHwKwZTAAB8gcEUAICIRFABAHyNoELU2Llxo+YNH66f1671uhQAlcAUSogKu378UTlZWSrevFklRUVelwOgEuhRoVzf/fid1v+83usyqmzvzp2aP3q0dn7/vfo+9ZROat/e65IAVAJBhXLd+8G9aju5ra6bc52+2PiF1+VU2o8FBfr522/V64kn1CzlsAFFAHyO4eko13c/fqcpn03Rc4uf0449O5SekK4/XfQnJTaLnNV3d//0kxqceKLXZQA4Boano8rantRWkwZM0vrb1uux8x/T2p/WqnGDxpKktT+tVdFe/13zMTPlTpyob157TZIIKSCCEVSosBNiT9AdPe/Q6ltXq80JbSRJWW9lqfWk1vrvD/5bG7dv9LjC//hy8mStmjVLO9at87oUACEiqFBpddx/fm3G9xmvvqf11UMfPaTTnjxNI/4xQl9t+srD6qQVM2dq+bPP6syrrlLSrbd6WguA0DE8HSHp3aa3erfprdU/rNbkTydrRv4MtW/aXp2ad1LJ/hI558oEW3X7ds4cLX7sMbW58EKljB8v51yNHRtA9aBHhbA48+Qz9aeL/6R1t63TTak3SZJeXfqqEp9O1LOLnlXx3uIaqaN4yxad0rOnejzyiOrExNTIMQFUL4IKYXXycSfr+AbHS5KaNGyi2LqxynorS22ebKP7c+7Xph2bquW4+/fulSR1/NWvlD51qmLq16+W4wCoeQQVqs2AMwdoUdYi5QzPUY9WPTRxwUQNfHlg2I/zw4oVenPgQG39KnBtrE5dzmgDtQl/o1GtnHNKT0hXekK6Vm5ZqS1FWyRJ23dv1/B/DNfolNE6//Tzq3wt6ec1a5STlaWYBg10XHx8OEsH4BP0qFBjzml6jnq16SVJWrFlhT5Z/4kufPFCdZraSTMWz9Dufbsr1V7Rpk3K+dWvJEnnPfecGp5ySthrBuA9ggqe6Naym9aMXaOZl85UTJ0YXf/G9TrtydNUuLPwiK9ftnmZEp9O1LLNyyRJe7ZtU05WlnZv26aMadPUOCGhBqsHUJMIKnimQd0GGp48XPk35mvedfM0InmE4uMCp+9eyH9BBVsKJEk79+zUxS9frOWFyzXw5YHauWenYmJjdeLZZ6vvn/6kkzt29PJtAKhmzPUH39m5Z6dO/eOp+nn3zxp41kDt2LNDn67/VLtLdivOxerytoP01+v+5nWZAMKMuf4QMeLqx2nVr1fpd+m/00drP9KHaz/U7pLdcvulUf/XRJ2m5mvGZ894XSaAGkJQwZeaxTXTfX3vU4O6DQIbTBqx+BSlrTtBC077UeM+Gu9tgQBqDEEFX3uk/yOKqxenK5fFq/83J+vNc7Yop1OxHun/iNelAaghIQeVc661cy7HObfCObfMOTc2HIUBkjSqyyiN2d5DVyyPV07bH/WPrj/rkrMv0cjkkV6XBqCGhKNHtU/S7WbWXlKapJudcx3C0C4gSbrr5mf1YdIePX/uv9W8UXNNHzzd65IA1KCQg8rMNprZFwd+3i5phaSWobYL/Lhihfbv26emrRJ06+R/qF3zDnr7/72tuPpxXpcGoAaF9RqVcy5BUhdJnx3huSznXJ5zLq+w8Mg3dQKlNi9apLmZmfrqqackSR2bddTSm5aqYzPumQKiTdiCyjnXSNLfJf2Xmf186PNm9oyZpZhZSjxzsuEYfiwo0Ic336y4U0/VOddd53U5ADwWlqByztVTIKReMrPXwtEmotP2f/1LOVlZqhcXp4xnnlHsySd7XRIAj4U8e7oLTHs9XdIKM/tj6CUhWtn+/fpo7FhZSYkynn9ecaee6nVJAHwgHMt89JJ0naSvnHP5B7bdY2bvhKFtRBFXp466TZggOacTzjjD63IA+ETIQWVmCyVVbTEhQNK+4mJtWLBAbS68UE07d/a6HAA+w8wU8MRPq1fr7Usv1Q8FBVr4m9/o4zvu0LZvv/W6LAA+xAq/qHH7ioo0f/RoFW3cqPeuvVYlxcXqNmGCTjj9dK9LA+BD9KhQ4z797//Wrq1bJUklxcU64eyzdeZVV3lcFQC/IqhQo7557TV9v2CB9u/ZE9y2fe1affMadzUAODKCCjUqf9IklRQXl9m2f/du5U+a5FFFAPyOoEKNSr7tNsUcd1yZbTGxsUr+zW88qgiA3xFUqFFnXHGFWvbpo5gGgQUR6zRooJbp6Trj8ss9rgyAXxFUqHFpDz6oBiefLDmn45o0UdoDD3hdEgAfI6hQ4+o2bKj0adN0whlnqO/UqarbsKHXJQHwMe6jgidOPPNMDXz9da/LABAB6FEBAHyNoAIA+BpBBQDwNYIKAOBrBBUAwNcIKgCArxFUAABfI6gAAL5GUAEAfI2gAgD4GkEFAPA1ggoA4GsEFQDA1wgqAICvEVQAAF8jqAAAvkZQAQB8jaACAPgaQQUA8DWCCgDgawQVAMDXCCoAgK8RVAAAXyOoAAC+RlABAHyNoAIA+BpBBQDwNYIKAOBrYQkq59wM59xm59zScLQHAECpcPWoZkoaEKa2AAAICktQmdkCST+Eoy0AAA5WY9eonHNZzrk851xeYWFhTR0WABDhaiyozOwZM0sxs5T4+PiaOiwAIMIx6g8A4GsEFQDA18I1PP0VSZ9IOsc5t945d3042gUAoG44GjGza8LRDgAAh+LUHwDA1wgqAICvEVQAAF8jqAAAvkZQAQB8jaACAPgaQQUA8DWCCgDgawQVAMDXCCoAgK8RVAAAXyOoAAC+RlABAHyNoAIA+BpBBQDwNYIKAOBrBBUAwNcIKgCArxFUAABfI6gAAL5GUAEAfI2gAgD4GkEFAPA1ggoA4GsEFQDA1wgqAICvEVQAAF8jqAAAvkZQAQB8jaACAPgaQQUA8DWCCgDgawQVAMDXCCoAgK8RVAAAXyOoAAC+RlABAHyNoAIA+BpBBQDwtbAElXNugHNupXNutXPu7nC0CQCAFIagcs7FSHpK0kWSOki6xjnXIdR2AQCQwtOj6iZptZl9a2Z7JL0q6dIwtAsAQFiCqqWkdQc9Xn9gWxnOuSznXJ5zLq+wsDAMhwUARINwBJU7wjY7bIPZM2aWYmYp8fHxYTgsACAahCOo1ktqfdDjVpI2hKFdAADCElS5ks5yzrV1ztWXdLWkN8LQLgAAqhtqA2a2zzl3i6R/SoqRNMPMloVcGQAACkNQSZKZvSPpnXC0BQDAwZiZAgDgawQVAMDXCCoAgK8RVAAAXyOoAAC+RlAhai1bJiUmBr4D8C+CClFp507p4oul5culgQMDjwH4E0GFqDRqlLR5s2QmbdokXX+91xUBOBqCClFnxgzprbekXbsCj3ftkt58M7AdgP8QVIg6d94pFRWV3VZUJI0b5009AI4tLFMoAZHATHr55cNDSpIaNpQeeaTmawJQPnpUiBp33y1de63UpUtgIEVsbGB7bKx0ySXSyJHe1gfgyOhRodYzk5yTrrhCatxYuusuafduqUMHad06qXlzafp0r6sEcDQEFWqtXbsCvSgzafJkqXv3wJck1a0rvfOONGyYNGuWFBfnba0Ajo5Tf6i19u+X5s4NBJXZ4c937CgtXRr4DsC/6FGh1mrYUMrNpbcERDp6VKjVCCkg8hFUAABfI6hqI2ZbBVCLEFS1DbOtAqhlCKraJoJmW330USknp+y2nJzAdgAoRVDVJjNmBGZXjZDZVlNTpaFD/xNWOTmBx6mp3tYFwF+cHekGk2qWkpJieXl5NX7cWs1MOuEEafv2w59r1izQu/Kh0nAaM0aaOlXKzpYyMryuCoAXnHOLzCzl0O30qGqDwkLpyisDIVXnkD9Sn8+2mpERCKkHHgh8J6QAHIqgqg3+53+kt9+WHn88EFgRNNtqTk6gJzV+fOD7odesAICZKSLVzz9La9ZISUmBBZauvFJq3z4wyi9CZlstPe1XerovI6PsYwCQ6FFFpgULpM6dpcGDpT17pPr1AyElBaZieOedQFi9/bavp2bIzS0bShkZgce5ud7WBcBfGEwRSXbtCpwje+IJ6fTTpb/8RerZ0+uqACAsjjaYglN/kaKwUDrvvMB03zfeGLge1aiR11UBQLXj1F+kaNpU6to1cFpv2jRCCkDUIKj8bPXqwHRI69YFlqh94QXpoou8rgoAahRB5UdmgSHnycnS//2fVFDgdUUA4BmCym82bpQGDZJGj5bS0qSvvpLOP9/rqgDAMwSV3/z+99IHH0hTpgTWUW/d2uuKAMBTBJUf/PST9M03gZ9//3tp8WLp178+fDokAIhC/Evotffflzp1CkzJUDqxbLt2XlcFAL5BUHmluFgaO1bq3z8wcezUqYGRfQCAMrjh1wtr1gSGmRcUBE7xPfJIIKwAAIcJqUflnLvKObfMObffOXfYtBc4ilNPlc48MzBYYsoUQgoAjiHUU39LJV0haUEYaqndVq6UrrgiMHCifv3AyrsMOweAcoUUVGa2wsxWhquYWmn/funPf5a6dJE+/FBascLrigAgotTYYArnXJZzLs85l1dYWFhTh/XW+vXShRcGrkOlpwcmlO3Rw+uqACCilBtUzrl5zrmlR/i6tDIHMrNnzCzFzFLi4+OrXnEkue22wBRI06YF1oZq0cLrigAg4pQ76s/M+tdEIbXG1q2BxQxbtJCefFJ6+OHAwAkAQJVwH1U4vftu4ObdG24IPG7ZkpACgBCFOjz9cufcekk9JL3tnPtneMqKQNOnB5bkOPnkwDRIAICwCOmGXzObI2lOmGqJbJdeKq1dK91zjxQb63U1AFBrMDNFuDRtKk2c6HUVAFDrcI0KAOBrBBUAwNcIqlA9+qiUk1N2W05OYDsAIGQEVahSUwNrSZWGVU5O4HFqqrd1AUAtwWCKUGVkSNnZgXAaMyawrlR2dmA7ACBk9KjCISMjEFIPPBD4TkgBQNgQVOGQkxPoSY0fH/h+6DUrAECVEVShKr0mlZ0duI+q9DQgYQUAYUFQhSo3t+w1qdJrVrm53tYFALWEM7MaP2hKSorl5eXV+HEBAP7lnFtkZimHbqdHBQDwNYIKAOBrBBUAwNcIKgCArxFUAABfI6gAAL5GUAEAfI2gAgD4GkEFAPA1ggoA4GsEFQDA1wgqAICvEVQAAF8jqAAAvkZQAQB8jaACAPgaQQUA8DWCCgDgawQVAMDXCCoAgK8RVAAAXyOoAAC+RlABAHyNoAIA+BpBBQDwNYIKAOBrBBUAwNdCCirn3GPOuQLn3BLn3Bzn3IlhqgsAAEmh96jek5RoZkmSvpY0LvSSAAD4j5CCyszmmtm+Aw8/ldQq9JIAAPiPcF6jGiXp3aM96ZzLcs7lOefyCgsLw3hYAEBtVre8Fzjn5kk65QhP3Wtmrx94zb2S9kl66WjtmNkzkp6RpJSUFKtStQCAqFNuUJlZ/2M975wbLmmQpH5mRgABAMKq3KA6FufcAEl3SeprZkXhKQkAgP8I9RrVnyUdL+k951y+c25aGGoCACAopB6VmZ0ZrkIAADgSZqYAAPgaQQUA8DWCCgDgawQVAMDXCCoAgK8RVAAAX3NeTCbhnCuUtLYSuzSVtKWayqkJkV6/FPnvIdLrlyL/PUR6/VLkvwe/13+amcUfutGToKos51yemaV4XUdVRXr9UuS/h0ivX4r89xDp9UuR/x4itX5O/QEAfI2gAgD4WqQE1TNeFxCiSK9fivz3EOn1S5H/HiK9finy30NE1h8R16gAANErUnpUAIAoRVABAHwtYoLKOfeYc67AObfEOTfHOXei1zVVhnPuKufcMufcfudcxAwPdc4NcM6tdM6tds7d7XU9leWcm+Gc2+ycW+p1LVXhnGvtnMtxzq048Psz1uuaKss5F+uc+9w59+WB9/A7r2uqCudcjHNusXPuLa9rqQrn3Brn3FcH1g7M87qeyoiYoJL0nqREM0uS9LWkcR7XU1lLJV0haYHXhVSUcy5G0lOSLpLUQdI1zrkO3lZVaTMlDfC6iBDsk3S7mbWXlCbp5gj8M9gt6Twz6ywpWdIA51yatyVVyVhJK7wuIkQZZpYcafdSRUxQmdlcM9t34OGnklp5WU9lmdkKM1vpdR2V1E3SajP71sz2SHpV0qUe11QpZrZA0g9e11FVZrbRzL448PN2Bf6hbOltVZVjATsOPKx34CuiRnE551pJGijpOa9riUYRE1SHGCXpXa+LiAItJa076PF6Rdg/krWJcy5BUhdJn3lcSqUdOG2WL2mzpPfMLNLew5OS7pS03+M6QmGS5jrnFjnnsrwupjJCWoo+3Jxz8ySdcoSn7jWz1w+85l4FToe8VJO1VURF6o8w7gjbIup/wrWFc66RpL9L+i8z+9nreirLzEokJR+4tjzHOZdoZhFx3dA5N0jSZjNb5JxL97icUPQysw3OuWaS3nPOFRw44+B7vgoqM+t/rOedc8MlDZLUz3x4A1h59Ueg9ZJaH/S4laQNHtUStZxz9RQIqZfM7DWv6wmFmf3knJuvwHXDiAgqSb0kDXbOXSwpVlJj59yLZnatx3VVipltOPB9s3NujgKn9iMiqCLm1J9zboCkuyQNNrMir+uJErmSznLOtXXO1Zd0taQ3PK4pqjjnnKTpklaY2R+9rqcqnHPxpaN0nXPHSeovqcDToirBzMaZWSszS1Dg78AHkRZSzrk459zxpT9LukCR8x+FyAkqSX+WdLwCXdZ859w0rwuqDOfc5c659ZJ6SHrbOfdPr2sqz4HBK7dI+qcCF/GzzWyZt1VVjnPuFUmfSDrHObfeOXe91zVVUi9J10k678Dvff6B/9lHkhaScpxzSxT4z897ZhaRQ7wjWHNJC51zX0r6XNLbZva/HtdUYUyhBADwtUjqUQEAohBBBQDwNYIKAOBrBBUAwNcIKgCArxFUAABfI6gAAL72/wHZM6uXPOu55wAAAABJRU5ErkJggg==",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {
    "id": "059b633c"
   },
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ecb529",
   "metadata": {
    "id": "e6ecb529"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f8633eb8",
   "metadata": {
    "id": "f8633eb8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DatasetClass(Dataset):\n",
    "    def __init__(self, positions, velocities,charges):\n",
    "        \n",
    "        (samples,seq_length,dim,length) = positions.shape\n",
    "        # Get the initial positions\n",
    "        init_pos = positions[:,0,:,:]\n",
    "        init_pos = init_pos.reshape(samples,dim*length) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the initial velocities\n",
    "        init_vel = velocities.reshape(samples,dim*length) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the charges\n",
    "        c = charges.reshape(samples,length) # Flatten (samples,1,length) -> (samples,length)\n",
    "        # Create the feature array using initial state\n",
    "        features = np.concatenate((init_pos,init_vel,c),axis=1) # Concatenate initial information to a feature array\n",
    "        \n",
    "        #Create targets using positions in timesteps after the initial one and flattening the dimensions to a single list\n",
    "        targets = positions[:,1:,:,:].reshape(samples,seq_length - 1, dim*length)\n",
    "        \n",
    "        self.data = torch.FloatTensor(features)\n",
    "        print(self.data.shape)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        # Sanity checks\n",
    "        assert features.shape == (samples,dim*length*2 + length)\n",
    "        assert targets.shape == (samples,seq_length - 1, dim*length)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "0a99a32b",
   "metadata": {
    "id": "0a99a32b"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([10000, 25])\n",
      "torch.Size([2000, 25])\n",
      "torch.Size([2000, 25])\n"
     ]
    }
   ],
   "source": [
    "train_dataset = DatasetClass(positions_train,velocities_train,charges_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10)\n",
    "valid_dataset = DatasetClass(positions_valid, velocities_valid, charges_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=10)\n",
    "test_dataset = DatasetClass(positions_test, velocities_test, charges_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "f10d4c45",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 4, 2, 5)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "positions_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "01d3588e",
   "metadata": {},
   "outputs": [],
   "source": [
    "(samples,seq_length,dim,length) = positions_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "026a1c5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_positions = positions_train[:,0,:,:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "f0d55502",
   "metadata": {},
   "outputs": [],
   "source": [
    "init_positions = init_positions.reshape(samples,length, dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "ece13aec",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 5, 2)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "init_positions.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9ca765d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 5\n",
    "\n",
    "t1 = torch.rand(n, n)\n",
    "t1 = t1 * (torch.ones(n, n) - torch.eye(n, n))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "6ee6a40b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.0000, 0.1169, 0.3520, 0.4990, 0.4513],\n",
       "        [0.4249, 0.0000, 0.4613, 0.5628, 0.6153],\n",
       "        [0.8845, 0.5705, 0.0000, 0.5244, 0.0170],\n",
       "        [0.6892, 0.9224, 0.4804, 0.0000, 0.5614],\n",
       "        [0.9517, 0.5672, 0.1649, 0.1247, 0.0000]])"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8c86992",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch_geometric\n",
    "def unison_shuffled_copies(a, b):\n",
    "    assert len(a) == len(b)\n",
    "    p = np.random.permutation(len(a))\n",
    "    return a[p], b[p]\n",
    "def create_graphset(positions, velocities,charges,t_horizons,batch_size = 20):\n",
    "        (samples,seq_length,dim,length) = positions.shape\n",
    "        # Get the initial positions\n",
    "        init_pos = positions[:,0,:,:]\n",
    "        init_pos = init_pos.reshape(samples,length,dim) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the initial velocities\n",
    "        init_vel = velocities.reshape(samples,length,dim) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the charges\n",
    "        c = charges.reshape(samples,length,1) # Flatten (samples,1,length) -> (samples,length)\n",
    "        src = []\n",
    "        tgt = []\n",
    "        for i in range(length):\n",
    "           for j in range(length):\n",
    "              src.append(i)\n",
    "              tgt.append(j)\n",
    "        # Same generic edge index for every simulation\n",
    "        edge_index = torch.LongTensor([src,tgt])\n",
    "        features_array = []\n",
    "        data = []\n",
    "        batches = []\n",
    "        batch_counter = 0\n",
    "        target_ids = np.random.choice(np.arange(1,len(t_horizons)+1),size=samples)\n",
    "        target_values = np.array([t_horizons[target_id-1] for target_id in target_ids]).reshape(samples,1,1)\n",
    "        target_values = np.broadcast_to(target_values,(samples,length,1))\n",
    "        targets = np.array([positions[idx,target_ids[idx],:,:] for idx in range(len(target_ids))]).reshape(samples,length,dim)\n",
    "        features = np.concatenate((init_pos,init_vel,c,target_values),axis=2) # Concatenate initial information to a feature array\n",
    "        \n",
    "            \n",
    "        # Create the feature array using initial state\n",
    "        print(features.shape)\n",
    "        print(targets.shape)\n",
    "        #features,targets = unison_shuffled_copies(features,targets)\n",
    "        features = torch.FloatTensor(features)\n",
    "        for sim_id in range(features.shape[0]):\n",
    "            data.append(torch_geometric.data.Data(x=features[sim_id],edge_index=edge_index,num_nodes = features.shape[1]))\n",
    "            batch_counter+=1\n",
    "            if batch_counter == batch_size:\n",
    "                batch = torch_geometric.data.Batch.from_data_list(data)\n",
    "                batches.append(batch)\n",
    "                data = []\n",
    "                batch_counter = 0\n",
    "        #Create targets using positions in timesteps after the initial one and flattening the dimensions to a single list\n",
    "        \n",
    "        #data = torch.FloatTensor(features)\n",
    "        targets = torch.FloatTensor(targets.reshape(len(batches),length*batch_size,dim))\n",
    "        return batches,targets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "267a83d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "graph_train_data,graph_train_targets = create_graphset(positions_train,velocities_train,charges_train,[0.5,1,1.5])\n",
    "graph_valid_data,graph_valid_targets = create_graphset(positions_valid,velocities_valid,charges_valid,[0.5,1,1.5])\n",
    "graph_test_data,graph_test_targets = create_graphset(positions_test,velocities_test,charges_test,[0.5,1,1.5])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {
    "id": "18b2874d"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "66774050",
   "metadata": {
    "id": "66774050"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ba598378",
   "metadata": {
    "id": "ba598378"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.rnn = nn.LSTMCell(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "\n",
    "    def forward(self, batch_input):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, seq_length, input_shape]\n",
    "        \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        c0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        hidden1, c1 = self.rnn(batch_input,(hidden0,c0))\n",
    "        hidden2, c2 = self.rnn(batch_input,(hidden1,c1)) # Feed same input to all for now\n",
    "        hidden3, c3 = self.rnn(batch_input,(hidden2,c2)) # Feed same input to all for now\n",
    "        \n",
    "        \n",
    "        # retrieve final hidden output of last timestep for each sequence\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        #last_timestep = out[:,-1]\n",
    "        \n",
    "        # apply dropout\n",
    "        #self.drop(last_timestep)\n",
    "        \n",
    "        # feed lstm output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        h1 = nn.ReLU()(self.fc1(hidden1))\n",
    "        output1 = self.fc2(h1)\n",
    "        h2 = nn.ReLU()(self.fc1(hidden2))\n",
    "        output2 = self.fc2(h2)\n",
    "        h3 = nn.ReLU()(self.fc1(hidden3))\n",
    "        output3 = self.fc2(h3)\n",
    "        #h = nn.ReLU()(h)\n",
    "        \n",
    "        y_preds = torch.stack((output1,output2,output3),axis=1) # (Batch_size,3,dim * length)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "95154df7",
   "metadata": {
    "id": "95154df7"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class LSTMRegressorFeedForward(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(LSTMRegressorFeedForward, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.rnn = nn.LSTMCell(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "\n",
    "    def forward(self, batch_input):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, seq_length, input_shape]\n",
    "        \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        c0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        hidden1, c1 = self.rnn(batch_input,(hidden0,c0))\n",
    "        h1 = nn.ReLU()(self.fc1(hidden1))\n",
    "        output1 = self.fc2(h1)\n",
    "        \n",
    "        avg_velocities = (output1 - batch_input[:,:10]) / 0.5\n",
    "        batch_input2 = torch.cat((output1,avg_velocities,batch_input[:,-5:]),axis=1)\n",
    "        hidden2, c2 = self.rnn(batch_input2,(hidden1,c1)) # Feed same input to all for now\n",
    "        h2 = nn.ReLU()(self.fc1(hidden2))\n",
    "        output2 = self.fc2(h2)\n",
    "        \n",
    "        avg_velocities2 = (output2 - batch_input2[:,:10]) / 0.5\n",
    "        batch_input3 = torch.cat((output2,avg_velocities2,batch_input2[:,-5:]),axis=1)\n",
    "        hidden3, c3 = self.rnn(batch_input3,(hidden2,c2)) # Feed same input to all for now\n",
    "        h3 = nn.ReLU()(self.fc1(hidden3))\n",
    "        output3 = self.fc2(h3)\n",
    "        \n",
    "        \n",
    "        # retrieve final hidden output of last timestep for each sequence\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        #last_timestep = out[:,-1]\n",
    "        \n",
    "        # apply dropout\n",
    "        #self.drop(last_timestep)\n",
    "        \n",
    "        # feed lstm output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        \n",
    "        #h = nn.ReLU()(h)\n",
    "        \n",
    "        y_preds = torch.stack((output1,output2,output3),axis=1) # (Batch_size,3,dim * length)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "713e5296",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch_geometric.nn import GAT,SAGEConv,GATv2Conv,GraphSAGE\n",
    "class PhysicsSAGE(nn.Module):\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(PhysicsSAGE, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.sage = SAGEConv(in_channels=input_dim,\n",
    "                       out_channels=hidden_dim)\n",
    "        self.drop = nn.Dropout(0.3)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc2 = nn.Linear(hidden_dim//2, output_dim)\n",
    "        \n",
    "    def forward(self, batch_data,batch_edge_index):\n",
    "        \n",
    "        embedding = self.sage(batch_data,batch_edge_index)\n",
    "        embedding = self.drop(embedding)\n",
    "        h1 = nn.ReLU()(self.fc1(embedding))\n",
    "        #h1 = self.drop(h1)\n",
    "        output = self.fc2(h1)\n",
    "        \n",
    "        \n",
    "        return output\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {
    "id": "dea70d73"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3af520ae",
   "metadata": {
    "id": "3af520ae"
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(path, model, optimizer, val_loss, val_acc, train_acc, train_loss ):\n",
    "    if path == None:\n",
    "        return print(\"Kindly define a path\")\n",
    "    path = path\n",
    "    \n",
    "    save_dict = {\"model_dict\" : model.state_dict(), \n",
    "                 \"optimizer_dict\": optimizer.state_dict(),\n",
    "                 \"val_loss_dict\": val_loss,\n",
    "                 \"val_acc_dict\": val_acc,\n",
    "                 \"train_acc_dict\": train_acc,\n",
    "                 \"train_loss_dict\": train_loss}\n",
    "    torch.save(save_dict, path)\n",
    "    return print(\"Model Saved to ==> {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e95af5f9",
   "metadata": {
    "id": "e95af5f9"
   },
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train(model, train_loader, val_loader, criterion, num_epochs, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    cur_step = 0\n",
    "    train_pred = []\n",
    "    val_pred = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "  \n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for train_data, targets in train_loader:\n",
    "            \n",
    "           \n",
    "            # Forward\n",
    "            input_tensor = train_data.to(device)\n",
    "            outputs = model.forward(input_tensor)\n",
    "            loss = criterion(outputs,targets.to(device))\n",
    "            \n",
    "                \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            running_loss += loss\n",
    "          \n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(\"Train Pass Completed\")\n",
    "\n",
    "        ########################################|Validation Set|#############################################\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for val_data, val_targets in val_loader:\n",
    "                input_tensor = val_data.to(device)\n",
    "                outputs = model.forward(input_tensor)\n",
    "                loss = criterion(outputs,val_targets.to(device))\n",
    "                val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}' \n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss \n",
    "            save_model_checkpoint(save_name, model, optimizer, best_val_loss, 0, 0, avg_train_loss )\n",
    "    \n",
    "    print(\"Finished Training\") \n",
    "    return train_losses, val_losses\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9aa8bc2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train_graph(model, train_data,train_targets,\n",
    "                val_data,val_targets,\n",
    "                criterion, num_epochs, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    cur_step = 0\n",
    "    train_pred = []\n",
    "    val_pred = []\n",
    "\n",
    "                              \n",
    "    for epoch in range(num_epochs):\n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        running_loss = 0.0\n",
    "        for batch_idx,batch in enumerate(train_data):\n",
    "            # Forward\n",
    "            outputs = model.forward(batch.x.to(device),\n",
    "                                   batch.edge_index.to(device))\n",
    "            #print(outputs.shape)\n",
    "            loss = criterion(outputs,train_targets[batch_idx].to(device))\n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            running_loss += loss\n",
    "\n",
    "        avg_train_loss = running_loss / len(train_data)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(\"Train Pass Completed\")\n",
    "\n",
    "        ########################################|Validation Set|#############################################\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for batch_idx,batch in enumerate(val_data):\n",
    "                outputs = model.forward(batch.x.to(device),\n",
    "                                   batch.edge_index.to(device))\n",
    "                loss = criterion(outputs,val_targets[batch_idx].to(device))\n",
    "                val_running_loss += loss\n",
    "\n",
    "            avg_val_loss = val_running_loss / len(val_data)\n",
    "            val_losses.append(avg_val_loss)\n",
    "\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}' \n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss \n",
    "            save_model_checkpoint(save_name, model, optimizer, best_val_loss, 0, 0, avg_train_loss )\n",
    "    \n",
    "    print(\"Finished Training\") \n",
    "    return train_losses, val_losses\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc23dab9",
   "metadata": {},
   "outputs": [],
   "source": [
    "p_sage = PhysicsSAGE(6,192,2,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(p_sage.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'p_sage_t=all.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss_psage, obtained_val_loss_psage = train_graph(p_sage, \n",
    "                                                      graph_train_data,graph_train_targets,\n",
    "                                                      graph_valid_data,graph_valid_targets,                                  \n",
    "                                                      criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07e03ddf",
   "metadata": {
    "id": "07e03ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/100],Train Loss: 1.7338, Valid Loss: 0.56551653\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/100],Train Loss: 0.5043, Valid Loss: 0.43483043\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/100],Train Loss: 0.4045, Valid Loss: 0.38587406\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/100],Train Loss: 0.3471, Valid Loss: 0.34214899\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/100],Train Loss: 0.3065, Valid Loss: 0.31607971\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/100],Train Loss: 0.2791, Valid Loss: 0.29593742\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/100],Train Loss: 0.2561, Valid Loss: 0.27490342\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/100],Train Loss: 0.2387, Valid Loss: 0.25953364\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/100],Train Loss: 0.2241, Valid Loss: 0.25022793\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/100],Train Loss: 0.2130, Valid Loss: 0.24167404\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/100],Train Loss: 0.2028, Valid Loss: 0.23520391\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/100],Train Loss: 0.1953, Valid Loss: 0.22716445\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/100],Train Loss: 0.1880, Valid Loss: 0.22278243\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 14\n",
      "Train Pass Completed\n",
      "Epoch [14/100],Train Loss: 0.1821, Valid Loss: 0.21806754\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 15\n",
      "Train Pass Completed\n",
      "Epoch [15/100],Train Loss: 0.1768, Valid Loss: 0.21328804\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 16\n",
      "Train Pass Completed\n",
      "Epoch [16/100],Train Loss: 0.1726, Valid Loss: 0.20971148\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 17\n",
      "Train Pass Completed\n",
      "Epoch [17/100],Train Loss: 0.1690, Valid Loss: 0.20892118\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 18\n",
      "Train Pass Completed\n",
      "Epoch [18/100],Train Loss: 0.1644, Valid Loss: 0.20750563\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 19\n",
      "Train Pass Completed\n",
      "Epoch [19/100],Train Loss: 0.1616, Valid Loss: 0.20314725\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 20\n",
      "Train Pass Completed\n",
      "Epoch [20/100],Train Loss: 0.1589, Valid Loss: 0.19981550\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 21\n",
      "Train Pass Completed\n",
      "Epoch [21/100],Train Loss: 0.1564, Valid Loss: 0.19923854\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 22\n",
      "Train Pass Completed\n",
      "Epoch [22/100],Train Loss: 0.1536, Valid Loss: 0.19516559\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 23\n",
      "Train Pass Completed\n",
      "Epoch [23/100],Train Loss: 0.1507, Valid Loss: 0.19479044\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 24\n",
      "Train Pass Completed\n",
      "Epoch [24/100],Train Loss: 0.1479, Valid Loss: 0.19317694\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 25\n",
      "Train Pass Completed\n",
      "Epoch [25/100],Train Loss: 0.1461, Valid Loss: 0.19157873\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 26\n",
      "Train Pass Completed\n",
      "Epoch [26/100],Train Loss: 0.1438, Valid Loss: 0.19076639\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 27\n",
      "Train Pass Completed\n",
      "Epoch [27/100],Train Loss: 0.1424, Valid Loss: 0.19026613\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 28\n",
      "Train Pass Completed\n",
      "Epoch [28/100],Train Loss: 0.1402, Valid Loss: 0.19011910\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 29\n",
      "Train Pass Completed\n",
      "Epoch [29/100],Train Loss: 0.1387, Valid Loss: 0.18851508\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 30\n",
      "Train Pass Completed\n",
      "Epoch [30/100],Train Loss: 0.1368, Valid Loss: 0.18670960\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 31\n",
      "Train Pass Completed\n",
      "Epoch [31/100],Train Loss: 0.1352, Valid Loss: 0.18542884\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 32\n",
      "Train Pass Completed\n",
      "Epoch [32/100],Train Loss: 0.1338, Valid Loss: 0.18553375\n",
      "Starting epoch 33\n",
      "Train Pass Completed\n",
      "Epoch [33/100],Train Loss: 0.1323, Valid Loss: 0.18215495\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 34\n",
      "Train Pass Completed\n",
      "Epoch [34/100],Train Loss: 0.1307, Valid Loss: 0.18189643\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 35\n",
      "Train Pass Completed\n",
      "Epoch [35/100],Train Loss: 0.1294, Valid Loss: 0.18038872\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 36\n",
      "Train Pass Completed\n",
      "Epoch [36/100],Train Loss: 0.1279, Valid Loss: 0.18228132\n",
      "Starting epoch 37\n",
      "Train Pass Completed\n",
      "Epoch [37/100],Train Loss: 0.1271, Valid Loss: 0.18023035\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 38\n",
      "Train Pass Completed\n",
      "Epoch [38/100],Train Loss: 0.1254, Valid Loss: 0.17877075\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 39\n",
      "Train Pass Completed\n",
      "Epoch [39/100],Train Loss: 0.1244, Valid Loss: 0.17659397\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 40\n",
      "Train Pass Completed\n",
      "Epoch [40/100],Train Loss: 0.1237, Valid Loss: 0.17741169\n",
      "Starting epoch 41\n",
      "Train Pass Completed\n",
      "Epoch [41/100],Train Loss: 0.1220, Valid Loss: 0.17671777\n",
      "Starting epoch 42\n",
      "Train Pass Completed\n",
      "Epoch [42/100],Train Loss: 0.1209, Valid Loss: 0.17559859\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 43\n",
      "Train Pass Completed\n",
      "Epoch [43/100],Train Loss: 0.1203, Valid Loss: 0.17523356\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 44\n",
      "Train Pass Completed\n",
      "Epoch [44/100],Train Loss: 0.1191, Valid Loss: 0.17540579\n",
      "Starting epoch 45\n",
      "Train Pass Completed\n",
      "Epoch [45/100],Train Loss: 0.1179, Valid Loss: 0.17663832\n",
      "Starting epoch 46\n",
      "Train Pass Completed\n",
      "Epoch [46/100],Train Loss: 0.1175, Valid Loss: 0.17312013\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 47\n",
      "Train Pass Completed\n",
      "Epoch [47/100],Train Loss: 0.1165, Valid Loss: 0.17299244\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 48\n",
      "Train Pass Completed\n",
      "Epoch [48/100],Train Loss: 0.1153, Valid Loss: 0.17294982\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 49\n",
      "Train Pass Completed\n",
      "Epoch [49/100],Train Loss: 0.1147, Valid Loss: 0.17057750\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 50\n",
      "Train Pass Completed\n",
      "Epoch [50/100],Train Loss: 0.1138, Valid Loss: 0.17371221\n",
      "Starting epoch 51\n",
      "Train Pass Completed\n",
      "Epoch [51/100],Train Loss: 0.1129, Valid Loss: 0.17151318\n",
      "Starting epoch 52\n",
      "Train Pass Completed\n",
      "Epoch [52/100],Train Loss: 0.1120, Valid Loss: 0.17055109\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 53\n",
      "Train Pass Completed\n",
      "Epoch [53/100],Train Loss: 0.1112, Valid Loss: 0.17048626\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 54\n",
      "Train Pass Completed\n",
      "Epoch [54/100],Train Loss: 0.1108, Valid Loss: 0.17019922\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 55\n",
      "Train Pass Completed\n",
      "Epoch [55/100],Train Loss: 0.1101, Valid Loss: 0.17004302\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 56\n",
      "Train Pass Completed\n",
      "Epoch [56/100],Train Loss: 0.1094, Valid Loss: 0.17086019\n",
      "Starting epoch 57\n",
      "Train Pass Completed\n",
      "Epoch [57/100],Train Loss: 0.1086, Valid Loss: 0.17025092\n",
      "Starting epoch 58\n",
      "Train Pass Completed\n",
      "Epoch [58/100],Train Loss: 0.1078, Valid Loss: 0.16793346\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 59\n",
      "Train Pass Completed\n",
      "Epoch [59/100],Train Loss: 0.1072, Valid Loss: 0.16994213\n",
      "Starting epoch 60\n",
      "Train Pass Completed\n",
      "Epoch [60/100],Train Loss: 0.1066, Valid Loss: 0.16932231\n",
      "Starting epoch 61\n",
      "Train Pass Completed\n",
      "Epoch [61/100],Train Loss: 0.1062, Valid Loss: 0.16855903\n",
      "Starting epoch 62\n",
      "Train Pass Completed\n",
      "Epoch [62/100],Train Loss: 0.1057, Valid Loss: 0.16887183\n",
      "Starting epoch 63\n",
      "Train Pass Completed\n",
      "Epoch [63/100],Train Loss: 0.1049, Valid Loss: 0.16723457\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 64\n",
      "Train Pass Completed\n",
      "Epoch [64/100],Train Loss: 0.1044, Valid Loss: 0.16738532\n",
      "Starting epoch 65\n",
      "Train Pass Completed\n",
      "Epoch [65/100],Train Loss: 0.1040, Valid Loss: 0.16796656\n",
      "Starting epoch 66\n",
      "Train Pass Completed\n",
      "Epoch [66/100],Train Loss: 0.1034, Valid Loss: 0.16712838\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 67\n",
      "Train Pass Completed\n",
      "Epoch [67/100],Train Loss: 0.1027, Valid Loss: 0.16794051\n",
      "Starting epoch 68\n",
      "Train Pass Completed\n",
      "Epoch [68/100],Train Loss: 0.1024, Valid Loss: 0.16786323\n",
      "Starting epoch 69\n",
      "Train Pass Completed\n",
      "Epoch [69/100],Train Loss: 0.1018, Valid Loss: 0.16726047\n",
      "Starting epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass Completed\n",
      "Epoch [70/100],Train Loss: 0.1014, Valid Loss: 0.16614254\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 71\n",
      "Train Pass Completed\n",
      "Epoch [71/100],Train Loss: 0.1010, Valid Loss: 0.16670536\n",
      "Starting epoch 72\n",
      "Train Pass Completed\n",
      "Epoch [72/100],Train Loss: 0.1000, Valid Loss: 0.16573808\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 73\n",
      "Train Pass Completed\n",
      "Epoch [73/100],Train Loss: 0.0997, Valid Loss: 0.16699180\n",
      "Starting epoch 74\n",
      "Train Pass Completed\n",
      "Epoch [74/100],Train Loss: 0.0995, Valid Loss: 0.16705044\n",
      "Starting epoch 75\n",
      "Train Pass Completed\n",
      "Epoch [75/100],Train Loss: 0.0990, Valid Loss: 0.16674715\n",
      "Starting epoch 76\n",
      "Train Pass Completed\n",
      "Epoch [76/100],Train Loss: 0.0985, Valid Loss: 0.16640814\n",
      "Starting epoch 77\n",
      "Train Pass Completed\n",
      "Epoch [77/100],Train Loss: 0.0981, Valid Loss: 0.16520455\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 78\n",
      "Train Pass Completed\n",
      "Epoch [78/100],Train Loss: 0.0977, Valid Loss: 0.16619679\n",
      "Starting epoch 79\n",
      "Train Pass Completed\n",
      "Epoch [79/100],Train Loss: 0.0975, Valid Loss: 0.16597268\n",
      "Starting epoch 80\n",
      "Train Pass Completed\n",
      "Epoch [80/100],Train Loss: 0.0968, Valid Loss: 0.16629563\n",
      "Starting epoch 81\n",
      "Train Pass Completed\n",
      "Epoch [81/100],Train Loss: 0.0962, Valid Loss: 0.16631834\n",
      "Starting epoch 82\n",
      "Train Pass Completed\n",
      "Epoch [82/100],Train Loss: 0.0961, Valid Loss: 0.16554661\n",
      "Starting epoch 83\n",
      "Train Pass Completed\n",
      "Epoch [83/100],Train Loss: 0.0957, Valid Loss: 0.16545688\n",
      "Starting epoch 84\n",
      "Train Pass Completed\n",
      "Epoch [84/100],Train Loss: 0.0956, Valid Loss: 0.16652651\n",
      "Starting epoch 85\n",
      "Train Pass Completed\n",
      "Epoch [85/100],Train Loss: 0.0951, Valid Loss: 0.16511020\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 86\n",
      "Train Pass Completed\n",
      "Epoch [86/100],Train Loss: 0.0946, Valid Loss: 0.16638784\n",
      "Starting epoch 87\n",
      "Train Pass Completed\n",
      "Epoch [87/100],Train Loss: 0.0941, Valid Loss: 0.16572365\n",
      "Starting epoch 88\n",
      "Train Pass Completed\n",
      "Epoch [88/100],Train Loss: 0.0939, Valid Loss: 0.16615134\n",
      "Starting epoch 89\n",
      "Train Pass Completed\n",
      "Epoch [89/100],Train Loss: 0.0935, Valid Loss: 0.16751413\n",
      "Starting epoch 90\n",
      "Train Pass Completed\n",
      "Epoch [90/100],Train Loss: 0.0933, Valid Loss: 0.16674000\n",
      "Starting epoch 91\n",
      "Train Pass Completed\n",
      "Epoch [91/100],Train Loss: 0.0927, Valid Loss: 0.16485965\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 92\n",
      "Train Pass Completed\n",
      "Epoch [92/100],Train Loss: 0.0924, Valid Loss: 0.16706701\n",
      "Starting epoch 93\n",
      "Train Pass Completed\n",
      "Epoch [93/100],Train Loss: 0.0924, Valid Loss: 0.16412306\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 94\n",
      "Train Pass Completed\n",
      "Epoch [94/100],Train Loss: 0.0918, Valid Loss: 0.16595542\n",
      "Starting epoch 95\n",
      "Train Pass Completed\n",
      "Epoch [95/100],Train Loss: 0.0914, Valid Loss: 0.16535644\n",
      "Starting epoch 96\n",
      "Train Pass Completed\n",
      "Epoch [96/100],Train Loss: 0.0909, Valid Loss: 0.16599590\n",
      "Starting epoch 97\n",
      "Train Pass Completed\n",
      "Epoch [97/100],Train Loss: 0.0910, Valid Loss: 0.16663922\n",
      "Starting epoch 98\n",
      "Train Pass Completed\n",
      "Epoch [98/100],Train Loss: 0.0906, Valid Loss: 0.16510227\n",
      "Starting epoch 99\n",
      "Train Pass Completed\n",
      "Epoch [99/100],Train Loss: 0.0902, Valid Loss: 0.16626045\n",
      "Starting epoch 100\n",
      "Train Pass Completed\n",
      "Epoch [100/100],Train Loss: 0.0900, Valid Loss: 0.16604753\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "LSTM_reg = LSTMRegressor(25,192,10,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(LSTM_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'LSTM_reg.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(LSTM_reg, \n",
    "                                                      train_loader, valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "15d74560",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/100],Train Loss: 2.9493, Valid Loss: 1.29062331\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/100],Train Loss: 1.1049, Valid Loss: 0.92549068\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/100],Train Loss: 0.7987, Valid Loss: 0.68528670\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/100],Train Loss: 0.6311, Valid Loss: 0.58944482\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/100],Train Loss: 0.5417, Valid Loss: 0.52197975\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/100],Train Loss: 0.4797, Valid Loss: 0.48037547\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/100],Train Loss: 0.4292, Valid Loss: 0.43565467\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/100],Train Loss: 0.3978, Valid Loss: 0.41503748\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/100],Train Loss: 0.3722, Valid Loss: 0.40283674\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/100],Train Loss: 0.3507, Valid Loss: 0.37834665\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/100],Train Loss: 0.3321, Valid Loss: 0.36455217\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/100],Train Loss: 0.3183, Valid Loss: 0.34966055\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/100],Train Loss: 0.3086, Valid Loss: 0.34366205\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 14\n",
      "Train Pass Completed\n",
      "Epoch [14/100],Train Loss: 0.2967, Valid Loss: 0.34058064\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 15\n",
      "Train Pass Completed\n",
      "Epoch [15/100],Train Loss: 0.2870, Valid Loss: 0.33346996\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 16\n",
      "Train Pass Completed\n",
      "Epoch [16/100],Train Loss: 0.2785, Valid Loss: 0.33192214\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 17\n",
      "Train Pass Completed\n",
      "Epoch [17/100],Train Loss: 0.2723, Valid Loss: 0.31535167\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 18\n",
      "Train Pass Completed\n",
      "Epoch [18/100],Train Loss: 0.2660, Valid Loss: 0.31408799\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 19\n",
      "Train Pass Completed\n",
      "Epoch [19/100],Train Loss: 0.2607, Valid Loss: 0.31582147\n",
      "Starting epoch 20\n",
      "Train Pass Completed\n",
      "Epoch [20/100],Train Loss: 0.2540, Valid Loss: 0.30499691\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 21\n",
      "Train Pass Completed\n",
      "Epoch [21/100],Train Loss: 0.2512, Valid Loss: 0.29763767\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 22\n",
      "Train Pass Completed\n",
      "Epoch [22/100],Train Loss: 0.2436, Valid Loss: 0.29927057\n",
      "Starting epoch 23\n",
      "Train Pass Completed\n",
      "Epoch [23/100],Train Loss: 0.2394, Valid Loss: 0.29683733\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 24\n",
      "Train Pass Completed\n",
      "Epoch [24/100],Train Loss: 0.2362, Valid Loss: 0.29610604\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 25\n",
      "Train Pass Completed\n",
      "Epoch [25/100],Train Loss: 0.2336, Valid Loss: 0.29498926\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 26\n",
      "Train Pass Completed\n",
      "Epoch [26/100],Train Loss: 0.2313, Valid Loss: 0.28475180\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 27\n",
      "Train Pass Completed\n",
      "Epoch [27/100],Train Loss: 0.2272, Valid Loss: 0.28751436\n",
      "Starting epoch 28\n",
      "Train Pass Completed\n",
      "Epoch [28/100],Train Loss: 0.2259, Valid Loss: 0.28743619\n",
      "Starting epoch 29\n",
      "Train Pass Completed\n",
      "Epoch [29/100],Train Loss: 0.2223, Valid Loss: 0.28567123\n",
      "Starting epoch 30\n",
      "Train Pass Completed\n",
      "Epoch [30/100],Train Loss: 0.2190, Valid Loss: 0.28503561\n",
      "Starting epoch 31\n",
      "Train Pass Completed\n",
      "Epoch [31/100],Train Loss: 0.2158, Valid Loss: 0.27811444\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 32\n",
      "Train Pass Completed\n",
      "Epoch [32/100],Train Loss: 0.2141, Valid Loss: 0.27330038\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 33\n",
      "Train Pass Completed\n",
      "Epoch [33/100],Train Loss: 0.2087, Valid Loss: 0.27348918\n",
      "Starting epoch 34\n",
      "Train Pass Completed\n",
      "Epoch [34/100],Train Loss: 0.2089, Valid Loss: 0.27400443\n",
      "Starting epoch 35\n",
      "Train Pass Completed\n",
      "Epoch [35/100],Train Loss: 0.2064, Valid Loss: 0.27201033\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 36\n",
      "Train Pass Completed\n",
      "Epoch [36/100],Train Loss: 0.2047, Valid Loss: 0.26804864\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 37\n",
      "Train Pass Completed\n",
      "Epoch [37/100],Train Loss: 0.2019, Valid Loss: 0.26925543\n",
      "Starting epoch 38\n",
      "Train Pass Completed\n",
      "Epoch [38/100],Train Loss: 0.1996, Valid Loss: 0.26853362\n",
      "Starting epoch 39\n",
      "Train Pass Completed\n",
      "Epoch [39/100],Train Loss: 0.1981, Valid Loss: 0.26473987\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 40\n",
      "Train Pass Completed\n",
      "Epoch [40/100],Train Loss: 0.1953, Valid Loss: 0.25657952\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 41\n",
      "Train Pass Completed\n",
      "Epoch [41/100],Train Loss: 0.1925, Valid Loss: 0.25961962\n",
      "Starting epoch 42\n",
      "Train Pass Completed\n",
      "Epoch [42/100],Train Loss: 0.1905, Valid Loss: 0.25333253\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 43\n",
      "Train Pass Completed\n",
      "Epoch [43/100],Train Loss: 0.1898, Valid Loss: 0.26035395\n",
      "Starting epoch 44\n",
      "Train Pass Completed\n",
      "Epoch [44/100],Train Loss: 0.1882, Valid Loss: 0.26395831\n",
      "Starting epoch 45\n",
      "Train Pass Completed\n",
      "Epoch [45/100],Train Loss: 0.1867, Valid Loss: 0.25319597\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 46\n",
      "Train Pass Completed\n",
      "Epoch [46/100],Train Loss: 0.1846, Valid Loss: 0.25714317\n",
      "Starting epoch 47\n",
      "Train Pass Completed\n",
      "Epoch [47/100],Train Loss: 0.1824, Valid Loss: 0.25595808\n",
      "Starting epoch 48\n",
      "Train Pass Completed\n",
      "Epoch [48/100],Train Loss: 0.1804, Valid Loss: 0.25282317\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 49\n",
      "Train Pass Completed\n",
      "Epoch [49/100],Train Loss: 0.1802, Valid Loss: 0.24583970\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 50\n",
      "Train Pass Completed\n",
      "Epoch [50/100],Train Loss: 0.1776, Valid Loss: 0.24919814\n",
      "Starting epoch 51\n",
      "Train Pass Completed\n",
      "Epoch [51/100],Train Loss: 0.1770, Valid Loss: 0.24930111\n",
      "Starting epoch 52\n",
      "Train Pass Completed\n",
      "Epoch [52/100],Train Loss: 0.1759, Valid Loss: 0.25439864\n",
      "Starting epoch 53\n",
      "Train Pass Completed\n",
      "Epoch [53/100],Train Loss: 0.1737, Valid Loss: 0.25380909\n",
      "Starting epoch 54\n",
      "Train Pass Completed\n",
      "Epoch [54/100],Train Loss: 0.1719, Valid Loss: 0.24569982\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 55\n",
      "Train Pass Completed\n",
      "Epoch [55/100],Train Loss: 0.1723, Valid Loss: 0.24684644\n",
      "Starting epoch 56\n",
      "Train Pass Completed\n",
      "Epoch [56/100],Train Loss: 0.1702, Valid Loss: 0.24515311\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 57\n",
      "Train Pass Completed\n",
      "Epoch [57/100],Train Loss: 0.1704, Valid Loss: 0.24455579\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 58\n",
      "Train Pass Completed\n",
      "Epoch [58/100],Train Loss: 0.1678, Valid Loss: 0.24116378\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 59\n",
      "Train Pass Completed\n",
      "Epoch [59/100],Train Loss: 0.1672, Valid Loss: 0.24180578\n",
      "Starting epoch 60\n",
      "Train Pass Completed\n",
      "Epoch [60/100],Train Loss: 0.1664, Valid Loss: 0.24226911\n",
      "Starting epoch 61\n",
      "Train Pass Completed\n",
      "Epoch [61/100],Train Loss: 0.1642, Valid Loss: 0.24174155\n",
      "Starting epoch 62\n",
      "Train Pass Completed\n",
      "Epoch [62/100],Train Loss: 0.1638, Valid Loss: 0.24137124\n",
      "Starting epoch 63\n",
      "Train Pass Completed\n",
      "Epoch [63/100],Train Loss: 0.1635, Valid Loss: 0.25235420\n",
      "Starting epoch 64\n",
      "Train Pass Completed\n",
      "Epoch [64/100],Train Loss: 0.1630, Valid Loss: 0.23838997\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 65\n",
      "Train Pass Completed\n",
      "Epoch [65/100],Train Loss: 0.1601, Valid Loss: 0.24036425\n",
      "Starting epoch 66\n",
      "Train Pass Completed\n",
      "Epoch [66/100],Train Loss: 0.1606, Valid Loss: 0.23438631\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 67\n",
      "Train Pass Completed\n",
      "Epoch [67/100],Train Loss: 0.1582, Valid Loss: 0.23792414\n",
      "Starting epoch 68\n",
      "Train Pass Completed\n",
      "Epoch [68/100],Train Loss: 0.1580, Valid Loss: 0.23837689\n",
      "Starting epoch 69\n",
      "Train Pass Completed\n",
      "Epoch [69/100],Train Loss: 0.1557, Valid Loss: 0.23570846\n",
      "Starting epoch 70\n",
      "Train Pass Completed\n",
      "Epoch [70/100],Train Loss: 0.1550, Valid Loss: 0.23686178\n",
      "Starting epoch 71\n",
      "Train Pass Completed\n",
      "Epoch [71/100],Train Loss: 0.1550, Valid Loss: 0.23352066\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass Completed\n",
      "Epoch [72/100],Train Loss: 0.1541, Valid Loss: 0.23342770\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 73\n",
      "Train Pass Completed\n",
      "Epoch [73/100],Train Loss: 0.1524, Valid Loss: 0.23360404\n",
      "Starting epoch 74\n",
      "Train Pass Completed\n",
      "Epoch [74/100],Train Loss: 0.1516, Valid Loss: 0.23012914\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 75\n",
      "Train Pass Completed\n",
      "Epoch [75/100],Train Loss: 0.1514, Valid Loss: 0.23431210\n",
      "Starting epoch 76\n",
      "Train Pass Completed\n",
      "Epoch [76/100],Train Loss: 0.1510, Valid Loss: 0.23052359\n",
      "Starting epoch 77\n",
      "Train Pass Completed\n",
      "Epoch [77/100],Train Loss: 0.1504, Valid Loss: 0.23349459\n",
      "Starting epoch 78\n",
      "Train Pass Completed\n",
      "Epoch [78/100],Train Loss: 0.1488, Valid Loss: 0.23225616\n",
      "Starting epoch 79\n",
      "Train Pass Completed\n",
      "Epoch [79/100],Train Loss: 0.1467, Valid Loss: 0.23099835\n",
      "Starting epoch 80\n",
      "Train Pass Completed\n",
      "Epoch [80/100],Train Loss: 0.1467, Valid Loss: 0.23157686\n",
      "Starting epoch 81\n",
      "Train Pass Completed\n",
      "Epoch [81/100],Train Loss: 0.1461, Valid Loss: 0.22974180\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 82\n",
      "Train Pass Completed\n",
      "Epoch [82/100],Train Loss: 0.1450, Valid Loss: 0.23117775\n",
      "Starting epoch 83\n",
      "Train Pass Completed\n",
      "Epoch [83/100],Train Loss: 0.1446, Valid Loss: 0.22763848\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 84\n",
      "Train Pass Completed\n",
      "Epoch [84/100],Train Loss: 0.1435, Valid Loss: 0.23095949\n",
      "Starting epoch 85\n",
      "Train Pass Completed\n",
      "Epoch [85/100],Train Loss: 0.1440, Valid Loss: 0.22723998\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 86\n",
      "Train Pass Completed\n",
      "Epoch [86/100],Train Loss: 0.1423, Valid Loss: 0.23059779\n",
      "Starting epoch 87\n",
      "Train Pass Completed\n",
      "Epoch [87/100],Train Loss: 0.1413, Valid Loss: 0.22821938\n",
      "Starting epoch 88\n",
      "Train Pass Completed\n",
      "Epoch [88/100],Train Loss: 0.1423, Valid Loss: 0.22272567\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 89\n",
      "Train Pass Completed\n",
      "Epoch [89/100],Train Loss: 0.1408, Valid Loss: 0.22982825\n",
      "Starting epoch 90\n",
      "Train Pass Completed\n",
      "Epoch [90/100],Train Loss: 0.1405, Valid Loss: 0.23373578\n",
      "Starting epoch 91\n",
      "Train Pass Completed\n",
      "Epoch [91/100],Train Loss: 0.1386, Valid Loss: 0.22638546\n",
      "Starting epoch 92\n",
      "Train Pass Completed\n",
      "Epoch [92/100],Train Loss: 0.1387, Valid Loss: 0.22841266\n",
      "Starting epoch 93\n",
      "Train Pass Completed\n",
      "Epoch [93/100],Train Loss: 0.1388, Valid Loss: 0.22377825\n",
      "Starting epoch 94\n",
      "Train Pass Completed\n",
      "Epoch [94/100],Train Loss: 0.1375, Valid Loss: 0.22374986\n",
      "Starting epoch 95\n",
      "Train Pass Completed\n",
      "Epoch [95/100],Train Loss: 0.1363, Valid Loss: 0.22193779\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 96\n",
      "Train Pass Completed\n",
      "Epoch [96/100],Train Loss: 0.1358, Valid Loss: 0.22199100\n",
      "Starting epoch 97\n",
      "Train Pass Completed\n",
      "Epoch [97/100],Train Loss: 0.1357, Valid Loss: 0.22568738\n",
      "Starting epoch 98\n",
      "Train Pass Completed\n",
      "Epoch [98/100],Train Loss: 0.1349, Valid Loss: 0.22563781\n",
      "Starting epoch 99\n",
      "Train Pass Completed\n",
      "Epoch [99/100],Train Loss: 0.1348, Valid Loss: 0.22097562\n",
      "Model Saved to ==> LSTM_reg_ff.pt\n",
      "Starting epoch 100\n",
      "Train Pass Completed\n",
      "Epoch [100/100],Train Loss: 0.1330, Valid Loss: 0.22106713\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "LSTM_reg_ff = LSTMRegressorFeedForward(25,192,10,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(LSTM_reg_ff.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'LSTM_reg_ff.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(LSTM_reg_ff, \n",
    "                                                      train_loader, valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {
    "id": "d5fb3b29"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf5fa1b4",
   "metadata": {
    "id": "bf5fa1b4"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "# Baseline model\n",
    "def baseline_predictor(inputs,t):\n",
    "    # The same input [samples,25]\n",
    "    initial_pos = inputs[:,10]\n",
    "    initial_vel = inputs[:,10:20]\n",
    "    return initial_pos + initial_vel * t "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "ed4a1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on the validation set\n",
    "from sklearn.metrics import mean_squared_error\n",
    "def evaluate(model, test_loader,device='cpu'):\n",
    "    val_running_loss = 0.0\n",
    "    preds = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for val_data, val_targets in test_loader:\n",
    "            input_tensor = val_data.to(device)\n",
    "            outputs = model.forward(input_tensor)\n",
    "            preds.append(outputs)\n",
    "            actual.append(val_targets)\n",
    "            loss = criterion(outputs,val_targets.to(device))\n",
    "            val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(test_loader)\n",
    "        print(\"Average Test Loss: {:4f}\".format(avg_val_loss))\n",
    "        return preds,actual\n",
    "def evaluate_graph(model,test_data,test_targets,device='cpu'):\n",
    "    val_running_loss = 0.0\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for batch_idx,batch in enumerate(test_data):\n",
    "            outputs = model.forward(batch.x.to(device),\n",
    "                               batch.edge_index.to(device))\n",
    "            loss = criterion(outputs,test_targets[batch_idx].to(device))\n",
    "            val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(test_data)\n",
    "        print(\"Average Test Loss: {:4f}\".format(avg_val_loss))\n",
    "        return preds,actual\n",
    "def evaluate_baseline(test_loader):\n",
    "    for seq_id,t in enumerate([0.5,1,1.5]):\n",
    "        test_running_loss = 0\n",
    "        for test_data,test_target in test_loader:\n",
    "            test_data = test_data.numpy()\n",
    "            test_target = test_target.numpy()\n",
    "            predictions = baseline_predictor(test_data,t)\n",
    "            loss = mean_squared_error(test_target[:,seq_id],predictions)\n",
    "            test_running_loss += loss\n",
    "        avg_test_loss = test_running_loss / len(test_loader)\n",
    "        print(\"Average Test Loss for Baseline Predictor(t={}): {}\".format(t,avg_test_loss))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2280031f",
   "metadata": {
    "id": "2280031f"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'LSTMRegressorFeedForward' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_241/1999655844.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;31m#Model Evaluation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mLSTMRegressorFeedForward\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m192\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m10\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mcheckpoint\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'LSTM_reg_ff.pt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmap_location\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'cpu'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mload_state_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcheckpoint\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model_dict'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'LSTMRegressorFeedForward' is not defined"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "model = LSTMRegressorFeedForward(25,192,10,'cpu')\n",
    "checkpoint = torch.load('LSTM_reg_ff.pt', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model_dict'])\n",
    "\n",
    "preds,actual = evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a140730",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation trained by sampling t=0.5,1 data tested on sampling from all possible t's\n",
    "model = PhysicsSAGE(6,192,2,'cpu')\n",
    "checkpoint = torch.load('p_sage_t=[0.5,1].pt', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model_dict'])\n",
    "\n",
    "preds,actual = evaluate_graph(model, graph_test_data,graph_test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9be48400",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Model Evaluation trained by sampling t=0.5,1,1.5 data tested on sampling from all possible t's\n",
    "model = PhysicsSAGE(6,192,2,'cpu')\n",
    "checkpoint = torch.load('p_sage_t=all.pt', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model_dict'])\n",
    "\n",
    "preds,actual = evaluate_graph(model, graph_test_data,graph_test_targets)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "658e878e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss for Baseline Predictor(t=0.5): 6.7281222403049465\n",
      "Average Test Loss for Baseline Predictor(t=1): 6.916228829622269\n",
      "Average Test Loss for Baseline Predictor(t=1.5): 7.2571910440921785\n"
     ]
    }
   ],
   "source": [
    "evaluate_baseline(test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a334b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_positions(preds_sample, actual_sample):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(5):\n",
    "        plt.plot(preds_sample[i],preds_sample[i+5],'o',color=colors[i])\n",
    "        plt.plot(actual_sample[i],actual_sample[i+5],'x',color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a8240f1",
   "metadata": {
    "id": "3a8240f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][0], actual[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2561c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][1], actual[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4666f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][2], actual[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdac092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "a2_skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
