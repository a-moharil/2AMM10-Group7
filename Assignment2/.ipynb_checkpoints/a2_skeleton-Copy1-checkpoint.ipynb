{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "730fd591",
   "metadata": {
    "id": "730fd591"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a2_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d32f8d18",
   "metadata": {
    "id": "d32f8d18"
   },
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "faec2056",
   "metadata": {
    "id": "faec2056"
   },
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {
    "id": "7d0580a5"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b0756591",
   "metadata": {
    "id": "b0756591"
   },
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_array(zipfile, fn):\n",
    "    return np.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {
    "id": "bb77a4be"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes of the training data:\n",
      "\n",
      "positions: (10000, 4, 2, 5)\n",
      "velocities: (10000, 1, 2, 5)\n",
      "charges: (10000, 5, 1)\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "This cell loads the training, validation or test data as numpy arrays,\n",
    "with the positions, initial velocities and charge data of the particles.\n",
    "\n",
    "The position arrays are shaped as\n",
    "[simulation id, time point (corresponding to t = 0, 0.5, 1 or 1.5), x/y spatial dimension, particle id].\n",
    "\n",
    "The initial velocity arrays are shaped as\n",
    "[simulation id, 1 (corresponding to t=0), x/y spatial dimension, particle id].\n",
    "\n",
    "The charge arrays are shaped as [simulation id, particle id, 1]\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/OIgda2ZRG8v0eqB/download')\n",
    "\n",
    "features = ['positions', 'velocities', 'charges']\n",
    "    \n",
    "positions_train, velocities_train, charges_train = (load_array(data, f'data/train/{f}.npy') for f in features)\n",
    "positions_valid, velocities_valid, charges_valid = (load_array(data, f'data/valid/{f}.npy') for f in features)\n",
    "positions_test, velocities_test, charges_test = (load_array(data, f'data/test/{f}.npy') for f in features)\n",
    "\n",
    "print('Shapes of the training data:\\n')\n",
    "print(f'positions: {positions_train.shape}')\n",
    "print(f'velocities: {velocities_train.shape}')\n",
    "print(f'charges: {charges_train.shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "806d69c9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(10000, 25)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = positions_train[:,0,:,:] #initial positions\n",
    "a.reshape(10000,10)\n",
    "np.concatenate((a.reshape(10000,10),velocities_train.reshape(10000,10),charges_train.reshape(10000,5)),axis=1).shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "1c3ea4cb",
   "metadata": {
    "id": "1c3ea4cb"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "An example of retrieving data from the arrays:\n",
      "\n",
      "\n",
      "In simulation 41 of the training set, particle 3 with charge 1.0 had coordinates [-3.64354499 -2.92196403].\n",
      "The initial velocity of this particle was [-0.63201981 -0.56448973].\n"
     ]
    }
   ],
   "source": [
    "print('An example of retrieving data from the arrays:\\n\\n')\n",
    "\n",
    "sim_idx = 41\n",
    "t_idx = 2  # t_idx 0, 1, 2, 3 corresponds to t=0, 0.5, 1 and 1.5 respectively\n",
    "spatial_idx = (0,1)  # corresponds to both x and y dimension\n",
    "particle_idx = 3  # corresponds to particle with index 3\n",
    "\n",
    "p = positions_train[sim_idx, t_idx, spatial_idx, particle_idx]\n",
    "v = velocities_train[sim_idx, 0, spatial_idx, particle_idx]  # note: this array contains only the inital velocity -> hence the 0\n",
    "c = charges_train[sim_idx, particle_idx, 0] \n",
    "\n",
    "print(\n",
    "    f'In simulation {sim_idx} of the training set, particle {particle_idx} with charge {c} had coordinates {p}.\\nThe initial velocity of this particle was {v}.'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "10a3438a",
   "metadata": {
    "id": "10a3438a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "10000 train, 2000 validation, 2000 test simulations\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print(f'{len(positions_train)} train, {len(positions_valid)} validation, {len(positions_test)} test simulations')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "f9106543",
   "metadata": {
    "id": "f9106543"
   },
   "outputs": [],
   "source": [
    "def plot_example(pos, vel):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(pos.shape[-1]):\n",
    "        plt.plot(pos[0, 0, i], pos[0, 1, i], 'd', color=colors[i])\n",
    "        plt.plot(pos[-1, 0, i], pos[-1, 1, i], 'x', color=colors[i])\n",
    "        plt.plot([pos[0, 0, i], pos[0, 0, i] + vel[0, 0, i]], [pos[0, 1, i], pos[0, 1, i] + vel[0, 1, i]], '--', color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.xlim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.ylim(np.min(pos)-1, np.max(pos) +1)\n",
    "    plt.plot([], [], 'd', color='black', label='initial position')\n",
    "    plt.plot([], [], 'x', color='black', label='final position')\n",
    "    plt.plot([], [], '--', color='black', label='initial velocity \\ndirection and magnitude')\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "d28681a6",
   "metadata": {
    "id": "d28681a6"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "random_idx = np.random.randint(0, 10000)\n",
    "plot_example(positions_train[random_idx], velocities_train[random_idx])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "059b633c",
   "metadata": {
    "id": "059b633c"
   },
   "source": [
    "# Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e6ecb529",
   "metadata": {
    "id": "e6ecb529"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "device = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "f8633eb8",
   "metadata": {
    "id": "f8633eb8"
   },
   "outputs": [],
   "source": [
    "\n",
    "class DatasetClass(Dataset):\n",
    "    def __init__(self, positions, velocities,charges):\n",
    "        \n",
    "        (samples,seq_length,dim,length) = positions.shape\n",
    "        # Get the initial positions\n",
    "        init_pos = positions[:,0,:,:]\n",
    "        init_pos = init_pos.reshape(samples,dim*length) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the initial velocities\n",
    "        init_vel = velocities.reshape(samples,dim*length) # Flatten x,y to a single list [x1,x2...,x5,y1,y2...,y5]\n",
    "        # Get the charges\n",
    "        c = charges.reshape(samples,length) # Flatten (samples,1,length) -> (samples,length)\n",
    "        # Create the feature array using initial state\n",
    "        features = np.concatenate((init_pos,init_vel,c),axis=1) # Concatenate initial information to a feature array\n",
    "        \n",
    "        #Create targets using positions in timesteps after the initial one and flattening the dimensions to a single list\n",
    "        targets = positions[:,1:,:,:].reshape(samples,seq_length - 1, dim*length)\n",
    "        \n",
    "        self.data = torch.FloatTensor(features)\n",
    "        self.targets = torch.FloatTensor(targets)\n",
    "        # Sanity checks\n",
    "        assert features.shape == (samples,dim*length*2 + length)\n",
    "        assert targets.shape == (samples,seq_length - 1, dim*length)\n",
    "        \n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "0a99a32b",
   "metadata": {
    "id": "0a99a32b"
   },
   "outputs": [],
   "source": [
    "train_dataset = DatasetClass(positions_train,velocities_train,charges_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=10)\n",
    "valid_dataset = DatasetClass(positions_valid, velocities_valid, charges_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=10)\n",
    "test_dataset = DatasetClass(positions_test, velocities_test, charges_test)\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "18b2874d",
   "metadata": {
    "id": "18b2874d"
   },
   "source": [
    "# Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "66774050",
   "metadata": {
    "id": "66774050"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "116991a2",
   "metadata": {},
   "source": [
    "![title](lstm.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "ba598378",
   "metadata": {
    "id": "ba598378"
   },
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class LSTMRegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(LSTMRegressor, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.rnn = nn.LSTMCell(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "\n",
    "    def forward(self, batch_input):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, seq_length, input_shape]\n",
    "        \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        c0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        hidden1, c1 = self.rnn(batch_input,(hidden0,c0))\n",
    "        hidden2, c2 = self.rnn(batch_input,(hidden1,c1)) # Feed same input to all for now\n",
    "        hidden3, c3 = self.rnn(batch_input,(hidden2,c2)) # Feed same input to all for now\n",
    "        \n",
    "        \n",
    "        # retrieve final hidden output of last timestep for each sequence\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        #last_timestep = out[:,-1]\n",
    "        \n",
    "        # apply dropout\n",
    "        #self.drop(last_timestep)\n",
    "        \n",
    "        # feed lstm output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        h1 = nn.ReLU()(self.fc1(hidden1))\n",
    "        output1 = self.fc2(h1)\n",
    "        h2 = nn.ReLU()(self.fc1(hidden2))\n",
    "        output2 = self.fc2(h2)\n",
    "        h3 = nn.ReLU()(self.fc1(hidden3))\n",
    "        output3 = self.fc2(h3)\n",
    "        #h = nn.ReLU()(h)\n",
    "        \n",
    "        y_preds = torch.stack((output1,output2,output3),axis=1) # (Batch_size,3,dim * length)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b131f1cf",
   "metadata": {},
   "source": [
    "![title](gru.png)\n",
    "![title](label.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "bf5500c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn\n",
    "class GRURegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim, hidden_dim,output_dim,device):\n",
    "        super(GRURegressor, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "    \n",
    "        self.rnn = nn.GRU(input_dim, hidden_dim)\n",
    "        \n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "        \n",
    "        #self.drop = nn.Dropout(p=0.5)\n",
    "        \n",
    "        self.criterion = nn.MSELoss()\n",
    "        \n",
    "        self.optimizer = torch.optim.Adam(self.parameters())\n",
    "        \n",
    "\n",
    "    def forward(self, batch_input):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, seq_length, input_shape]\n",
    "        \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        c0 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        hidden1, c1 = self.rnn(batch_input,(hidden0,c0))\n",
    "        hidden2, c2 = self.rnn(batch_input,(hidden1,c1)) # Feed same input to all for now\n",
    "        hidden3, c3 = self.rnn(batch_input,(hidden2,c2)) # Feed same input to all for now\n",
    "        \n",
    "        \n",
    "        # retrieve final hidden output of last timestep for each sequence\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        #last_timestep = out[:,-1]\n",
    "        \n",
    "        # apply dropout\n",
    "        #self.drop(last_timestep)\n",
    "        \n",
    "        # feed lstm output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        h1 = nn.ReLU()(self.fc1(hidden1))\n",
    "        output1 = self.fc2(h1)\n",
    "        h2 = nn.ReLU()(self.fc1(hidden2))\n",
    "        output2 = self.fc2(h2)\n",
    "        h3 = nn.ReLU()(self.fc1(hidden3))\n",
    "        output3 = self.fc2(h3)\n",
    "        #h = nn.ReLU()(h)\n",
    "        \n",
    "        y_preds = torch.stack((output1,output2,output3),axis=1) # (Batch_size,3,dim * length)\n",
    "        return y_preds"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dea70d73",
   "metadata": {
    "id": "dea70d73"
   },
   "source": [
    "# Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "3af520ae",
   "metadata": {
    "id": "3af520ae"
   },
   "outputs": [],
   "source": [
    "def save_model_checkpoint(path, model, optimizer, val_loss, val_acc, train_acc, train_loss ):\n",
    "    if path == None:\n",
    "        return print(\"Kindly define a path\")\n",
    "    path = path\n",
    "    \n",
    "    save_dict = {\"model_dict\" : model.state_dict(), \n",
    "                 \"optimizer_dict\": optimizer.state_dict(),\n",
    "                 \"val_loss_dict\": val_loss,\n",
    "                 \"val_acc_dict\": val_acc,\n",
    "                 \"train_acc_dict\": train_acc,\n",
    "                 \"train_loss_dict\": train_loss}\n",
    "    torch.save(save_dict, path)\n",
    "    return print(\"Model Saved to ==> {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "e95af5f9",
   "metadata": {
    "id": "e95af5f9"
   },
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train(model, train_loader, val_loader, criterion, num_epochs, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    cur_step = 0\n",
    "    train_pred = []\n",
    "    val_pred = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "  \n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for train_data, targets in train_loader:\n",
    "            \n",
    "           \n",
    "            # Forward\n",
    "            input_tensor = train_data.to(device)\n",
    "            outputs = model.forward(input_tensor)\n",
    "            loss = criterion(outputs,targets.to(device))\n",
    "            \n",
    "                \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            running_loss += loss\n",
    "          \n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(\"Train Pass Completed\")\n",
    "\n",
    "        ########################################|Validation Set|#############################################\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for val_data, val_targets in val_loader:\n",
    "                input_tensor = val_data.to(device)\n",
    "                outputs = model.forward(input_tensor)\n",
    "                loss = criterion(outputs,val_targets.to(device))\n",
    "                val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}' \n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss \n",
    "            save_model_checkpoint(save_name, model, optimizer, best_val_loss, 0, 0, avg_train_loss )\n",
    "    \n",
    "    print(\"Finished Training\") \n",
    "    return train_losses, val_losses\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "07e03ddf",
   "metadata": {
    "id": "07e03ddf"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/100],Train Loss: 1.7338, Valid Loss: 0.56551653\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/100],Train Loss: 0.5043, Valid Loss: 0.43483043\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/100],Train Loss: 0.4045, Valid Loss: 0.38587406\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/100],Train Loss: 0.3471, Valid Loss: 0.34214899\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/100],Train Loss: 0.3065, Valid Loss: 0.31607971\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/100],Train Loss: 0.2791, Valid Loss: 0.29593742\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/100],Train Loss: 0.2561, Valid Loss: 0.27490342\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/100],Train Loss: 0.2387, Valid Loss: 0.25953364\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/100],Train Loss: 0.2241, Valid Loss: 0.25022793\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/100],Train Loss: 0.2130, Valid Loss: 0.24167404\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/100],Train Loss: 0.2028, Valid Loss: 0.23520391\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/100],Train Loss: 0.1953, Valid Loss: 0.22716445\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/100],Train Loss: 0.1880, Valid Loss: 0.22278243\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 14\n",
      "Train Pass Completed\n",
      "Epoch [14/100],Train Loss: 0.1821, Valid Loss: 0.21806754\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 15\n",
      "Train Pass Completed\n",
      "Epoch [15/100],Train Loss: 0.1768, Valid Loss: 0.21328804\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 16\n",
      "Train Pass Completed\n",
      "Epoch [16/100],Train Loss: 0.1726, Valid Loss: 0.20971148\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 17\n",
      "Train Pass Completed\n",
      "Epoch [17/100],Train Loss: 0.1690, Valid Loss: 0.20892118\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 18\n",
      "Train Pass Completed\n",
      "Epoch [18/100],Train Loss: 0.1644, Valid Loss: 0.20750563\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 19\n",
      "Train Pass Completed\n",
      "Epoch [19/100],Train Loss: 0.1616, Valid Loss: 0.20314725\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 20\n",
      "Train Pass Completed\n",
      "Epoch [20/100],Train Loss: 0.1589, Valid Loss: 0.19981550\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 21\n",
      "Train Pass Completed\n",
      "Epoch [21/100],Train Loss: 0.1564, Valid Loss: 0.19923854\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 22\n",
      "Train Pass Completed\n",
      "Epoch [22/100],Train Loss: 0.1536, Valid Loss: 0.19516559\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 23\n",
      "Train Pass Completed\n",
      "Epoch [23/100],Train Loss: 0.1507, Valid Loss: 0.19479044\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 24\n",
      "Train Pass Completed\n",
      "Epoch [24/100],Train Loss: 0.1479, Valid Loss: 0.19317694\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 25\n",
      "Train Pass Completed\n",
      "Epoch [25/100],Train Loss: 0.1461, Valid Loss: 0.19157873\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 26\n",
      "Train Pass Completed\n",
      "Epoch [26/100],Train Loss: 0.1438, Valid Loss: 0.19076639\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 27\n",
      "Train Pass Completed\n",
      "Epoch [27/100],Train Loss: 0.1424, Valid Loss: 0.19026613\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 28\n",
      "Train Pass Completed\n",
      "Epoch [28/100],Train Loss: 0.1402, Valid Loss: 0.19011910\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 29\n",
      "Train Pass Completed\n",
      "Epoch [29/100],Train Loss: 0.1387, Valid Loss: 0.18851508\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 30\n",
      "Train Pass Completed\n",
      "Epoch [30/100],Train Loss: 0.1368, Valid Loss: 0.18670960\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 31\n",
      "Train Pass Completed\n",
      "Epoch [31/100],Train Loss: 0.1352, Valid Loss: 0.18542884\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 32\n",
      "Train Pass Completed\n",
      "Epoch [32/100],Train Loss: 0.1338, Valid Loss: 0.18553375\n",
      "Starting epoch 33\n",
      "Train Pass Completed\n",
      "Epoch [33/100],Train Loss: 0.1323, Valid Loss: 0.18215495\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 34\n",
      "Train Pass Completed\n",
      "Epoch [34/100],Train Loss: 0.1307, Valid Loss: 0.18189643\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 35\n",
      "Train Pass Completed\n",
      "Epoch [35/100],Train Loss: 0.1294, Valid Loss: 0.18038872\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 36\n",
      "Train Pass Completed\n",
      "Epoch [36/100],Train Loss: 0.1279, Valid Loss: 0.18228132\n",
      "Starting epoch 37\n",
      "Train Pass Completed\n",
      "Epoch [37/100],Train Loss: 0.1271, Valid Loss: 0.18023035\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 38\n",
      "Train Pass Completed\n",
      "Epoch [38/100],Train Loss: 0.1254, Valid Loss: 0.17877075\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 39\n",
      "Train Pass Completed\n",
      "Epoch [39/100],Train Loss: 0.1244, Valid Loss: 0.17659397\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 40\n",
      "Train Pass Completed\n",
      "Epoch [40/100],Train Loss: 0.1237, Valid Loss: 0.17741169\n",
      "Starting epoch 41\n",
      "Train Pass Completed\n",
      "Epoch [41/100],Train Loss: 0.1220, Valid Loss: 0.17671777\n",
      "Starting epoch 42\n",
      "Train Pass Completed\n",
      "Epoch [42/100],Train Loss: 0.1209, Valid Loss: 0.17559859\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 43\n",
      "Train Pass Completed\n",
      "Epoch [43/100],Train Loss: 0.1203, Valid Loss: 0.17523356\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 44\n",
      "Train Pass Completed\n",
      "Epoch [44/100],Train Loss: 0.1191, Valid Loss: 0.17540579\n",
      "Starting epoch 45\n",
      "Train Pass Completed\n",
      "Epoch [45/100],Train Loss: 0.1179, Valid Loss: 0.17663832\n",
      "Starting epoch 46\n",
      "Train Pass Completed\n",
      "Epoch [46/100],Train Loss: 0.1175, Valid Loss: 0.17312013\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 47\n",
      "Train Pass Completed\n",
      "Epoch [47/100],Train Loss: 0.1165, Valid Loss: 0.17299244\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 48\n",
      "Train Pass Completed\n",
      "Epoch [48/100],Train Loss: 0.1153, Valid Loss: 0.17294982\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 49\n",
      "Train Pass Completed\n",
      "Epoch [49/100],Train Loss: 0.1147, Valid Loss: 0.17057750\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 50\n",
      "Train Pass Completed\n",
      "Epoch [50/100],Train Loss: 0.1138, Valid Loss: 0.17371221\n",
      "Starting epoch 51\n",
      "Train Pass Completed\n",
      "Epoch [51/100],Train Loss: 0.1129, Valid Loss: 0.17151318\n",
      "Starting epoch 52\n",
      "Train Pass Completed\n",
      "Epoch [52/100],Train Loss: 0.1120, Valid Loss: 0.17055109\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 53\n",
      "Train Pass Completed\n",
      "Epoch [53/100],Train Loss: 0.1112, Valid Loss: 0.17048626\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 54\n",
      "Train Pass Completed\n",
      "Epoch [54/100],Train Loss: 0.1108, Valid Loss: 0.17019922\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 55\n",
      "Train Pass Completed\n",
      "Epoch [55/100],Train Loss: 0.1101, Valid Loss: 0.17004302\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 56\n",
      "Train Pass Completed\n",
      "Epoch [56/100],Train Loss: 0.1094, Valid Loss: 0.17086019\n",
      "Starting epoch 57\n",
      "Train Pass Completed\n",
      "Epoch [57/100],Train Loss: 0.1086, Valid Loss: 0.17025092\n",
      "Starting epoch 58\n",
      "Train Pass Completed\n",
      "Epoch [58/100],Train Loss: 0.1078, Valid Loss: 0.16793346\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 59\n",
      "Train Pass Completed\n",
      "Epoch [59/100],Train Loss: 0.1072, Valid Loss: 0.16994213\n",
      "Starting epoch 60\n",
      "Train Pass Completed\n",
      "Epoch [60/100],Train Loss: 0.1066, Valid Loss: 0.16932231\n",
      "Starting epoch 61\n",
      "Train Pass Completed\n",
      "Epoch [61/100],Train Loss: 0.1062, Valid Loss: 0.16855903\n",
      "Starting epoch 62\n",
      "Train Pass Completed\n",
      "Epoch [62/100],Train Loss: 0.1057, Valid Loss: 0.16887183\n",
      "Starting epoch 63\n",
      "Train Pass Completed\n",
      "Epoch [63/100],Train Loss: 0.1049, Valid Loss: 0.16723457\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 64\n",
      "Train Pass Completed\n",
      "Epoch [64/100],Train Loss: 0.1044, Valid Loss: 0.16738532\n",
      "Starting epoch 65\n",
      "Train Pass Completed\n",
      "Epoch [65/100],Train Loss: 0.1040, Valid Loss: 0.16796656\n",
      "Starting epoch 66\n",
      "Train Pass Completed\n",
      "Epoch [66/100],Train Loss: 0.1034, Valid Loss: 0.16712838\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 67\n",
      "Train Pass Completed\n",
      "Epoch [67/100],Train Loss: 0.1027, Valid Loss: 0.16794051\n",
      "Starting epoch 68\n",
      "Train Pass Completed\n",
      "Epoch [68/100],Train Loss: 0.1024, Valid Loss: 0.16786323\n",
      "Starting epoch 69\n",
      "Train Pass Completed\n",
      "Epoch [69/100],Train Loss: 0.1018, Valid Loss: 0.16726047\n",
      "Starting epoch 70\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass Completed\n",
      "Epoch [70/100],Train Loss: 0.1014, Valid Loss: 0.16614254\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 71\n",
      "Train Pass Completed\n",
      "Epoch [71/100],Train Loss: 0.1010, Valid Loss: 0.16670536\n",
      "Starting epoch 72\n",
      "Train Pass Completed\n",
      "Epoch [72/100],Train Loss: 0.1000, Valid Loss: 0.16573808\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 73\n",
      "Train Pass Completed\n",
      "Epoch [73/100],Train Loss: 0.0997, Valid Loss: 0.16699180\n",
      "Starting epoch 74\n",
      "Train Pass Completed\n",
      "Epoch [74/100],Train Loss: 0.0995, Valid Loss: 0.16705044\n",
      "Starting epoch 75\n",
      "Train Pass Completed\n",
      "Epoch [75/100],Train Loss: 0.0990, Valid Loss: 0.16674715\n",
      "Starting epoch 76\n",
      "Train Pass Completed\n",
      "Epoch [76/100],Train Loss: 0.0985, Valid Loss: 0.16640814\n",
      "Starting epoch 77\n",
      "Train Pass Completed\n",
      "Epoch [77/100],Train Loss: 0.0981, Valid Loss: 0.16520455\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 78\n",
      "Train Pass Completed\n",
      "Epoch [78/100],Train Loss: 0.0977, Valid Loss: 0.16619679\n",
      "Starting epoch 79\n",
      "Train Pass Completed\n",
      "Epoch [79/100],Train Loss: 0.0975, Valid Loss: 0.16597268\n",
      "Starting epoch 80\n",
      "Train Pass Completed\n",
      "Epoch [80/100],Train Loss: 0.0968, Valid Loss: 0.16629563\n",
      "Starting epoch 81\n",
      "Train Pass Completed\n",
      "Epoch [81/100],Train Loss: 0.0962, Valid Loss: 0.16631834\n",
      "Starting epoch 82\n",
      "Train Pass Completed\n",
      "Epoch [82/100],Train Loss: 0.0961, Valid Loss: 0.16554661\n",
      "Starting epoch 83\n",
      "Train Pass Completed\n",
      "Epoch [83/100],Train Loss: 0.0957, Valid Loss: 0.16545688\n",
      "Starting epoch 84\n",
      "Train Pass Completed\n",
      "Epoch [84/100],Train Loss: 0.0956, Valid Loss: 0.16652651\n",
      "Starting epoch 85\n",
      "Train Pass Completed\n",
      "Epoch [85/100],Train Loss: 0.0951, Valid Loss: 0.16511020\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 86\n",
      "Train Pass Completed\n",
      "Epoch [86/100],Train Loss: 0.0946, Valid Loss: 0.16638784\n",
      "Starting epoch 87\n",
      "Train Pass Completed\n",
      "Epoch [87/100],Train Loss: 0.0941, Valid Loss: 0.16572365\n",
      "Starting epoch 88\n",
      "Train Pass Completed\n",
      "Epoch [88/100],Train Loss: 0.0939, Valid Loss: 0.16615134\n",
      "Starting epoch 89\n",
      "Train Pass Completed\n",
      "Epoch [89/100],Train Loss: 0.0935, Valid Loss: 0.16751413\n",
      "Starting epoch 90\n",
      "Train Pass Completed\n",
      "Epoch [90/100],Train Loss: 0.0933, Valid Loss: 0.16674000\n",
      "Starting epoch 91\n",
      "Train Pass Completed\n",
      "Epoch [91/100],Train Loss: 0.0927, Valid Loss: 0.16485965\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 92\n",
      "Train Pass Completed\n",
      "Epoch [92/100],Train Loss: 0.0924, Valid Loss: 0.16706701\n",
      "Starting epoch 93\n",
      "Train Pass Completed\n",
      "Epoch [93/100],Train Loss: 0.0924, Valid Loss: 0.16412306\n",
      "Model Saved to ==> LSTM_reg.pt\n",
      "Starting epoch 94\n",
      "Train Pass Completed\n",
      "Epoch [94/100],Train Loss: 0.0918, Valid Loss: 0.16595542\n",
      "Starting epoch 95\n",
      "Train Pass Completed\n",
      "Epoch [95/100],Train Loss: 0.0914, Valid Loss: 0.16535644\n",
      "Starting epoch 96\n",
      "Train Pass Completed\n",
      "Epoch [96/100],Train Loss: 0.0909, Valid Loss: 0.16599590\n",
      "Starting epoch 97\n",
      "Train Pass Completed\n",
      "Epoch [97/100],Train Loss: 0.0910, Valid Loss: 0.16663922\n",
      "Starting epoch 98\n",
      "Train Pass Completed\n",
      "Epoch [98/100],Train Loss: 0.0906, Valid Loss: 0.16510227\n",
      "Starting epoch 99\n",
      "Train Pass Completed\n",
      "Epoch [99/100],Train Loss: 0.0902, Valid Loss: 0.16626045\n",
      "Starting epoch 100\n",
      "Train Pass Completed\n",
      "Epoch [100/100],Train Loss: 0.0900, Valid Loss: 0.16604753\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "LSTM_reg = LSTMRegressor(25,192,10,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(LSTM_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'LSTM_reg.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(LSTM_reg, \n",
    "                                                      train_loader, valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "95ab5fce",
   "metadata": {},
   "outputs": [
    {
     "ename": "AssertionError",
     "evalue": "Torch not compiled with CUDA enabled",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAssertionError\u001b[0m                            Traceback (most recent call last)",
      "Input \u001b[0;32mIn [21]\u001b[0m, in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0m LSTM_reg \u001b[38;5;241m=\u001b[39m \u001b[43mGRURegressor\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m25\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m192\u001b[39;49m\u001b[43m,\u001b[49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda:0\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m optimizer \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39moptim\u001b[38;5;241m.\u001b[39mSGD(LSTM_reg\u001b[38;5;241m.\u001b[39mparameters(), lr\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.01\u001b[39m, momentum\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0.9\u001b[39m)\n\u001b[1;32m      4\u001b[0m num_epochs \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m100\u001b[39m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda\u001b[0;34m(self, device)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43;01mlambda\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:578\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    576\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[1;32m    577\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mchildren():\n\u001b[0;32m--> 578\u001b[0m         \u001b[43mmodule\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    580\u001b[0m     \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcompute_should_use_set_data\u001b[39m(tensor, tensor_applied):\n\u001b[1;32m    581\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m torch\u001b[38;5;241m.\u001b[39m_has_compatible_shallow_copy_type(tensor, tensor_applied):\n\u001b[1;32m    582\u001b[0m             \u001b[38;5;66;03m# If the new tensor has compatible tensor type as the existing tensor,\u001b[39;00m\n\u001b[1;32m    583\u001b[0m             \u001b[38;5;66;03m# the current behavior is to change the tensor in-place using `.data =`,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    588\u001b[0m             \u001b[38;5;66;03m# global flag to let the user control whether they want the future\u001b[39;00m\n\u001b[1;32m    589\u001b[0m             \u001b[38;5;66;03m# behavior of overwriting the existing tensor or not.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/rnn.py:182\u001b[0m, in \u001b[0;36mRNNBase._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    181\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m_apply\u001b[39m(\u001b[38;5;28mself\u001b[39m, fn):\n\u001b[0;32m--> 182\u001b[0m     ret \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mRNNBase\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_apply\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    184\u001b[0m     \u001b[38;5;66;03m# Resets _flat_weights\u001b[39;00m\n\u001b[1;32m    185\u001b[0m     \u001b[38;5;66;03m# Note: be v. careful before removing this, as 3rd party device types\u001b[39;00m\n\u001b[1;32m    186\u001b[0m     \u001b[38;5;66;03m# likely rely on this behavior to properly .to() modules like LSTM.\u001b[39;00m\n\u001b[1;32m    187\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights \u001b[38;5;241m=\u001b[39m [(\u001b[38;5;28;01mlambda\u001b[39;00m wn: \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(\u001b[38;5;28mself\u001b[39m, wn) \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m)(wn) \u001b[38;5;28;01mfor\u001b[39;00m wn \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_flat_weights_names]\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:601\u001b[0m, in \u001b[0;36mModule._apply\u001b[0;34m(self, fn)\u001b[0m\n\u001b[1;32m    597\u001b[0m \u001b[38;5;66;03m# Tensors stored in modules are graph leaves, and we don't want to\u001b[39;00m\n\u001b[1;32m    598\u001b[0m \u001b[38;5;66;03m# track autograd history of `param_applied`, so we have to use\u001b[39;00m\n\u001b[1;32m    599\u001b[0m \u001b[38;5;66;03m# `with torch.no_grad():`\u001b[39;00m\n\u001b[1;32m    600\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m--> 601\u001b[0m     param_applied \u001b[38;5;241m=\u001b[39m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mparam\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    602\u001b[0m should_use_set_data \u001b[38;5;241m=\u001b[39m compute_should_use_set_data(param, param_applied)\n\u001b[1;32m    603\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m should_use_set_data:\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/nn/modules/module.py:688\u001b[0m, in \u001b[0;36mModule.cuda.<locals>.<lambda>\u001b[0;34m(t)\u001b[0m\n\u001b[1;32m    671\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcuda\u001b[39m(\u001b[38;5;28mself\u001b[39m: T, device: Optional[Union[\u001b[38;5;28mint\u001b[39m, device]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m T:\n\u001b[1;32m    672\u001b[0m     \u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Moves all model parameters and buffers to the GPU.\u001b[39;00m\n\u001b[1;32m    673\u001b[0m \n\u001b[1;32m    674\u001b[0m \u001b[38;5;124;03m    This also makes associated parameters and buffers different objects. So\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    686\u001b[0m \u001b[38;5;124;03m        Module: self\u001b[39;00m\n\u001b[1;32m    687\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 688\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_apply(\u001b[38;5;28;01mlambda\u001b[39;00m t: \u001b[43mt\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcuda\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdevice\u001b[49m\u001b[43m)\u001b[49m)\n",
      "File \u001b[0;32m~/anaconda3/lib/python3.8/site-packages/torch/cuda/__init__.py:210\u001b[0m, in \u001b[0;36m_lazy_init\u001b[0;34m()\u001b[0m\n\u001b[1;32m    206\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[1;32m    207\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCannot re-initialize CUDA in forked subprocess. To use CUDA with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m    208\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmultiprocessing, you must use the \u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mspawn\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m start method\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    209\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(torch\u001b[38;5;241m.\u001b[39m_C, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m_cuda_getDeviceCount\u001b[39m\u001b[38;5;124m'\u001b[39m):\n\u001b[0;32m--> 210\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mTorch not compiled with CUDA enabled\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m    211\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m _cudart \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    212\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mAssertionError\u001b[39;00m(\n\u001b[1;32m    213\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mlibcudart functions unavailable. It looks like you have a broken build?\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mAssertionError\u001b[0m: Torch not compiled with CUDA enabled"
     ]
    }
   ],
   "source": [
    "LSTM_reg = GRURegressor(25,192,10,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(LSTM_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "num_epochs = 100\n",
    "save_name = f'LSTM_reg.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(LSTM_reg, \n",
    "                                                      train_loader, valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5fb3b29",
   "metadata": {
    "id": "d5fb3b29"
   },
   "source": [
    "# Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf5fa1b4",
   "metadata": {
    "id": "bf5fa1b4"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "ed4a1a12",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Evaluating on the validation set\n",
    "\n",
    "def evaluate(model, test_loader,device='cpu'):\n",
    "    val_running_loss = 0.0\n",
    "    preds = []\n",
    "    actual = []\n",
    "    with torch.no_grad():\n",
    "        model.eval()\n",
    "        for val_data, val_targets in test_loader:\n",
    "            input_tensor = val_data.to(device)\n",
    "            outputs = model.forward(input_tensor)\n",
    "            preds.append(outputs)\n",
    "            actual.append(val_targets)\n",
    "            loss = criterion(outputs,val_targets.to(device))\n",
    "            val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(test_loader)\n",
    "        print(\"Average Test Loss: {:4f}\".format(avg_val_loss))\n",
    "        return preds,actual"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "2280031f",
   "metadata": {
    "id": "2280031f"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Average Test Loss: 0.176486\n"
     ]
    }
   ],
   "source": [
    "#Model Evaluation\n",
    "model = LSTMRegressor(25,192,10,'cpu')\n",
    "checkpoint = torch.load('LSTM_reg.pt', map_location = 'cpu')\n",
    "model.load_state_dict(checkpoint['model_dict'])\n",
    "\n",
    "preds,actual = evaluate(model, test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "1a334b02",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_positions(preds_sample, actual_sample):\n",
    "\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    colors = ['red', 'blue', 'green', 'orange', 'brown']\n",
    "    for i in range(5):\n",
    "        plt.plot(preds_sample[i],preds_sample[i+5],'o',color=colors[i])\n",
    "        plt.plot(actual_sample[i],actual_sample[i+5],'x',color=colors[i])\n",
    "    fig.set_size_inches(7, 7)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.show()\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "3a8240f1",
   "metadata": {
    "id": "3a8240f1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][0], actual[0][0][0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "a2561c4f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAGbCAYAAACVqdT+AAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/YYfK9AAAACXBIWXMAAAsTAAALEwEAmpwYAAASFUlEQVR4nO3df6jl9X3n8ddbHRiGuinorGYdnTuw+8eKJhTumIWE7U4MJW2nzT9l2Pa2UFoYGLYQYXal6WDKKv5jSWtpy4RLXFjoXcLQH1sqLa3J3mWxUDtXq/lh2my2Rjs22hu3tIWLW00++8eZ6zi/nLlzj/e8r/fxADl+P+f6/b45qM/5/rj31hgjANDVdbMeAADeiVAB0JpQAdCaUAHQmlAB0NoNszjozTffPObm5mZxaACaevrpp789xth74fpMQjU3N5eVlZVZHBqApqrqxUutu/QHQGtCBUBrQgVAazO5RwXAe9sbb7yRM2fO5PXXX7/ovd27d2ffvn3ZtWvXVe1LqACYujNnzuTGG2/M3Nxcquqt9TFGXnvttZw5cyYHDhy4qn259AfA1L3++uu56aabzotUklRVbrrppkueaV2OUAHwrrgwUldavxyhAqA1oQKgNaEC4F1xuV/Mu9Ff2CtUAEzd7t2789prr10UpfWn/nbv3n3V+/J4OgBTt2/fvpw5cyarq6sXvbf+fVRXS6gAmLpdu3Zd9fdJXYlLfwC0JlQAtCZUALQmVAC0JlQAtCZUALQmVAC0JlQAtCZUALQmVAC0JlQAtCZUALQmVAC0JlQAtCZUALQmVAC0JlQAtCZUALQmVAC0JlQAtDa1UFXV9VX151X1+LT2CQDTPKP6ZJKvTXF/ADCdUFXVviQ/nORz09gfAKyb1hnVo0nuT/Ldy31BVR2tqpWqWlldXZ3SYQF4r9t0qKrqcJK/HWM8/U5fN8ZYHGPMjzHm9+7du9nDArBDTOOM6sNJfrSqvpnk80k+WlW/OYX9AsDmQzXG+NQYY98YYy7Jv0/yP8YYP7npyQAgvo8KgOamGqoxxv8cYxye5j4BpuqFpeS/zyX/7brJ6wtLs56IK7hh1gMAbJkXlpI/O5p8Z22yvfbiZDtJDizMbi7ekUt/wM7x3IlzkVr3nbXJOm0JFbBzrL20sXVaECpg59hzx8bWaUGogJ3jgw8n1+85f612JXMX3J96dTl5/pGtm4t3JFTAznFgIblnMdmzP0lNXv/1f0r+z+IkTsnk9ckjyU0HZzoq53jqD9hZDixc/ITf+z82idO/Opb875PJR04ltxyazXxcxBkVwC2HJpH6ykOTV5FqRagAXl2enEnd9cDkdf0yIC0IFbCzrd+T+sip5AMPTl6fPCJWjQgVsLO9dvr8e1K3HJpsv3Z6tnPxFg9TADvbnfdfvHbLIfepGnFGBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrmw5VVd1eVctV9XxVfbWqPjmNwQAgSW6Ywj7eTHJ8jPFMVd2Y5OmqemKM8fwU9g3ADrfpM6oxxrfGGM+c/ft/TPK1JLdtdr8AkEz5HlVVzSX5viRPXeK9o1W1UlUrq6ur0zwsAO9hUwtVVX1Pkt9Oct8Y4x8ufH+MsTjGmB9jzO/du3dahwXgPW4qoaqqXZlEammM8TvT2CcAJNN56q+SPJbka2OMX978SABwzjTOqD6c5KeSfLSqnj371w9NYb8AsPnH08cYTyapKcwCABfxkykAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqABoTagAaE2oAGhNqKbs+ccey6tPPXXe2qtPPZXnH3tsRhMBbG9CNWU33XVXnjx+/K1YvfrUU3ny+PHcdNddM54MYHsSqim75UMfykc+85k8efx4vvRrv5Ynjx/PRz7zmdzyoQ/NejS4OktLydxcct11k9elpVlPxA53w6wHeK954fHH89yjj+b//d3f5Suf/Wxuu/dekWL7WFpKjh5N1tYm2y++ONlOkoWF2c3FjuaMaopeePzx/Nkv/mLWvvWtt9Ze/uIX8+yv/uoMp4INOHHiXKTWra1N1mFGhGqKnnv00Xzn9dcvWn/+c5+76AELaOmllza2DltAqKZo7ZVXLv3Gd7+b177yla0dBq7FHXdsbB22gFBN0Z5bb730+vvfnzt/9me3eBq4Bg8/nOzZc/7anj2TdZgRoZqiD953X67fvfu8tet3784H77tvNgPBRi0sJIuLyf79SdXkdXHRgxTMlKf+pujA4cNJJveq1l55JXtuvTUfvO++t9ZhW1hYECZaEaopO3D4sDABTJFLfwC0JlQAtCZUALQmVAC0JlQAtCZUALQmVAC0JlQAtCZUwPkeeSRZXj5/bXl5sg4zMJVQVdXHq+ovq+obVfXz09gnMCMHDyZHjpyL1fLyZPvgwdnOxY616VBV1fVJfiPJDya5M8mPV9Wdm90vMCOHDiWnTk3i9OlPT15PnZqswwxM44zqniTfGGP81Rjjn5J8PsknprBfYFYOHUqOHUseemjyKlLM0DRCdVuSv37b9pmza8B2tbycnDyZPPDA5PXCe1awhbbsYYqqOlpVK1W1srq6ulWHBTZq/Z7UqVPJgw+euwwoVszINEL1cpLb37a97+zaecYYi2OM+THG/N69e6dwWOBdcfr0+fek1u9ZnT4927nYsWqMsbkdVN2Q5OtJ7s0kUKeT/MQY46uX+2fm5+fHysrKpo4LwHtLVT09xpi/cH3TvzhxjPFmVf1ckj9Kcn2S//JOkQKAjZjKb/gdY/xBkj+Yxr4A4O38ZAoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFoTKgBaEypoYOnLS5l7dC7X/efrMvfoXJa+vDTrkaCNG2Y9AOx0S19eytHfP5q1N9aSJC/+/Ys5+vtHkyQLdy/McjRowRkVzNiJL554K1Lr1t5Yy4kvnpjRRNCLUMGMvfT3L21oHXYaoYIZu+N9d2xoHXYaoYIZe/jeh7Nn157z1vbs2pOH7314RhNBL0IFM7Zw90IWf2Qx+9+3P5XK/vftz+KPLL7rD1I88iePZPmF5fPWll9YziN/8si7elzYKE/9QQMLdy9s+RN+B//FwRz5rSM59WOncujAoSy/sPzWNnQiVLBDHTpwKKd+7FSO/NaRHJs/lpMrJ9+KFnTi0h9ssUceSZbPv+KW5eXJ+lY7dOBQjs0fy0P/66Ecmz8mUrQkVLDFDh5Mjhw5F6vl5cn2wYNbP8vyC8s5uXIyD/zbB3Jy5eRF96ygA6GCLXboUHLq1CROn/705PXUqcn6Vnr7PakHDz341mVAsaIboYIZOHQoOXYseeihyetWRypJTv/N6fPuSa3fszr9N6e3fhh4BzXG2PKDzs/Pj5WVlS0/LnSxfrnv2LHk5MnZnFFBN1X19Bhj/sJ1Z1SwxdYjdepU8uCD5y4DXviABTAhVLDFTp8+/wxq/Z7VaVfc4JJc+gOghXfl0l9V/VJV/UVVfamqfreqvncz+wOAC2320t8TSe4aY3wgydeTfGrzIwHAOZsK1Rjjj8cYb57d/NMk+zY/EgCcM82HKX4myR9e7s2qOlpVK1W1srq6OsXDAvBedsUfSltVX0hy6yXeOjHG+L2zX3MiyZtJli63nzHGYpLFZPIwxTVNC8COc8UzqjHGx8YYd13ir/VI/XSSw0kWxiweIQSu2tJSMjeXXHfd5HXpsn+0hD429Ws+qurjSe5P8v1jjLXpjAS8G5aWkqNHk7Wz/6W++OJkO0kWtvZXYcGGbPYe1a8nuTHJE1X1bFV9dgozAe+CEyfORWrd2tpkHTrb1BnVGONfTmsQ4N310ksbW4cu/Agl2CHuuGNj69CFUMEO8fDDyZ4956/t2TNZh86ECnaIhYVkcTHZvz+pmrwuLnqQgv42dY8K2F4WFoSJ7ccZFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK0JFQCtCRUArQkVAK1NJVRVdbyqRlXdPI39AcC6TYeqqm5P8gNJXtr8OABwvmmcUf1KkvuTjCnsCwDOs6lQVdUnkrw8xnjuKr72aFWtVNXK6urqZg4LwA5yw5W+oKq+kOTWS7x1IskvZHLZ74rGGItJFpNkfn7e2RcAV+WKoRpjfOxS61V1d5IDSZ6rqiTZl+SZqrpnjPHKVKcEYMe6YqguZ4zx5ST/fH27qr6ZZH6M8e0pzAUASXwfFQDNXfMZ1YXGGHPT2hcArHNGBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAa0IFQGtCBUBrQgVAazXG2PqDVq0meXHLD3x1bk7y7VkPsQ353K6Nz+3a+NyuTffPbf8YY++FizMJVWdVtTLGmJ/1HNuNz+3a+Nyujc/t2mzXz82lPwBaEyoAWhOqiy3OeoBtyud2bXxu18bndm225efmHhUArTmjAqA1oQKgNaF6B1V1vKpGVd0861m2g6r6par6i6r6UlX9blV976xn6qyqPl5Vf1lV36iqn5/1PNtBVd1eVctV9XxVfbWqPjnrmbaTqrq+qv68qh6f9SwbIVSXUVW3J/mBJC/NepZt5Ikkd40xPpDk60k+NeN52qqq65P8RpIfTHJnkh+vqjtnO9W28GaS42OMO5P8myT/wee2IZ9M8rVZD7FRQnV5v5Lk/iSeNrlKY4w/HmO8eXbzT5Psm+U8zd2T5BtjjL8aY/xTks8n+cSMZ2pvjPGtMcYzZ//+HzP5n+5ts51qe6iqfUl+OMnnZj3LRgnVJVTVJ5K8PMZ4btazbGM/k+QPZz1EY7cl+eu3bZ+J/+FuSFXNJfm+JE/NeJTt4tFM/vD93RnPsWE3zHqAWamqLyS59RJvnUjyC5lc9uMC7/S5jTF+7+zXnMjkEs3SVs7GzlFV35Pkt5PcN8b4h1nP011VHU7yt2OMp6vq3814nA3bsaEaY3zsUutVdXeSA0meq6pkcvnqmaq6Z4zxyhaO2NLlPrd1VfXTSQ4nuXf4Jr138nKS29+2ve/sGldQVbsyidTSGON3Zj3PNvHhJD9aVT+UZHeSf1ZVvznG+MkZz3VVfMPvFVTVN5PMjzE6/8ThFqrq40l+Ocn3jzFWZz1PZ1V1QyYPnNybSaBOJ/mJMcZXZzpYczX50+N/TfJ/xxj3zXicbensGdV/HGMcnvEoV809Kqbp15PcmOSJqnq2qj4764G6OvvQyc8l+aNMHgg4JVJX5cNJfirJR8/+O/bs2bME3sOcUQHQmjMqAFoTKgBaEyoAWhMqAFoTKgBaEyoAWhMqAFr7/yw03lZB2CA5AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][1], actual[0][0][1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "4666f578",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "No artists with labels found to put in legend.  Note that artists whose label start with an underscore are ignored when legend() is called with no argument.\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 504x504 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plot_positions(preds[0][0][2], actual[0][0][2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cdac092",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "a2_skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
