{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "963690b2",
   "metadata": {
    "id": "963690b2"
   },
   "source": [
    "<a href=\"https://colab.research.google.com/github/vlamen/tue-deeplearning/blob/main/assignments/assignment_2_3/a3_skeleton.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd8459f1",
   "metadata": {
    "id": "bd8459f1"
   },
   "source": [
    "# Group Number:\n",
    "\n",
    "# Student 1:\n",
    "\n",
    "# Student 2:\n",
    "\n",
    "# Student 3:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dde28458",
   "metadata": {
    "id": "dde28458"
   },
   "source": [
    "# Downloading Data and Preliminaries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7d0580a5",
   "metadata": {
    "id": "7d0580a5"
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import matplotlib.pyplot as plt\n",
    "import matplotlib\n",
    "import numpy as np\n",
    "import torch\n",
    "from zipfile import ZipFile\n",
    "import requests\n",
    "import io"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "8ce00edc",
   "metadata": {
    "id": "8ce00edc"
   },
   "outputs": [],
   "source": [
    "def load_zip(url):\n",
    "    response = requests.get(url)\n",
    "    response.raise_for_status()\n",
    "    zipf = ZipFile(io.BytesIO(response.content))\n",
    "    return {name: zipf.read(name) for name in zipf.namelist()}\n",
    "\n",
    "def load_pickle(zipfile, fn):\n",
    "    return pickle.load(io.BytesIO(zipfile[fn]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb77a4be",
   "metadata": {
    "id": "bb77a4be"
   },
   "outputs": [],
   "source": [
    "data = load_zip('https://surfdrive.surf.nl/files/index.php/s/cwqGaS22KXgnXtg/download')\n",
    "\n",
    "    \n",
    "\"\"\"\n",
    "simulation_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_train = load_pickle(data, 'data/train/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_valid = load_pickle(data, 'data/valid/simulation.pickle')  # 3.1 + 3.2\n",
    "simulation_test = load_pickle(data, 'data/test/simulation.pickle')  # 3.1 + 3.2\n",
    "\n",
    "\"\"\"\n",
    "charges_{train, valid, test} is stored as a list of simulation-charges. \n",
    "These charges are stored as numpy arrays of size (3,): One value for each charge.\n",
    "\"\"\"\n",
    "charges_train = load_pickle(data, 'data/train/charges.pickle')  # 3.1\n",
    "charges_valid = load_pickle(data, 'data/valid/charges.pickle')  # 3.1\n",
    "charges_test = load_pickle(data, 'data/test/charges.pickle')  # 3.1\n",
    "\n",
    "\"\"\"\n",
    "simulation_continued_{train, valid, test} is stored as a list of simulations. \n",
    "Each simulation is a numpy array of size (t, 2): For t timesteps an x and y coordinate of our particle.\n",
    "\"\"\"\n",
    "simulation_continued_train = load_pickle(data, 'data/train/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_valid = load_pickle(data, 'data/valid/simulation_continued.pickle')  # 3.2\n",
    "simulation_continued_test = load_pickle(data, 'data/test/simulation_continued.pickle')  # 3.2\n",
    "\n",
    "\"\"\"\n",
    "Note that the indices are shared throughout the different lists, e.g., for the 4th training simulation:\n",
    "simulation_train[3] contains its initial simulation\n",
    "charges_train[3] contains the charges associated with the simulation\n",
    "simulation_continued_train[3] contains the continuation of the simulation \n",
    "                --> simulation_continued_train[3][0] is the state after simulation_train[3][-1]\n",
    "\"\"\"\n",
    "pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "10a3438a",
   "metadata": {
    "id": "10a3438a",
    "outputId": "b99a6a67-d0e0-45fa-8c00-74432af57e14"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overview of no. datapoints:\n",
      "\n",
      "Task 3.1:\n",
      "800 train, 100 validation, 100 test simulations\n",
      "800 train, 100 validation, 100 test charge pairs\n",
      "\n",
      "Task 3.2:\n",
      "Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations\n",
      "We cut simulation_train down to the first 150 samples in simulation_train_task32\n",
      "150 train, 100 validation, 100 test simulations\n",
      "150 train, 100 validation, 100 test continuations\n",
      "\n",
      "For task 3.1, use:\n",
      "simulation_train + charges_train\n",
      "simulation_valid + charges_valid\n",
      "simulation_test + charges_test\n",
      "\n",
      "For task 3.2, use:\n",
      "simulation_train_task32 + simulation_continued_train\n",
      "simulation_valid + simulation_continued_valid\n",
      "simulation_test + simulation_continued_test\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Overview of no. datapoints:\\n')\n",
    "\n",
    "print('Task 3.1:')\n",
    "print(f'{len(simulation_train)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(charges_train)} train, {len(charges_valid)} validation, {len(charges_test)} test charge pairs')\n",
    "print()\n",
    "\n",
    "print('Task 3.2:')\n",
    "print('Since len(simulation_continued_train) < len(simulation_train), we can only use a subset of initial simulations')\n",
    "print('We cut simulation_train down to the first 150 samples in simulation_train_task32')\n",
    "simulation_train_task32 = simulation_train[:150]\n",
    "print(f'{len(simulation_train_task32)} train, {len(simulation_valid)} validation, {len(simulation_test)} test simulations')\n",
    "print(f'{len(simulation_continued_train)} train, {len(simulation_continued_valid)} validation, {len(simulation_continued_test)} test continuations')\n",
    "\n",
    "print(f\"\"\"\n",
    "For task 3.1, use:\n",
    "{chr(10).join([\"simulation_{} + charges_{}\".format(t, t) for t in [\"train\", \"valid\", \"test\"]])}\n",
    "\n",
    "For task 3.2, use:\n",
    "{chr(10).join([\"simulation_{} + simulation_continued_{}\".format(*((t[0], t[1]) if isinstance(t, tuple) else (t, t))) for t in [(\"train_task32\", \"train\"), \"valid\", \"test\"]])}\n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3cfafdb3",
   "metadata": {
    "id": "3cfafdb3",
    "outputId": "9d36c17b-2b41-4b9e-fcb2-c7265c1e0b6e"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Print some shapes:\n",
      "\n",
      "simulation_train[0].shape: (103, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[0].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[0].shape: (54, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[1].shape: (97, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[1].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[1].shape: (45, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n",
      "simulation_train[2].shape: (99, 2) -> (t, 2), (x, y) at every t)\n",
      "charges_train[2].shape: (3,) -> charges for the simulation\n",
      "simulation_continued_train[2].shape: (47, 2) -> (t, 2), (x, y) at every t)\n",
      "----\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print('Print some shapes:\\n')\n",
    "for i in range(3):\n",
    "    print('simulation_train[{}].shape:'.format(i), simulation_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('charges_train[{}].shape:'.format(i), charges_train[i].shape, '-> charges for the simulation')\n",
    "    print('simulation_continued_train[{}].shape:'.format(i), simulation_continued_train[i].shape, '-> (t, 2), (x, y) at every t)')\n",
    "    print('----\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f9106543",
   "metadata": {
    "id": "f9106543"
   },
   "outputs": [],
   "source": [
    "def plot_example(x, x_gt=None, x_pred=None, fn=None):\n",
    "    charge_locations = np.array([[-1.53846154, -1.53846154],\n",
    "                                 [ 1.53846154, -1.53846154],\n",
    "                                 [ 0.        ,  1.53846154]])  # charge locations are fixed\n",
    "    fig = plt.figure()\n",
    "    axes = plt.gca()\n",
    "    axes.set_xlim([-5., 5.])\n",
    "    axes.set_ylim([-5., 5.])\n",
    "    cmap = matplotlib.cm.get_cmap('tab20')\n",
    "    plt.plot(x[:, 0], x[:, 1], color=cmap(0))\n",
    "    plt.plot(x[0, 0], x[0, 1], 'd', color=cmap(1))\n",
    "    fig.set_size_inches(5, 5)\n",
    "    for charge in charge_locations:\n",
    "        plt.plot(charge[0], charge[1], 'd', color='black')\n",
    "    if x_gt is not None:\n",
    "        plt.plot(x_gt[:, 0], x_gt[:, 1], color='red', linewidth=.5)\n",
    "    if x_pred is not None:\n",
    "        plt.plot(x_pred[:, 0], x_pred[:, 1], color='green', linestyle='--')\n",
    "    if fn is None:\n",
    "        plt.show()\n",
    "    else:\n",
    "        plt.savefig(fn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d28681a6",
   "metadata": {
    "id": "d28681a6",
    "outputId": "66752665-2c40-409e-b2a7-e70011b21c65"
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 360x360 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Charges are [-0.44862364 -0.51910605 -0.40360995]\n"
     ]
    }
   ],
   "source": [
    "test_idx = np.random.randint(150)\n",
    "plot_example(simulation_train[test_idx], simulation_continued_train[test_idx])\n",
    "print(f'Charges are {charges_train[test_idx]}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "883762b1",
   "metadata": {
    "id": "883762b1"
   },
   "source": [
    "# Task 3.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1ddabe",
   "metadata": {
    "id": "4c1ddabe"
   },
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bd9df856",
   "metadata": {
    "id": "bd9df856"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "#Playground\n",
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7dd9b7c1",
   "metadata": {
    "id": "7dd9b7c1"
   },
   "outputs": [],
   "source": [
    "#Task 3.1\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "class DatasetTaskOne(Dataset):\n",
    "    def __init__(self, simulation_data,charge_targets):\n",
    "        padded_len = len(max(simulation_data, key=len)) # Should be 110 ideally but set to max length just in case\n",
    "        padded_arrays = []\n",
    "        for i in range(len(simulation_data)):\n",
    "            diff = padded_len - simulation_data[i].shape[0] # How many rows should we pad?\n",
    "            # Pad diff amount of [0,0] rows to the end \n",
    "            padded_arrays.append(np.pad(simulation_data[i],[(0,diff),(0,0)],mode='constant',constant_values=0))\n",
    "        # Create data and target tensors\n",
    "        data = np.array(padded_arrays)\n",
    "        (samples,length,pos_dim) = data.shape\n",
    "        self.data = torch.FloatTensor(data).view(samples,1,-1) # Samples,Channels,Sequence length\n",
    "        print(self.data.shape)\n",
    "        self.targets = torch.FloatTensor(np.array(charge_targets))\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c08b2a3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "diff = len(max(simulation_train, key = len)) - simulation_train[0].shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "6f255f60",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3.2\n",
    "\n",
    "from torch.utils.data import Dataset, DataLoader,TensorDataset\n",
    "class DatasetTaskTwo(Dataset):\n",
    "    def __init__(self, simulation_data,continued_simulations):\n",
    "        padded_len = len(max(simulation_data, key=len)) # Should be 110 ideally but set to max length just in case\n",
    "        padded_arrays = []\n",
    "        for i in range(len(simulation_data)):\n",
    "            diff = padded_len - simulation_data[i].shape[0] # How many rows should we pad?\n",
    "            # Pad diff amount of [0,0] rows to the end \n",
    "            padded_arrays.append(np.pad(simulation_data[i],[(0,diff),(0,0)],mode='constant',constant_values=0))\n",
    "        # Create data and target tensors\n",
    "        data = np.array(padded_arrays)\n",
    "        (samples,length,pos_dim) = data.shape\n",
    "        self.data = torch.FloatTensor(data).view(samples,1,-1) # Samples,Channels,Sequence length\n",
    "        print(len(self.data))\n",
    "        print(self.data.shape)\n",
    "        \n",
    "        \n",
    "        padded_len_target = len(max(continued_simulations, key = len))\n",
    "        padded_target_array = []\n",
    "        for j in range(len(continued_simulations)):\n",
    "            diff_targ = padded_len_target - continued_simulations[j].shape[0]\n",
    "            padded_target_array.append(np.pad(continued_simulations[j], [(0, diff_targ), (0,0)], mode = 'constant', constant_values = 0))\n",
    "        targets = np.array(padded_target_array)\n",
    "        \n",
    "        (targ_samples, targ_length, targ_pos_dim) = targets.shape\n",
    "        self.targets = torch.FloatTensor(targets).view(targ_samples,1,-1)\n",
    "        print(len(self.targets))\n",
    "        print(self.targets.shape)\n",
    "        \n",
    "    def __getitem__(self, index):\n",
    "        x = self.data[index]\n",
    "        y = self.targets[index]\n",
    "        \n",
    "\n",
    "        return x, y\n",
    "    \n",
    "    def __len__(self):\n",
    "        return len(self.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "4ec1e03a",
   "metadata": {
    "id": "4ec1e03a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([800, 1, 220])\n",
      "torch.Size([100, 1, 220])\n",
      "torch.Size([100, 1, 220])\n"
     ]
    }
   ],
   "source": [
    "#For task 3.1\n",
    "t1_train_dataset = DatasetTaskOne(simulation_train,charges_train)\n",
    "t1_train_loader = torch.utils.data.DataLoader(t1_train_dataset, batch_size=10)\n",
    "t1_valid_dataset = DatasetTaskOne(simulation_valid,charges_valid)\n",
    "t1_valid_loader = torch.utils.data.DataLoader(t1_valid_dataset, batch_size=10)\n",
    "t1_test_dataset = DatasetTaskOne(simulation_test,charges_test)\n",
    "t1_test_loader = torch.utils.data.DataLoader(t1_test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52dbb621",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "150\n",
      "torch.Size([150, 1, 220])\n",
      "150\n",
      "torch.Size([150, 1, 120])\n",
      "100\n",
      "torch.Size([100, 1, 220])\n",
      "100\n",
      "torch.Size([100, 1, 120])\n",
      "100\n",
      "torch.Size([100, 1, 220])\n",
      "100\n",
      "torch.Size([100, 1, 118])\n"
     ]
    }
   ],
   "source": [
    "#For task 3.2\n",
    "t2_train_dataset = DatasetTaskTwo(simulation_train_task32,simulation_continued_train)\n",
    "t2_train_loader = torch.utils.data.DataLoader(t2_train_dataset, batch_size=10)\n",
    "t2_valid_dataset = DatasetTaskTwo(simulation_valid,simulation_continued_valid)\n",
    "t2_valid_loader = torch.utils.data.DataLoader(t2_valid_dataset, batch_size=10)\n",
    "t2_test_dataset = DatasetTaskTwo(simulation_test,simulation_continued_test)\n",
    "t2_test_loader = torch.utils.data.DataLoader(t2_test_dataset, batch_size=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e4be32b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#testing the train loader\n",
    "a, b = [], []\n",
    "for train, targ in t2_train_loader:\n",
    "    a.append(train)\n",
    "    b.append(targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "ff174d5f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 220])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[0][0].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "2f7b2d05",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 120])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b[0][0].shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc8853f6",
   "metadata": {
    "id": "cc8853f6"
   },
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "8794a0cf",
   "metadata": {
    "id": "8794a0cf"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "from torch import nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "92d423e7",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Task 3.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "8a570313",
   "metadata": {},
   "outputs": [],
   "source": [
    "class GRURegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim,device):\n",
    "        super(GRURegressor, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # Compress sequence length into filters \n",
    "        self.rnn = nn.GRUCell(input_dim, hidden_dim)\n",
    "        \n",
    "        #self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, batch_input ):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, 1,seq_length]\n",
    "            \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device) \n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        for i in range(0,220,2):\n",
    "            hidden = self.rnn(batch_input[:,0,i:i+2],hidden) # Pass the i-th compressed sequence step\n",
    "        # feed output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        h = nn.ReLU()(self.fc1(hidden))\n",
    "        output = self.fc2(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d62b5aa6",
   "metadata": {
    "id": "d62b5aa6"
   },
   "outputs": [],
   "source": [
    "class ConvGRURegressor(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim,device, conv_filters=64,kernel_size=4,stride=4):\n",
    "        super(ConvGRURegressor, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.conv_filters = conv_filters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # Compress sequence length into filters \n",
    "        self.conv1d_1 = nn.Conv1d(1,out_channels=conv_filters,kernel_size=kernel_size,stride=stride,padding=\"valid\")\n",
    "        self.conv1d_2 = nn.Conv1d(conv_filters,out_channels=conv_filters*2,kernel_size=kernel_size,stride=stride,padding=\"valid\")\n",
    "        self.rnn = nn.GRUCell(conv_filters*2, hidden_dim)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, batch_input ):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, 1,seq_length]\n",
    "        embedding = self.conv1d_1(batch_input) # embedding: [batch_size,filters,reduced_sequence_length]\n",
    "        embedding2 = self.conv1d_2(embedding) # embedding: [batch_size,filters,reduced_sequence_length]\n",
    "            \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device) \n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        for i in range(embedding2.shape[2]):\n",
    "            hidden = self.rnn(embedding2[:,:,i],hidden) # Pass the i-th compressed sequence step\n",
    "        #hidden = self.drop(hidden)\n",
    "        # feed output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        h = nn.ReLU()(self.fc1(hidden))\n",
    "        output = self.fc2(h)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "7273df46",
   "metadata": {},
   "outputs": [],
   "source": [
    "class BenchmarkFNN(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim,device):\n",
    "        super(BenchmarkFNN, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        \n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(input_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, hidden_dim//2)\n",
    "        self.fc3 = nn.Linear(hidden_dim//2, output_dim)\n",
    "    \n",
    "    def forward(self, batch_input):\n",
    "        \n",
    "        # feed output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        h1 = nn.ReLU()(self.fc1(batch_input))\n",
    "        h1 = self.drop(h1)\n",
    "        h2 = nn.ReLU()(self.fc2(h1))\n",
    "        output = self.fc3(h2)\n",
    "        return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "e620087f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Task 3.2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "528d6f0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#GRU with attention\n",
    "#we need our model to have input dim = 2 and output_dim = 120 (we need a sequence in the output) \n",
    "\n",
    "class GRURegressor32(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim,device):\n",
    "        super(GRURegressor32, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # Compress sequence length into filters \n",
    "        self.rnn1 = nn.GRUCell(input_dim, hidden_dim)\n",
    "        self.rnn2 = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        #self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, batch_input ):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, 1,seq_length]\n",
    "            \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device) \n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        for i in range(0,220,2):\n",
    "            hidden = self.rnn1(batch_input[:,0,i:i+2],hidden) # Pass the i-th compressed sequence step\n",
    "        # feed output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "        #hidden_dim = [10, 256]\n",
    "        \n",
    "        \n",
    "        #so i have my hidden vector at time = t\n",
    "        hidden_vectors = []\n",
    "        output_vectors = []\n",
    "        \n",
    "        hidden2 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        for j in range(0,60):\n",
    "            hidden2 = self.rnn2(hidden, hidden2)\n",
    "            hidden_vectors.append(hidden2)\n",
    "            #each vector has shape [10, 256]\n",
    "            #batch =1 so the shape is [1,256]\n",
    "        \n",
    "        \n",
    "        for op in range(len(hidden_vectors)):\n",
    "            h1 = nn.ReLU()(self.fc1(hidden_vectors[op]))\n",
    "            h2 = self.fc2(h1) #operation [10,256] and [256,2]\n",
    "            #h2 has a dimension (10, 2)\n",
    "            #h2 batch =1 has the shape (1,2) and we have 60 time steps.\n",
    "            \n",
    "\n",
    "            output_vectors.append(h2)\n",
    "            \n",
    "        outputs = torch.stack(output_vectors, dim=1)\n",
    "        \n",
    "        final_output = []\n",
    "        for tens in range(len(outputs)):\n",
    "            t = outputs[tens].view(1,-1) #we need the output as [10,1,120], it was [10,60,20]. Hence the conversion\n",
    "            final_output.append(t)\n",
    "        \n",
    "        model_output = torch.stack(final_output)\n",
    "            \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "96659ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "class ConvGRURegressor32(nn.Module):\n",
    "\n",
    "    def __init__(self, input_dim,hidden_dim,output_dim,device, conv_filters=64,kernel_size=4,stride=4):\n",
    "        super(ConvGRURegressor32, self).__init__()\n",
    "        \n",
    "        self.input_dim = input_dim\n",
    "        self.conv_filters = conv_filters\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.device = device\n",
    "        \n",
    "        # Compress sequence length into filters \n",
    "        self.conv1d_1 = nn.Conv1d(1,out_channels=conv_filters,kernel_size=kernel_size,stride=stride,padding=\"valid\")\n",
    "        self.conv1d_2 = nn.Conv1d(conv_filters,out_channels=conv_filters*2,kernel_size=kernel_size,stride=stride,padding=\"valid\")\n",
    "        self.rnn1 = nn.GRUCell(conv_filters*2, hidden_dim)\n",
    "        self.rnn2 = nn.GRUCell(hidden_dim, hidden_dim)\n",
    "        self.drop = nn.Dropout(0.5)\n",
    "        self.fc1 = nn.Linear(hidden_dim, hidden_dim)\n",
    "        self.fc2 = nn.Linear(hidden_dim, output_dim)\n",
    "    \n",
    "    def forward(self, batch_input ):\n",
    "        \n",
    "        # input shapes:\n",
    "        # batch_input: [batch_size, 1,seq_length]\n",
    "        embedding = self.conv1d_1(batch_input) # embedding: [batch_size,filters,reduced_sequence_length]\n",
    "        embedding2 = self.conv1d_2(embedding) # embedding: [batch_size,filters,reduced_sequence_length]\n",
    "            \n",
    "        # Generate initial hidden and cell states\n",
    "        hidden = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device) \n",
    "        \n",
    "        # Feed packed input sequence to lstm \n",
    "        for i in range(embedding2.shape[2]):\n",
    "            hidden = self.rnn1(embedding2[:,:,i],hidden) # Pass the i-th compressed sequence step\n",
    "        #hidden = self.drop(hidden)\n",
    "        # feed output to MLP, apply ReLU nonlinearity\n",
    "        # shape [batch_size, hidden_dim]\n",
    "    \n",
    "        #so i have my hidden vector at time = t\n",
    "        hidden_vectors = []\n",
    "        output_vectors = []\n",
    "        \n",
    "        hidden2 = torch.randn(batch_input.shape[0], self.hidden_dim).to(self.device)\n",
    "        for j in range(0,60):\n",
    "            hidden2 = self.rnn2(hidden, hidden2)\n",
    "            hidden_vectors.append(hidden2)\n",
    "            #each vector has shape [10, 256]\n",
    "            #batch =1 so the shape is [1,256]\n",
    "        \n",
    "        \n",
    "        for op in range(len(hidden_vectors)):\n",
    "            h1 = nn.ReLU()(self.fc1(hidden_vectors[op]))\n",
    "            h2 = self.fc2(h1) #operation [10,256] and [256,2]\n",
    "            #h2 has a dimension (10, 2)\n",
    "            #h2 batch =1 has the shape (1,2) and we have 60 time steps.\n",
    "            \n",
    "\n",
    "            output_vectors.append(h2)\n",
    "            \n",
    "        outputs = torch.stack(output_vectors, dim=1)\n",
    "        \n",
    "        final_output = []\n",
    "        for tens in range(len(outputs)):\n",
    "            t = outputs[tens].view(1,-1) #we need the output as [10,1,120], it was [10,60,20]. Hence the conversion\n",
    "            final_output.append(t)\n",
    "        \n",
    "        model_output = torch.stack(final_output)\n",
    "            \n",
    "        return model_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "7060a02a",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = ConvGRURegressor32(input_dim=220,hidden_dim=256,output_dim = 2, device = 'cpu')\n",
    "criterion = nn.MSELoss()\n",
    "for train_data, targets in t2_train_loader:\n",
    "    # Forward\n",
    "    input_tensor = train_data\n",
    "    outputs = model.forward(input_tensor)\n",
    "    loss = criterion(outputs,targ)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "a09831cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 220])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "522d8ffe",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 120])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7f9c318c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10, 1, 120])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "43355f31",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.9955, grad_fn=<MseLossBackward0>)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e443b7f",
   "metadata": {
    "id": "0e443b7f"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "5a5b0aca",
   "metadata": {
    "id": "5a5b0aca"
   },
   "outputs": [],
   "source": [
    "#todo\n",
    "def save_model_checkpoint(path, model, optimizer, val_loss, val_acc, train_acc, train_loss ):\n",
    "    if path == None:\n",
    "        return print(\"Kindly define a path\")\n",
    "    path = path\n",
    "    \n",
    "    save_dict = {\"model_dict\" : model.state_dict(), \n",
    "                 \"optimizer_dict\": optimizer.state_dict(),\n",
    "                 \"val_loss_dict\": val_loss,\n",
    "                 \"val_acc_dict\": val_acc,\n",
    "                 \"train_acc_dict\": train_acc,\n",
    "                 \"train_loss_dict\": train_loss}\n",
    "    torch.save(save_dict, path)\n",
    "    return print(\"Model Saved to ==> {}\".format(path))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "58348edd",
   "metadata": {
    "id": "58348edd"
   },
   "outputs": [],
   "source": [
    "# training and validation after every epoch\n",
    "def train(model, train_loader, val_loader, criterion, num_epochs, save_name):\n",
    "    best_val_loss = float(\"Inf\") \n",
    "    train_losses = []\n",
    "    val_losses = []\n",
    "    train_acc = []\n",
    "    val_acc = []\n",
    "    cur_step = 0\n",
    "    train_pred = []\n",
    "    val_pred = []\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        running_loss = 0.0\n",
    "        running_train_acc = 0.0\n",
    "  \n",
    "        model.train()\n",
    "        print(\"Starting epoch \" + str(epoch+1))\n",
    "        for train_data, targets in train_loader:\n",
    "            \n",
    "           \n",
    "            # Forward\n",
    "            input_tensor = train_data.to(device)\n",
    "            outputs = model.forward(input_tensor)\n",
    "            loss = criterion(outputs,targets.to(device))\n",
    "            loss = loss/120\n",
    "                \n",
    "            # Backward and optimize\n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            optimizer.step()   \n",
    "            running_loss += loss\n",
    "          \n",
    "\n",
    "        avg_train_loss = running_loss / len(train_loader)\n",
    "        train_losses.append(avg_train_loss)\n",
    "        print(\"Train Pass Completed\")\n",
    "\n",
    "        ########################################|Validation Set|#############################################\n",
    "        val_running_loss = 0.0\n",
    "        with torch.no_grad():\n",
    "            model.eval()\n",
    "            for val_data, val_targets in val_loader:\n",
    "                input_tensor = val_data.to(device)\n",
    "                outputs = model.forward(input_tensor)\n",
    "                loss = criterion(outputs,val_targets.to(device))\n",
    "                val_running_loss += loss\n",
    "\n",
    "        avg_val_loss = val_running_loss / len(val_loader)\n",
    "        val_losses.append(avg_val_loss)\n",
    "\n",
    "        \n",
    "        print('Epoch [{}/{}],Train Loss: {:.4f}, Valid Loss: {:.8f}' \n",
    "            .format(epoch+1, num_epochs, avg_train_loss, avg_val_loss))\n",
    "        if avg_val_loss < best_val_loss:\n",
    "            best_val_loss = avg_val_loss \n",
    "            save_model_checkpoint(save_name, model, optimizer, best_val_loss, 0, 0, avg_train_loss )\n",
    "    \n",
    "    print(\"Finished Training\") \n",
    "    return train_losses, val_losses\n",
    "     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07943e62",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/300],Train Loss: 0.1161, Valid Loss: 0.09134934\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/300],Train Loss: 0.0828, Valid Loss: 0.09106201\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/300],Train Loss: 0.0825, Valid Loss: 0.09090095\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/300],Train Loss: 0.0823, Valid Loss: 0.09077165\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/300],Train Loss: 0.0822, Valid Loss: 0.09065922\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/300],Train Loss: 0.0821, Valid Loss: 0.09056215\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/300],Train Loss: 0.0820, Valid Loss: 0.09046462\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/300],Train Loss: 0.0820, Valid Loss: 0.09037244\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/300],Train Loss: 0.0819, Valid Loss: 0.09028576\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/300],Train Loss: 0.0818, Valid Loss: 0.09019928\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/300],Train Loss: 0.0818, Valid Loss: 0.09012228\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/300],Train Loss: 0.0817, Valid Loss: 0.09003752\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/300],Train Loss: 0.0816, Valid Loss: 0.08994749\n",
      "Model Saved to ==> GRU_reg.pt\n",
      "Starting epoch 14\n"
     ]
    }
   ],
   "source": [
    "GRU_reg = GRURegressor(input_dim=2,hidden_dim=256,output_dim=3,device='cuda:0').cuda()\n",
    "\n",
    "optimizer = torch.optim.SGD(GRU_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = torch.optim.Adam(GRU_reg.parameters(), lr= 1e-4, weight_decay = 0.01)\n",
    "num_epochs = 300\n",
    "save_name = f'GRU_reg.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(GRU_reg, \n",
    "                                                      t1_train_loader, t1_valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "176b3ea3",
   "metadata": {
    "id": "176b3ea3"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/100],Train Loss: 0.0844, Valid Loss: 0.07058328\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/100],Train Loss: 0.0623, Valid Loss: 0.06625268\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/100],Train Loss: 0.0603, Valid Loss: 0.06607549\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/100],Train Loss: 0.0593, Valid Loss: 0.06633176\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/100],Train Loss: 0.0591, Valid Loss: 0.06721675\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/100],Train Loss: 0.0591, Valid Loss: 0.06836617\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/100],Train Loss: 0.0595, Valid Loss: 0.06923538\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/100],Train Loss: 0.0598, Valid Loss: 0.06914496\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/100],Train Loss: 0.0600, Valid Loss: 0.06812099\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/100],Train Loss: 0.0601, Valid Loss: 0.06726190\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/100],Train Loss: 0.0601, Valid Loss: 0.06665851\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/100],Train Loss: 0.0599, Valid Loss: 0.06620124\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/100],Train Loss: 0.0596, Valid Loss: 0.06590126\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 14\n",
      "Train Pass Completed\n",
      "Epoch [14/100],Train Loss: 0.0593, Valid Loss: 0.06591673\n",
      "Starting epoch 15\n",
      "Train Pass Completed\n",
      "Epoch [15/100],Train Loss: 0.0592, Valid Loss: 0.06573399\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 16\n",
      "Train Pass Completed\n",
      "Epoch [16/100],Train Loss: 0.0590, Valid Loss: 0.06595352\n",
      "Starting epoch 17\n",
      "Train Pass Completed\n",
      "Epoch [17/100],Train Loss: 0.0588, Valid Loss: 0.06558206\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 18\n",
      "Train Pass Completed\n",
      "Epoch [18/100],Train Loss: 0.0587, Valid Loss: 0.06567401\n",
      "Starting epoch 19\n",
      "Train Pass Completed\n",
      "Epoch [19/100],Train Loss: 0.0586, Valid Loss: 0.06593271\n",
      "Starting epoch 20\n",
      "Train Pass Completed\n",
      "Epoch [20/100],Train Loss: 0.0586, Valid Loss: 0.06586169\n",
      "Starting epoch 21\n",
      "Train Pass Completed\n",
      "Epoch [21/100],Train Loss: 0.0585, Valid Loss: 0.06584455\n",
      "Starting epoch 22\n",
      "Train Pass Completed\n",
      "Epoch [22/100],Train Loss: 0.0585, Valid Loss: 0.06582376\n",
      "Starting epoch 23\n",
      "Train Pass Completed\n",
      "Epoch [23/100],Train Loss: 0.0584, Valid Loss: 0.06570130\n",
      "Starting epoch 24\n",
      "Train Pass Completed\n",
      "Epoch [24/100],Train Loss: 0.0583, Valid Loss: 0.06582494\n",
      "Starting epoch 25\n",
      "Train Pass Completed\n",
      "Epoch [25/100],Train Loss: 0.0584, Valid Loss: 0.06582799\n",
      "Starting epoch 26\n",
      "Train Pass Completed\n",
      "Epoch [26/100],Train Loss: 0.0583, Valid Loss: 0.06610332\n",
      "Starting epoch 27\n",
      "Train Pass Completed\n",
      "Epoch [27/100],Train Loss: 0.0582, Valid Loss: 0.06566877\n",
      "Starting epoch 28\n",
      "Train Pass Completed\n",
      "Epoch [28/100],Train Loss: 0.0582, Valid Loss: 0.06567745\n",
      "Starting epoch 29\n",
      "Train Pass Completed\n",
      "Epoch [29/100],Train Loss: 0.0581, Valid Loss: 0.06585607\n",
      "Starting epoch 30\n",
      "Train Pass Completed\n",
      "Epoch [30/100],Train Loss: 0.0581, Valid Loss: 0.06593668\n",
      "Starting epoch 31\n",
      "Train Pass Completed\n",
      "Epoch [31/100],Train Loss: 0.0580, Valid Loss: 0.06569596\n",
      "Starting epoch 32\n",
      "Train Pass Completed\n",
      "Epoch [32/100],Train Loss: 0.0580, Valid Loss: 0.06585529\n",
      "Starting epoch 33\n",
      "Train Pass Completed\n",
      "Epoch [33/100],Train Loss: 0.0580, Valid Loss: 0.06572116\n",
      "Starting epoch 34\n",
      "Train Pass Completed\n",
      "Epoch [34/100],Train Loss: 0.0580, Valid Loss: 0.06581479\n",
      "Starting epoch 35\n",
      "Train Pass Completed\n",
      "Epoch [35/100],Train Loss: 0.0578, Valid Loss: 0.06552439\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 36\n",
      "Train Pass Completed\n",
      "Epoch [36/100],Train Loss: 0.0580, Valid Loss: 0.06571953\n",
      "Starting epoch 37\n",
      "Train Pass Completed\n",
      "Epoch [37/100],Train Loss: 0.0578, Valid Loss: 0.06548383\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 38\n",
      "Train Pass Completed\n",
      "Epoch [38/100],Train Loss: 0.0577, Valid Loss: 0.06547430\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 39\n",
      "Train Pass Completed\n",
      "Epoch [39/100],Train Loss: 0.0577, Valid Loss: 0.06548278\n",
      "Starting epoch 40\n",
      "Train Pass Completed\n",
      "Epoch [40/100],Train Loss: 0.0577, Valid Loss: 0.06548259\n",
      "Starting epoch 41\n",
      "Train Pass Completed\n",
      "Epoch [41/100],Train Loss: 0.0577, Valid Loss: 0.06542709\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 42\n",
      "Train Pass Completed\n",
      "Epoch [42/100],Train Loss: 0.0577, Valid Loss: 0.06543421\n",
      "Starting epoch 43\n",
      "Train Pass Completed\n",
      "Epoch [43/100],Train Loss: 0.0577, Valid Loss: 0.06531361\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 44\n",
      "Train Pass Completed\n",
      "Epoch [44/100],Train Loss: 0.0576, Valid Loss: 0.06535744\n",
      "Starting epoch 45\n",
      "Train Pass Completed\n",
      "Epoch [45/100],Train Loss: 0.0575, Valid Loss: 0.06519137\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 46\n",
      "Train Pass Completed\n",
      "Epoch [46/100],Train Loss: 0.0575, Valid Loss: 0.06532436\n",
      "Starting epoch 47\n",
      "Train Pass Completed\n",
      "Epoch [47/100],Train Loss: 0.0576, Valid Loss: 0.06537058\n",
      "Starting epoch 48\n",
      "Train Pass Completed\n",
      "Epoch [48/100],Train Loss: 0.0575, Valid Loss: 0.06540010\n",
      "Starting epoch 49\n",
      "Train Pass Completed\n",
      "Epoch [49/100],Train Loss: 0.0576, Valid Loss: 0.06523903\n",
      "Starting epoch 50\n",
      "Train Pass Completed\n",
      "Epoch [50/100],Train Loss: 0.0575, Valid Loss: 0.06515714\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 51\n",
      "Train Pass Completed\n",
      "Epoch [51/100],Train Loss: 0.0574, Valid Loss: 0.06522893\n",
      "Starting epoch 52\n",
      "Train Pass Completed\n",
      "Epoch [52/100],Train Loss: 0.0574, Valid Loss: 0.06515205\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 53\n",
      "Train Pass Completed\n",
      "Epoch [53/100],Train Loss: 0.0574, Valid Loss: 0.06510421\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 54\n",
      "Train Pass Completed\n",
      "Epoch [54/100],Train Loss: 0.0571, Valid Loss: 0.06503760\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 55\n",
      "Train Pass Completed\n",
      "Epoch [55/100],Train Loss: 0.0572, Valid Loss: 0.06520724\n",
      "Starting epoch 56\n",
      "Train Pass Completed\n",
      "Epoch [56/100],Train Loss: 0.0573, Valid Loss: 0.06506389\n",
      "Starting epoch 57\n",
      "Train Pass Completed\n",
      "Epoch [57/100],Train Loss: 0.0573, Valid Loss: 0.06510697\n",
      "Starting epoch 58\n",
      "Train Pass Completed\n",
      "Epoch [58/100],Train Loss: 0.0572, Valid Loss: 0.06487798\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 59\n",
      "Train Pass Completed\n",
      "Epoch [59/100],Train Loss: 0.0571, Valid Loss: 0.06499418\n",
      "Starting epoch 60\n",
      "Train Pass Completed\n",
      "Epoch [60/100],Train Loss: 0.0571, Valid Loss: 0.06480777\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 61\n",
      "Train Pass Completed\n",
      "Epoch [61/100],Train Loss: 0.0571, Valid Loss: 0.06484907\n",
      "Starting epoch 62\n",
      "Train Pass Completed\n",
      "Epoch [62/100],Train Loss: 0.0571, Valid Loss: 0.06503827\n",
      "Starting epoch 63\n",
      "Train Pass Completed\n",
      "Epoch [63/100],Train Loss: 0.0571, Valid Loss: 0.06508967\n",
      "Starting epoch 64\n",
      "Train Pass Completed\n",
      "Epoch [64/100],Train Loss: 0.0571, Valid Loss: 0.06499610\n",
      "Starting epoch 65\n",
      "Train Pass Completed\n",
      "Epoch [65/100],Train Loss: 0.0572, Valid Loss: 0.06496152\n",
      "Starting epoch 66\n",
      "Train Pass Completed\n",
      "Epoch [66/100],Train Loss: 0.0571, Valid Loss: 0.06512856\n",
      "Starting epoch 67\n",
      "Train Pass Completed\n",
      "Epoch [67/100],Train Loss: 0.0570, Valid Loss: 0.06496542\n",
      "Starting epoch 68\n",
      "Train Pass Completed\n",
      "Epoch [68/100],Train Loss: 0.0570, Valid Loss: 0.06478231\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 69\n",
      "Train Pass Completed\n",
      "Epoch [69/100],Train Loss: 0.0571, Valid Loss: 0.06503816\n",
      "Starting epoch 70\n",
      "Train Pass Completed\n",
      "Epoch [70/100],Train Loss: 0.0569, Valid Loss: 0.06478287\n",
      "Starting epoch 71\n",
      "Train Pass Completed\n",
      "Epoch [71/100],Train Loss: 0.0569, Valid Loss: 0.06478740\n",
      "Starting epoch 72\n",
      "Train Pass Completed\n",
      "Epoch [72/100],Train Loss: 0.0569, Valid Loss: 0.06497265\n",
      "Starting epoch 73\n",
      "Train Pass Completed\n",
      "Epoch [73/100],Train Loss: 0.0570, Valid Loss: 0.06497677\n",
      "Starting epoch 74\n",
      "Train Pass Completed\n",
      "Epoch [74/100],Train Loss: 0.0567, Valid Loss: 0.06469994\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 75\n",
      "Train Pass Completed\n",
      "Epoch [75/100],Train Loss: 0.0569, Valid Loss: 0.06469404\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 76\n",
      "Train Pass Completed\n",
      "Epoch [76/100],Train Loss: 0.0569, Valid Loss: 0.06481244\n",
      "Starting epoch 77\n",
      "Train Pass Completed\n",
      "Epoch [77/100],Train Loss: 0.0568, Valid Loss: 0.06481903\n",
      "Starting epoch 78\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass Completed\n",
      "Epoch [78/100],Train Loss: 0.0568, Valid Loss: 0.06482341\n",
      "Starting epoch 79\n",
      "Train Pass Completed\n",
      "Epoch [79/100],Train Loss: 0.0568, Valid Loss: 0.06472896\n",
      "Starting epoch 80\n",
      "Train Pass Completed\n",
      "Epoch [80/100],Train Loss: 0.0568, Valid Loss: 0.06486375\n",
      "Starting epoch 81\n",
      "Train Pass Completed\n",
      "Epoch [81/100],Train Loss: 0.0568, Valid Loss: 0.06496435\n",
      "Starting epoch 82\n",
      "Train Pass Completed\n",
      "Epoch [82/100],Train Loss: 0.0567, Valid Loss: 0.06485518\n",
      "Starting epoch 83\n",
      "Train Pass Completed\n",
      "Epoch [83/100],Train Loss: 0.0568, Valid Loss: 0.06480227\n",
      "Starting epoch 84\n",
      "Train Pass Completed\n",
      "Epoch [84/100],Train Loss: 0.0568, Valid Loss: 0.06466407\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 85\n",
      "Train Pass Completed\n",
      "Epoch [85/100],Train Loss: 0.0567, Valid Loss: 0.06477292\n",
      "Starting epoch 86\n",
      "Train Pass Completed\n",
      "Epoch [86/100],Train Loss: 0.0567, Valid Loss: 0.06461605\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 87\n",
      "Train Pass Completed\n",
      "Epoch [87/100],Train Loss: 0.0568, Valid Loss: 0.06451032\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 88\n",
      "Train Pass Completed\n",
      "Epoch [88/100],Train Loss: 0.0567, Valid Loss: 0.06438272\n",
      "Model Saved to ==> conv_GRU_reg.pt\n",
      "Starting epoch 89\n",
      "Train Pass Completed\n",
      "Epoch [89/100],Train Loss: 0.0567, Valid Loss: 0.06484544\n",
      "Starting epoch 90\n",
      "Train Pass Completed\n",
      "Epoch [90/100],Train Loss: 0.0567, Valid Loss: 0.06452288\n",
      "Starting epoch 91\n",
      "Train Pass Completed\n",
      "Epoch [91/100],Train Loss: 0.0566, Valid Loss: 0.06463843\n",
      "Starting epoch 92\n",
      "Train Pass Completed\n",
      "Epoch [92/100],Train Loss: 0.0567, Valid Loss: 0.06455689\n",
      "Starting epoch 93\n",
      "Train Pass Completed\n",
      "Epoch [93/100],Train Loss: 0.0567, Valid Loss: 0.06467317\n",
      "Starting epoch 94\n",
      "Train Pass Completed\n",
      "Epoch [94/100],Train Loss: 0.0566, Valid Loss: 0.06461171\n",
      "Starting epoch 95\n",
      "Train Pass Completed\n",
      "Epoch [95/100],Train Loss: 0.0566, Valid Loss: 0.06461628\n",
      "Starting epoch 96\n",
      "Train Pass Completed\n",
      "Epoch [96/100],Train Loss: 0.0566, Valid Loss: 0.06462693\n",
      "Starting epoch 97\n",
      "Train Pass Completed\n",
      "Epoch [97/100],Train Loss: 0.0566, Valid Loss: 0.06474793\n",
      "Starting epoch 98\n",
      "Train Pass Completed\n",
      "Epoch [98/100],Train Loss: 0.0566, Valid Loss: 0.06447889\n",
      "Starting epoch 99\n",
      "Train Pass Completed\n",
      "Epoch [99/100],Train Loss: 0.0566, Valid Loss: 0.06478833\n",
      "Starting epoch 100\n",
      "Train Pass Completed\n",
      "Epoch [100/100],Train Loss: 0.0566, Valid Loss: 0.06456646\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "conv_GRU_reg = ConvGRURegressor(input_dim=220,hidden_dim=256,output_dim=3,device='cuda:0').cuda()\n",
    "\n",
    "#optimizer = torch.optim.SGD(GRU_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(conv_GRU_reg.parameters(), lr= 6e-4, weight_decay = 0.01)\n",
    "num_epochs = 100\n",
    "save_name = f'conv_GRU_reg.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(conv_GRU_reg, \n",
    "                                                      t1_train_loader, t1_valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 201,
   "id": "8d24bfc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/100],Train Loss: 0.1255, Valid Loss: 0.11048593\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/100],Train Loss: 0.0985, Valid Loss: 0.09961852\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 3\n",
      "Train Pass Completed\n",
      "Epoch [3/100],Train Loss: 0.0944, Valid Loss: 0.09823599\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 4\n",
      "Train Pass Completed\n",
      "Epoch [4/100],Train Loss: 0.0923, Valid Loss: 0.09767643\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 5\n",
      "Train Pass Completed\n",
      "Epoch [5/100],Train Loss: 0.0923, Valid Loss: 0.09530633\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 6\n",
      "Train Pass Completed\n",
      "Epoch [6/100],Train Loss: 0.0908, Valid Loss: 0.09753335\n",
      "Starting epoch 7\n",
      "Train Pass Completed\n",
      "Epoch [7/100],Train Loss: 0.0907, Valid Loss: 0.09764654\n",
      "Starting epoch 8\n",
      "Train Pass Completed\n",
      "Epoch [8/100],Train Loss: 0.0902, Valid Loss: 0.09651460\n",
      "Starting epoch 9\n",
      "Train Pass Completed\n",
      "Epoch [9/100],Train Loss: 0.0904, Valid Loss: 0.09699424\n",
      "Starting epoch 10\n",
      "Train Pass Completed\n",
      "Epoch [10/100],Train Loss: 0.0886, Valid Loss: 0.09535459\n",
      "Starting epoch 11\n",
      "Train Pass Completed\n",
      "Epoch [11/100],Train Loss: 0.0889, Valid Loss: 0.09567834\n",
      "Starting epoch 12\n",
      "Train Pass Completed\n",
      "Epoch [12/100],Train Loss: 0.0880, Valid Loss: 0.09478736\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 13\n",
      "Train Pass Completed\n",
      "Epoch [13/100],Train Loss: 0.0876, Valid Loss: 0.09487361\n",
      "Starting epoch 14\n",
      "Train Pass Completed\n",
      "Epoch [14/100],Train Loss: 0.0868, Valid Loss: 0.09450311\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 15\n",
      "Train Pass Completed\n",
      "Epoch [15/100],Train Loss: 0.0870, Valid Loss: 0.09429415\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 16\n",
      "Train Pass Completed\n",
      "Epoch [16/100],Train Loss: 0.0871, Valid Loss: 0.09490481\n",
      "Starting epoch 17\n",
      "Train Pass Completed\n",
      "Epoch [17/100],Train Loss: 0.0861, Valid Loss: 0.09481150\n",
      "Starting epoch 18\n",
      "Train Pass Completed\n",
      "Epoch [18/100],Train Loss: 0.0858, Valid Loss: 0.09590409\n",
      "Starting epoch 19\n",
      "Train Pass Completed\n",
      "Epoch [19/100],Train Loss: 0.0860, Valid Loss: 0.09480494\n",
      "Starting epoch 20\n",
      "Train Pass Completed\n",
      "Epoch [20/100],Train Loss: 0.0855, Valid Loss: 0.09382478\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 21\n",
      "Train Pass Completed\n",
      "Epoch [21/100],Train Loss: 0.0850, Valid Loss: 0.09318412\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 22\n",
      "Train Pass Completed\n",
      "Epoch [22/100],Train Loss: 0.0850, Valid Loss: 0.09328335\n",
      "Starting epoch 23\n",
      "Train Pass Completed\n",
      "Epoch [23/100],Train Loss: 0.0849, Valid Loss: 0.09366285\n",
      "Starting epoch 24\n",
      "Train Pass Completed\n",
      "Epoch [24/100],Train Loss: 0.0851, Valid Loss: 0.09363931\n",
      "Starting epoch 25\n",
      "Train Pass Completed\n",
      "Epoch [25/100],Train Loss: 0.0847, Valid Loss: 0.09375682\n",
      "Starting epoch 26\n",
      "Train Pass Completed\n",
      "Epoch [26/100],Train Loss: 0.0843, Valid Loss: 0.09303369\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 27\n",
      "Train Pass Completed\n",
      "Epoch [27/100],Train Loss: 0.0842, Valid Loss: 0.09289190\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 28\n",
      "Train Pass Completed\n",
      "Epoch [28/100],Train Loss: 0.0842, Valid Loss: 0.09317096\n",
      "Starting epoch 29\n",
      "Train Pass Completed\n",
      "Epoch [29/100],Train Loss: 0.0841, Valid Loss: 0.09237819\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 30\n",
      "Train Pass Completed\n",
      "Epoch [30/100],Train Loss: 0.0839, Valid Loss: 0.09284021\n",
      "Starting epoch 31\n",
      "Train Pass Completed\n",
      "Epoch [31/100],Train Loss: 0.0841, Valid Loss: 0.09337173\n",
      "Starting epoch 32\n",
      "Train Pass Completed\n",
      "Epoch [32/100],Train Loss: 0.0840, Valid Loss: 0.09185451\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 33\n",
      "Train Pass Completed\n",
      "Epoch [33/100],Train Loss: 0.0838, Valid Loss: 0.09224298\n",
      "Starting epoch 34\n",
      "Train Pass Completed\n",
      "Epoch [34/100],Train Loss: 0.0838, Valid Loss: 0.09271467\n",
      "Starting epoch 35\n",
      "Train Pass Completed\n",
      "Epoch [35/100],Train Loss: 0.0836, Valid Loss: 0.09179419\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 36\n",
      "Train Pass Completed\n",
      "Epoch [36/100],Train Loss: 0.0836, Valid Loss: 0.09205691\n",
      "Starting epoch 37\n",
      "Train Pass Completed\n",
      "Epoch [37/100],Train Loss: 0.0837, Valid Loss: 0.09257879\n",
      "Starting epoch 38\n",
      "Train Pass Completed\n",
      "Epoch [38/100],Train Loss: 0.0836, Valid Loss: 0.09224651\n",
      "Starting epoch 39\n",
      "Train Pass Completed\n",
      "Epoch [39/100],Train Loss: 0.0835, Valid Loss: 0.09173950\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 40\n",
      "Train Pass Completed\n",
      "Epoch [40/100],Train Loss: 0.0833, Valid Loss: 0.09174815\n",
      "Starting epoch 41\n",
      "Train Pass Completed\n",
      "Epoch [41/100],Train Loss: 0.0835, Valid Loss: 0.09167912\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 42\n",
      "Train Pass Completed\n",
      "Epoch [42/100],Train Loss: 0.0835, Valid Loss: 0.09201635\n",
      "Starting epoch 43\n",
      "Train Pass Completed\n",
      "Epoch [43/100],Train Loss: 0.0833, Valid Loss: 0.09174102\n",
      "Starting epoch 44\n",
      "Train Pass Completed\n",
      "Epoch [44/100],Train Loss: 0.0835, Valid Loss: 0.09183622\n",
      "Starting epoch 45\n",
      "Train Pass Completed\n",
      "Epoch [45/100],Train Loss: 0.0835, Valid Loss: 0.09234612\n",
      "Starting epoch 46\n",
      "Train Pass Completed\n",
      "Epoch [46/100],Train Loss: 0.0838, Valid Loss: 0.09204959\n",
      "Starting epoch 47\n",
      "Train Pass Completed\n",
      "Epoch [47/100],Train Loss: 0.0836, Valid Loss: 0.09196196\n",
      "Starting epoch 48\n",
      "Train Pass Completed\n",
      "Epoch [48/100],Train Loss: 0.0835, Valid Loss: 0.09251444\n",
      "Starting epoch 49\n",
      "Train Pass Completed\n",
      "Epoch [49/100],Train Loss: 0.0836, Valid Loss: 0.09164427\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 50\n",
      "Train Pass Completed\n",
      "Epoch [50/100],Train Loss: 0.0833, Valid Loss: 0.09171291\n",
      "Starting epoch 51\n",
      "Train Pass Completed\n",
      "Epoch [51/100],Train Loss: 0.0834, Valid Loss: 0.09172919\n",
      "Starting epoch 52\n",
      "Train Pass Completed\n",
      "Epoch [52/100],Train Loss: 0.0834, Valid Loss: 0.09193493\n",
      "Starting epoch 53\n",
      "Train Pass Completed\n",
      "Epoch [53/100],Train Loss: 0.0832, Valid Loss: 0.09150631\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 54\n",
      "Train Pass Completed\n",
      "Epoch [54/100],Train Loss: 0.0833, Valid Loss: 0.09178319\n",
      "Starting epoch 55\n",
      "Train Pass Completed\n",
      "Epoch [55/100],Train Loss: 0.0833, Valid Loss: 0.09167683\n",
      "Starting epoch 56\n",
      "Train Pass Completed\n",
      "Epoch [56/100],Train Loss: 0.0834, Valid Loss: 0.09171928\n",
      "Starting epoch 57\n",
      "Train Pass Completed\n",
      "Epoch [57/100],Train Loss: 0.0833, Valid Loss: 0.09184670\n",
      "Starting epoch 58\n",
      "Train Pass Completed\n",
      "Epoch [58/100],Train Loss: 0.0835, Valid Loss: 0.09254342\n",
      "Starting epoch 59\n",
      "Train Pass Completed\n",
      "Epoch [59/100],Train Loss: 0.0837, Valid Loss: 0.09376182\n",
      "Starting epoch 60\n",
      "Train Pass Completed\n",
      "Epoch [60/100],Train Loss: 0.0838, Valid Loss: 0.09227023\n",
      "Starting epoch 61\n",
      "Train Pass Completed\n",
      "Epoch [61/100],Train Loss: 0.0837, Valid Loss: 0.09197801\n",
      "Starting epoch 62\n",
      "Train Pass Completed\n",
      "Epoch [62/100],Train Loss: 0.0835, Valid Loss: 0.09212498\n",
      "Starting epoch 63\n",
      "Train Pass Completed\n",
      "Epoch [63/100],Train Loss: 0.0836, Valid Loss: 0.09203687\n",
      "Starting epoch 64\n",
      "Train Pass Completed\n",
      "Epoch [64/100],Train Loss: 0.0836, Valid Loss: 0.09169625\n",
      "Starting epoch 65\n",
      "Train Pass Completed\n",
      "Epoch [65/100],Train Loss: 0.0832, Valid Loss: 0.09204961\n",
      "Starting epoch 66\n",
      "Train Pass Completed\n",
      "Epoch [66/100],Train Loss: 0.0833, Valid Loss: 0.09202901\n",
      "Starting epoch 67\n",
      "Train Pass Completed\n",
      "Epoch [67/100],Train Loss: 0.0832, Valid Loss: 0.09189956\n",
      "Starting epoch 68\n",
      "Train Pass Completed\n",
      "Epoch [68/100],Train Loss: 0.0832, Valid Loss: 0.09179363\n",
      "Starting epoch 69\n",
      "Train Pass Completed\n",
      "Epoch [69/100],Train Loss: 0.0832, Valid Loss: 0.09166196\n",
      "Starting epoch 70\n",
      "Train Pass Completed\n",
      "Epoch [70/100],Train Loss: 0.0832, Valid Loss: 0.09174826\n",
      "Starting epoch 71\n",
      "Train Pass Completed\n",
      "Epoch [71/100],Train Loss: 0.0832, Valid Loss: 0.09148020\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 72\n",
      "Train Pass Completed\n",
      "Epoch [72/100],Train Loss: 0.0831, Valid Loss: 0.09149920\n",
      "Starting epoch 73\n",
      "Train Pass Completed\n",
      "Epoch [73/100],Train Loss: 0.0831, Valid Loss: 0.09175806\n",
      "Starting epoch 74\n",
      "Train Pass Completed\n",
      "Epoch [74/100],Train Loss: 0.0832, Valid Loss: 0.09200033\n",
      "Starting epoch 75\n",
      "Train Pass Completed\n",
      "Epoch [75/100],Train Loss: 0.0833, Valid Loss: 0.09183877\n",
      "Starting epoch 76\n",
      "Train Pass Completed\n",
      "Epoch [76/100],Train Loss: 0.0834, Valid Loss: 0.09161490\n",
      "Starting epoch 77\n",
      "Train Pass Completed\n",
      "Epoch [77/100],Train Loss: 0.0831, Valid Loss: 0.09165390\n",
      "Starting epoch 78\n",
      "Train Pass Completed\n",
      "Epoch [78/100],Train Loss: 0.0831, Valid Loss: 0.09191871\n",
      "Starting epoch 79\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train Pass Completed\n",
      "Epoch [79/100],Train Loss: 0.0832, Valid Loss: 0.09152376\n",
      "Starting epoch 80\n",
      "Train Pass Completed\n",
      "Epoch [80/100],Train Loss: 0.0831, Valid Loss: 0.09177291\n",
      "Starting epoch 81\n",
      "Train Pass Completed\n",
      "Epoch [81/100],Train Loss: 0.0831, Valid Loss: 0.09197382\n",
      "Starting epoch 82\n",
      "Train Pass Completed\n",
      "Epoch [82/100],Train Loss: 0.0830, Valid Loss: 0.09154239\n",
      "Starting epoch 83\n",
      "Train Pass Completed\n",
      "Epoch [83/100],Train Loss: 0.0829, Valid Loss: 0.09129942\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 84\n",
      "Train Pass Completed\n",
      "Epoch [84/100],Train Loss: 0.0831, Valid Loss: 0.09150403\n",
      "Starting epoch 85\n",
      "Train Pass Completed\n",
      "Epoch [85/100],Train Loss: 0.0831, Valid Loss: 0.09168002\n",
      "Starting epoch 86\n",
      "Train Pass Completed\n",
      "Epoch [86/100],Train Loss: 0.0830, Valid Loss: 0.09131439\n",
      "Starting epoch 87\n",
      "Train Pass Completed\n",
      "Epoch [87/100],Train Loss: 0.0829, Valid Loss: 0.09158293\n",
      "Starting epoch 88\n",
      "Train Pass Completed\n",
      "Epoch [88/100],Train Loss: 0.0830, Valid Loss: 0.09157836\n",
      "Starting epoch 89\n",
      "Train Pass Completed\n",
      "Epoch [89/100],Train Loss: 0.0830, Valid Loss: 0.09143256\n",
      "Starting epoch 90\n",
      "Train Pass Completed\n",
      "Epoch [90/100],Train Loss: 0.0829, Valid Loss: 0.09138021\n",
      "Starting epoch 91\n",
      "Train Pass Completed\n",
      "Epoch [91/100],Train Loss: 0.0830, Valid Loss: 0.09147092\n",
      "Starting epoch 92\n",
      "Train Pass Completed\n",
      "Epoch [92/100],Train Loss: 0.0831, Valid Loss: 0.09134408\n",
      "Starting epoch 93\n",
      "Train Pass Completed\n",
      "Epoch [93/100],Train Loss: 0.0830, Valid Loss: 0.09133097\n",
      "Starting epoch 94\n",
      "Train Pass Completed\n",
      "Epoch [94/100],Train Loss: 0.0829, Valid Loss: 0.09128375\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 95\n",
      "Train Pass Completed\n",
      "Epoch [95/100],Train Loss: 0.0829, Valid Loss: 0.09166127\n",
      "Starting epoch 96\n",
      "Train Pass Completed\n",
      "Epoch [96/100],Train Loss: 0.0828, Valid Loss: 0.09118789\n",
      "Model Saved to ==> benchmark_fnn.pt\n",
      "Starting epoch 97\n",
      "Train Pass Completed\n",
      "Epoch [97/100],Train Loss: 0.0828, Valid Loss: 0.09129578\n",
      "Starting epoch 98\n",
      "Train Pass Completed\n",
      "Epoch [98/100],Train Loss: 0.0828, Valid Loss: 0.09138878\n",
      "Starting epoch 99\n",
      "Train Pass Completed\n",
      "Epoch [99/100],Train Loss: 0.0829, Valid Loss: 0.09147375\n",
      "Starting epoch 100\n",
      "Train Pass Completed\n",
      "Epoch [100/100],Train Loss: 0.0829, Valid Loss: 0.09133402\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "# Benchmark Neural Network. Play around with hidden dim.\n",
    "benchmark_fnn = BenchmarkFNN(input_dim=220,hidden_dim=256,output_dim=3,device='cuda:0').cuda()\n",
    "\n",
    "#optimizer = torch.optim.SGD(GRU_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "optimizer = torch.optim.Adam(benchmark_fnn.parameters(), lr= 6e-4, weight_decay = 0.01)\n",
    "num_epochs = 100\n",
    "save_name = f'benchmark_fnn.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(benchmark_fnn, \n",
    "                                                      t1_train_loader, t1_valid_loader, criterion, num_epochs, save_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "15a2da72",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting epoch 1\n",
      "Train Pass Completed\n",
      "Epoch [1/2],Train Loss: 2.0450, Valid Loss: 2.19615507\n",
      "Model Saved to ==> GRU_reg_seq_32.pt\n",
      "Starting epoch 2\n",
      "Train Pass Completed\n",
      "Epoch [2/2],Train Loss: 2.0311, Valid Loss: 2.19309521\n",
      "Model Saved to ==> GRU_reg_seq_32.pt\n",
      "Finished Training\n"
     ]
    }
   ],
   "source": [
    "#Task 3.2\n",
    "\n",
    "device = 'cpu'\n",
    "GRU_reg = GRURegressor32(input_dim=2,hidden_dim=256,output_dim=2,device='cpu')\n",
    "\n",
    "optimizer = torch.optim.SGD(GRU_reg.parameters(), lr=0.01, momentum=0.9)\n",
    "#optimizer = torch.optim.Adam(GRU_reg.parameters(), lr= 1e-4, weight_decay = 0.01)\n",
    "num_epochs = 2\n",
    "save_name = f'GRU_reg_seq_32.pt'\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "obtained_train_loss, obtained_val_loss = train(GRU_reg, \n",
    "                                                      t2_train_loader, \n",
    "                                                      t2_valid_loader, criterion, num_epochs, save_name)\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da139d5b",
   "metadata": {
    "id": "da139d5b"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ebed03ba",
   "metadata": {
    "id": "ebed03ba"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 1])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "targets.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "17af7ec3",
   "metadata": {
    "id": "17af7ec3"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([120, 1])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "outputs.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "43a3422e",
   "metadata": {
    "id": "43a3422e"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 1, 220])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "input_tensor.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9a59808b",
   "metadata": {
    "id": "9a59808b"
   },
   "source": [
    "# Task 3.2"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f64a855d",
   "metadata": {
    "id": "f64a855d"
   },
   "source": [
    "## Data Handling and Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b935865",
   "metadata": {
    "id": "5b935865"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ec19a8d",
   "metadata": {
    "id": "0ec19a8d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f189d19",
   "metadata": {
    "id": "8f189d19"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "867aabb3",
   "metadata": {
    "id": "867aabb3"
   },
   "source": [
    "## Model Implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "36fe2739",
   "metadata": {
    "id": "36fe2739"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f80b1ca2",
   "metadata": {
    "id": "f80b1ca2"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbf2800",
   "metadata": {
    "id": "fdbf2800"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "826fae3f",
   "metadata": {
    "id": "826fae3f"
   },
   "source": [
    "## Model Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "db3fce95",
   "metadata": {
    "id": "db3fce95"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41ddb47d",
   "metadata": {
    "id": "41ddb47d"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ee069fc",
   "metadata": {
    "id": "4ee069fc"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c87278a2",
   "metadata": {
    "id": "c87278a2"
   },
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cbb6137",
   "metadata": {
    "id": "2cbb6137"
   },
   "outputs": [],
   "source": [
    "#todo"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2cf6f4b7",
   "metadata": {
    "id": "2cf6f4b7"
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736c10d8",
   "metadata": {
    "id": "736c10d8"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "colab": {
   "name": "a3_skeleton.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
